# C语言的抽象描述

虽然C语言被称为“高级汇编”，它的语义实际上还是定义在一种非常贴近机器但也做了不少抽象的“C抽象计算机”上的，所以很多概念的讨论不能下降到“汇编如何如何”，还是要就C语言讨论C语言。
例如，完整地描述C语言的内存模型实际上并不需要显式地引入“栈”和“堆”的概念，“分配在栈上的内容”实际上是“自动分配内存的内容”，“分配在堆上的内容”实际上是“可以手动管理的内容”。
虽然如此，堆和栈之类的实际上是ABI或runtime的概念几乎是唯一用于实现C语言语义的方法，因此使用它们描述C语言的行为也没有什么太大的问题。

现在我们大概讨论一下，尽可能不考虑实际的实现，要怎么描述C语言的语义。首先，按照冯诺依曼架构，计算机是这样工作的：

1. 程序和数据被载入**内存**，内存的每一个字节都有一个地址；
2. CPU中的**控制器**依次读取内存中的指令，可以是顺序读取，也可以根据GOTO指令跳转；
3. 一些指令会读写内存；
4. 每一条指令被送往**运算器**计算，计算的中间结果可能被存放在一些**寄存器**中；

以上过程中，CPU加电之后发生了什么、程序和数据是怎么加载的、怎么根据地址寻找数据这一类的问题全部不做考虑——它们实际上是数字电路的问题，是“怎么设计出一个CPU”的问题。我们只是假定这样一台机器已经造出来了。
可计算性理论保证了以上过程原则上能够实现一切计算问题。

那么，C语言的各个组成部分和以上过程有什么联系？

在C语言中可以直接写`goto`语句，但是可以证明`if`,`for`,`while`等语句能够实现一切`goto`能够做到的功能，而且还结构清晰。这些语句用于描述**控制流**。

**变量**是内存中一块地址固定，专门被划分出来；当一个变量被声明时，自动就有一块这样的内存被分配。变量名只不过是一个简写，这就是为什么`&`运算符不会被多重使用——设`a`是一个变量，则`&a`得到的就是一个地址，这个地址存储在什么地方却不得而知。
**数组**是一系列在内存中连续分配的变量。
**指针**是一个变量，它存储的内容实际上是一个地址。（当然，内存并不知道这是一个地址；只有其内容被提交到CPU，并且按此执行读/写指令时它才展现出地址的作用）`*a`获得`a`处的内存保存的内容。
**结构体**和**共用体**是复合数据类型，前者是多个数据类型可能不同的变量放在一起得到的，后者是多个数据类型可能不同的变量共用一块内存（从而一个会覆盖另一个）得到的。

**数据类型**用于指明变量的内容应当被当成什么来执行各种操作，例如内存中的两个字节可以被诠释为一个整数，也可以被诠释为一个汉字的编码。
显然，数组、变量、指针、数据类型这些东西实际上和计算机的底层体系结构并没有多少关系，但引入这些概念无疑有助于让程序更清晰，并且不容易出错。
有时需要**数据类型强制转换**。

虽然数组可以隐式转换为指针，应该指出“数组变量”的语义和指针是不同的。
如果一个含有$n$个某种数据类型的数组被声明了，那么真的就会连续分配$n$个这种数据类型的变量。
另一方面，如果声明一个某种数据类型的指针，并不会直接有内存分配给它。
这就造成了一个很神奇的现象：对一个数组应用`sizeof`得到的结果和对这个数组隐式转化成的指针应用`sizeof`得到的结果是不同的：前者给出的是$n$个某种数据类型的变量需要的总长度，后者给出的是一个指针的长度（比如说一个字节）。
还有一个神奇的现象，就是含有数组成员的结构体的大小和含有指针成员的结构体的大小也是不一样的，从而它们之间就不能够强制转换了。

**函数调用**是另一种组织控制流的方式。当一个函数被调用，内存中会按照该函数的形参分配内存来保存参数，然后实参被放置到这些位置中；当函数调用结束，函数中的局部变量、形参什么的全部被释放，只留下返回值；主调函数从被调函数调用的位置开始继续执行。
这个机制可以用来实现一些有趣的功能。例如，如果形参被声明为数目可变，则可以通过`&`运算符获得数目可变形参的第一个的地址，然后不停向后读取，直到通过某种方式发现读到的已经不是参数了，此时就获得了所有参数。

# 内存分配的具体实现

## 内存分区

上一节中“内存”完全是抽象的概念，我们只知道“一些内容（如函数实参、数组、结构体）应该放在一起”，别的一无所知。
原则上，编译器可以随意分配内存，而程序员也可以随意管理内存（例如，手动指定某个指针的位置，向该指针指向的地址输入一些值），但这样一方面效率低下（内存将会非常碎片化），一方面非常不安全（程序员必须小心地分配内存，免得一不小心把已经占用的变量甚至程序指令覆盖掉）。
为了解决这些问题，我们希望，我们自己写的程序编译之后，满足以下条件：

- 变量存放的位置和程序员可以随意支配的内存区域最好分开；
- 程序代码存放的位置和以上两者最好也分开；
- 局部变量占据的内存最好可以容易地被分配和回收，并且要能够比较容易地追踪函数调用是怎么一层一层进行的（显然栈是最好的实现方法：一个函数被调用了，那就往栈中压入形参、局部变量之类的东西，执行完成，那就从栈顶移除这些东西）

于是非常自然的，分配给一个程序的内存分为5个区：

1. 栈，存放需要时分配，不需要时就可以释放的变量，基本上就是各种局部变量、函数形参之类的东西。
   栈内存的分配很多时候是内置在CPU的指令集中的，效率高，但是空间有限。
   基本上，左大括号`{`出现，那就入栈，右大括号`}`出现，那就出栈。
2. 堆，程序员可以手动管理的区域，通常用`malloc`和`free`管理。
3. 静态存储区，存放全局变量和静态变量的地方。
4. 常量存储区，可读不可写的地方。全局`const`就在这里（局部`const`还是在栈上）。
5. 程序代码区，存放二进制可执行代码。

栈和堆向相反的方向延伸，因此它们绝对不会相遇。
栈是连续的一块内存，编译期大小通常被固定。（需要注意的是也可能有一些办法能够动态分配栈内存，那么栈内存需要多大实际上是不能确定的；实际实现时基本上是分配一个定死了的值）
堆是不连续的，在堆的头部通常会有一个字节存放堆的大小，堆的具体内容由程序员安排。

## 操作系统

即使采用上一节的方法，我们还是会遇到内存安全性的问题。例如，程序员可能会胡乱分配很大的堆，以至于把内存中别的东西给覆盖了。
归根到底，我们自己的程序通常不是独占运行的，因此在运行我们自己的程序之前，最好还是首先运行一个“母程序”，它负责处理这些脏活，具体来说：

- 在适当的时候加载我们自己的（通常是非独占的）程序，即用户程序，给每个用户程序分配栈、堆，并且提供一组标准的API来动态分配堆（或者也许还有栈），而不是让程序员自己胡乱分配堆（注：提供一组标准的API来动态分配堆这件事实际上是由标准库负责的，但是标准库通常不会从头实现内存分配器，而是会调用系统提供的API）；
- 和输入输出设备交互（IO）、读写磁盘（文件系统）等也需要冗长的指令发送，这些也需要一组标准化的、语义清晰的API；
- 提供多线程、多进程等功能，也就是合理调度程序，造成“同时执行”的效果；
- 虚拟内存，为了提高效率和确保不同程序的内存不会重叠，需要让用户程序“以为”它在访问完整的，连续的一块内存，实则用户程序眼中的内存地址（虚拟地址）要被映射不同的，可能是不连续的或者甚至是磁盘上的地址上；
- 还有许许多多其它的功能

这个“母程序”当然就是**操作系统**。实际上，这就是为什么即使是在同样的计算机架构（一样的x86或者是ARM CPU，DDR 4内存，等等）下，虽然机器码都是一样的，不同的操作系统也需要不同的可执行文件——不同的操作系统会提供不同的API，在不同的位置寻找程序的执行入口，将不同的区域当成代码和数据，以不同的方式做必要的初始化……
总之，不同的操作系统需要不同的**可执行文件头**，也提供不同的DLL或者SO文件，那么自然不同操作系统需要不同的可执行文件了。

## 不同特性的实现

### 函数调用的实现

函数调用：

1. 主函数中最后一条指令的地址入栈
2. 参数入栈
3. 局部变量入栈

调用结束：

1. 局部变量出栈
2. 参数出栈
3. 此时栈顶指针指向主函数中的下一条指令的位置，继续执行主函数

## 数组


