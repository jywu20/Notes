# 一些用于具体计算的定义和公式

以下使用大写黑体字母表示矩阵，小写黑体字母表示向量。这里所说的矩阵和向量均可能不具备指标升降和坐标变换关系，因此不写成斜体以表示区别。

### 范数
$L^p$范数定义为
$$
\|\bold{x}\|_p = \left( \sum_i |x_i|^p \right)^{\frac{1}{p}}.
$$
显然，
$$
\|\bold{x}\|^2 \equiv \|\bold{x}\| = \bold{x}^\top \bold{x}.
$$

总的来说，$p$比较大时$L^p$范数在向量非常接近零时变化得比较缓慢，而在向量比较大的时候变化得很迅速。在零和非零元素之间的差异非常重要时，应该使用$L^1$范数。

定义$L^0$范数为向量中非零元素的个数。需要注意的是这个术语并不严谨，因为$L^0$并非范数——对向量的缩放不会改变$L^0$的大小。

有时希望衡量矩阵的大小，常使用Frobenius 范数
$$
\| \bold{A} \|_F = \sqrt{\sum_{i,j}A_{ij}^2}
$$
这是$L^2$范数的推广。

### 矩阵运算常用公式
$$
\mathrm{diag}(\bold{v}) \bold{x} = \bold{v} \cdot \bold{x}.
$$

设矩阵$\bold{A}$具有$n$个线性无关的特征向量$\bold{v}^{(1)}, \ldots, \bold{v}^{(n)}$以及和它们对应的特征值$\lambda_1, \ldots, \lambda_n$，设
$$
\bold{V} = [\bold{v}^{(1)}, \ldots, \bold{v}^{(n)}], \quad \bold{\lambda} = [\lambda_1, \ldots, \lambda_n]^\top,
$$
则有
$$
\bold{A} = \bold{V} \mathrm{diag}(\bold{\lambda}) \bold{V}^{-1}.
$$

特征分解对矩阵的性质有一定的要求，而奇异值分解则并没有这些要求。
$$
\bold{A} = \bold{U} \bold{D} \bold{V}^{-1}
$$
要求$\bold{U},\bold{V}$为正交方阵，$\bold{D}$为对角矩阵（不一定是方阵）。称$\bold{U}$的列向量为左奇异向量，$\bold{V}$的列向量为右奇异向量，$\bold{D}$的对角线上的值为奇异值。

可以证明，$\bold{A}$的左奇异向量就是$\bold{A}\bold{A}^\top$的特征向量，$\bold{A}$的右奇异向量就是$\bold{A}^\top \bold{A}$的特征向量，$\bold{A}$的奇异值就是$\bold{A}^\top \bold{A}$的特征值的平方根，也是$\bold{A}\bold{A}^\top$的平方根。

定义Moore-Penrose伪逆，
$$
\bold{A}^+ = \lim_{a \rightarrow 0} (\bold{A}^\top \bold{A} + a \bold{I})^{-1} \bold{A}^\top,
$$
则有
$$
\bold{A}^+ = \bold{V}\bold{D}^+ \bold{U}^\top,
$$
其中$\bold{D}^+$为其非零元素取倒数之后转置的结果。

设
$$
\bold{x} = \bold{A}^+ \bold{b},
$$
在当矩阵$\bold{A}$的列数多于行数时，使用伪逆求解线性方程是众多可能解法中的一种，且$\|\bold{x}\|$取最小值；当矩阵A 的行数多于列数时，可能没有解。在这种情况下，通过伪逆得到的$\bold{x}$使$\|\bold{A}\bold{x} - \bold{b}\|$最小。

$$
\mathrm{softmax}(\bold{x}) = [\frac{e^{x_1}}{\sum_i e^{x_i}}, \ldots, \frac{e^{x_n}}{\sum_i e^{x_i}}]^\top
$$

# 基本概念

## 机器学习需要做什么

机器学习系统的工作方式
1. 预处理，去除噪声等
2. 特征提取
3. 特征转换，也即数据降维等
4. 预测

预测是通常意义上的“机器学习”，但是真正影响系统性能的主要是前三步。因此机器学习问题往往归约为**特征工程**。

**嵌入(Embedding)** 指的是将高维的数据降维而保留大部分原信息。例如，使用RGB表示不同的颜色就可以视为将“颜色名称”降维为了一个三元数组。

## 数据集、特征与标签
设我们有下面所示的有限数据集
$$
D = \{(\bold{x}^{(i)}, y^{(i)})\}
$$
这个数据集中的每一项都代表一个例子，我们称它们为**样本**。每个样本分别由两个部分组成：
- 向量$\bold{x}^{(i)}$，是一系列**特征**的取值，这些特征描写了第$i$个例子值得注意的全部性质。例如，对一个名词而言，值得注意的特征包括格、性、数，也许还包括使用频率，于是我们可以把$\bold{x}$设置为$[\text{nominative}, \text{neutral}, \text{plural}, 0.01]^\top$。
- $y^{(i)}$，称为**标签**，通常是可以从特征当中判断出来的一些性质，比如说，在$\bold{x}^{(i)}$代表了一段文字的情况下，$y^{(i)}$就可以是这段文字的语言。

标签和特征的取值可以是连续的也可以是离散的。

我们希望数据集$D$是按照某个**确定不变的真实概率分布**$p_r(\bold{x}, y)$以**独立同分布**的方式产生的。因此，在$D$非常大的时候，它就是$p_r$的一个不完美的摹本。

## 模型以及用于建立模型的假设

一个预测装置是这样一个函数$f(\bold{x};\theta)$，在给定了**参数**$\theta$之后，预测装置读入$\bold{x}$并且预测它应该对应的标签$y$。容易看出$f$的形式要足够复杂以至于能够很好地概括$D$中特征和标签的关系。预测有两种方式，一种是直接预测标签的值，也就是
$$
\hat{y} = f(\bold{x};\theta),
$$
还有一种方法是计算不同标签的概率分布，也就是
$$
p(y|\bold{x}) = f_y (\bold{x};\theta).
$$
这里把可能的标签$y$看成是$f$的另一个参数，只是这个参数不能手工调节。显然，第一种方法可以看成第二种方法的特例（某个标签获得的概率为1，其它都是0），而且可以简单地使用第二种方法实现（例如取概率最大的标签输出）。
总之，模型需要做到给定一个$\bold{x}$，能够输出一个$\hat{y}$，或者输出$p(y|\bold{x})$。
如果确信能够输出一个$\hat{y}$，那么总是计算$p(y|\bold{x})$，然后输出
$$
\hat{y} = \argmax_y p(y | \bold{x}).
$$
反过来，$p(y|\bold{x})$也可以被看成是一个略微展宽的$\hat{y}$。

很显然，为了让预测装置——或者说**模型**——的预测能力足够强，$\theta$很可能是一个很大的向量，要手工调节参数来预测标签非常困难。因此需要使用一个**学习算法**和一个已经标好特征和标签的**训练数据集**，来自动地计算出参数取值$\theta^*$，让$f(\bold{x}|\theta^*)$近似和$f(\bold{x}|\theta)$在$D$上的效果相同。

如何判断参数近似值$\theta^*$的好坏？我们使用一个**测试数据集**来做这件事。例如可以定义**准确率**
$$
\mathrm{Acc}(f(\bold{x};\theta^*)) = \frac{1}{|D'|} \sum_{(\bold{x}, y) \in D'} I(f(\bold{x};\theta^*)=y)
$$
模型越准确，准确率越接近1，而且它必定小于1。也可以使用其它函数来判断近似值的好坏（称为metrics）

函数$f$的形式在实际问题中通常是不知道的。我们把所有可能的$f$组成的几何称为**假设空间**，而把具体使用的那个$f$称为**假设**。

通常使用的$f$或是线性的或是非线性的。线性的可以写成
$$
f(\bold{x};\theta) = \bold{w}^\top \bold{x} + b, \quad \theta = (\bold{w}, b)
$$
而非线性假设可以写成
$$
f(\bold{x};\theta) = \bold{w}^\top \phi (\bold{x}) + b, \quad \theta = (\bold{w}, b), \quad \phi(\bold{x}) = [\phi_1(\bold{x}), \ldots, \phi_K(\bold{x})]^\top
$$
也就是说，我们选定了一组总计$K$个基函数，然后把它们按照一定的权重线性叠加起来，就得到了一个非线性假设。

在实际工作中还是很难直接猜出正确的$\phi$的形式。那么为什么不使用另一个学习算法自动计算出$\phi$应该采取的形式呢？我们可以把每一个$\phi$写成下面的形式：
$$
\phi_k (\bold{x}) = h (\bold{w}_k^\top \phi'(\bold{x})+b_k)
$$
其中$\phi'$代表另一些基函数形式，而$h(\cdot)$则是某个固定不变的非线性函数，用于把输出值压缩到某个合理的区间（避免随着基函数的嵌套，输出值一层层放大）。这实际上就是神经网络算法了——通过多层基函数（神经元）做预测。

## 问题

### 监督学习
监督学习指的是训练数据集明确给出特征-标签对的学习。先前提到过，标签可以是连续的也可以是离散的。同时，我们既可以要求算法直接输出我们想要的标签，又可以要求算法输出不同标签的概率分布。因此我们就有了四种常见的问题：
- 直接预测某些特征对应的连续标签
- 估算某些特征对应的连续标签的概率分布
- 直接预测某些特征对应的离散标签
- 估算某些特征对应的离散标签的概率分布

第二类问题看起来是过于复杂了，因为要解决这一类问题必须在计算机内表示一个定义在实数集上的函数，而对一般的计算机架构而言这是做不到的；第三类问题则没有太多存在的必要——它可以很容易地划归到第四类问题当中。

那么，我们就得到了两类比较有意义而又比较常见的问题：
- **回归问题** 直接预测某些特征对应的连续标签
- **分类问题** 估算某些特征属于各个类别的可能性（当我们说某个样本属于某个类别的时候，我们就给它贴上了离散的标签）

前者的模型输出一个具体的$y$，后者的模型输出一个概率分布$p^*(y|\bold{x})$，其中$\bold{x}$可以取第$1, 2, \ldots, C$个类别中的一个。

虽然在一般的分析中我们将分类问题的模型看成是带参数$y$的$f_y(\bold{x};\theta)$，由于分类问题中$y$只能取$C$种类别中的一个，完全可以把$f_y(\bold{x};\theta)$看成一系列互不相关的函数$f_1, f_2, \ldots, f_C$，它们中的每一个都输出了一个概率。最后输出的$y$其实是一个向量。

分类问题有一种简化情况，那就是**二分类**。这种情况下只有两个类别，所以我们完全可以把标签看成是$\{+, -\}$的二元对立（在某个类别中-不在某个类别中）这时没有必要使用$f_1, f_2, \ldots, f_C$形式的模型，只需要单个$f$就够了——我们可以让它输出一个实数值，实数值为正代表它可能是一个类别，为负代表它可能是另一个类别。

总之，我们有三种问题：回归问题、二分类问题、$C$分类问题（$C>2$）。

## 优化模型

一个好的模型应该在所有输入上都和真实情况一致，也就是，我们需要把误差控制在一个有限的量以下。

为了避免将复杂的不等式带入到讨论中，我们需要定义能够表征两个分布偏离情况的量。首先我们引入**损失函数**$\mathcal{L}(y, f(\bold{x};\theta))$来度量**单个样本**下模型的误差。我们要求损失函数非负，且在模型和实际情况没有偏差的时候取零。这样，就可以将损失函数的值加总，从而计算整个模型的误差。定义**期望风险**来衡量整个模型的误差：
$$
\mathcal{R}(\theta) = \mathbb{E}_{(\bold{x}, y) \sim p_r (\bold{x}, y)}[\mathcal{L}(y, f(\bold{x};\theta))].
$$
当然，我们实际上并不知道真实的概率分布，因此实际上我们只能够计算**经验风险**
$$
\mathcal{R}_D^\text{emp}(\theta) = \frac{1}{N} \sum_i \mathcal{L}(y_i, f(\bold{x}_i;\theta))
$$
如果我们想让模型尽可能准确，我们就要降低这个值。

### 损失函数的不同类型

不同的问题可以使用不同的损失函数。由于训练模型的时候需要让经验风险下降，我们就要写出损失函数的具体形式。我们一般使用常规的优化理论来做优化，那么损失函数的形式最好是足够光滑的。

标签属于不同的类型，损失函数也就取不同的形式。

在**回归问题**中，通常使用**平方损失函数**，即
$$
\mathcal{L}(y, f(\bold{x};\theta)) = \frac{1}{2} (y-f(\bold{x};\theta))^2.
$$
这样可以满足非负性要求，同时又让函数足够光滑。

在$C$**分类问题**中，可以把损失函数设置为实际概率分布和预测出的概率分布的**交叉熵**。设特征$\bold{x}$在训练数据集中对应的类别为$y\in \{1, 2, \ldots, C\}$，则训练数据集中给出的概率分布就是$\bold{y}=\mathbb{I}_y$，于是我们可以取
$$
\mathcal{L}(\bold{y}, f(\bold{x};\theta)) = - \sum_{c=1}^C y_c \log f_c(\bold{x};\theta)
$$
考虑到$\bold{y}$的定义，我们有
$$
\mathcal{L}(\bold{y}, f(\bold{x};\theta)) = - y \log f_y (\bold{x};\theta)
$$

在**二分类问题**中，我们可以使用**Hinge损失函数**，也就是
$$
\mathcal{L}(y, f(\bold{x};\theta)) = [1-yf(\bold{x};\theta)]_+
$$
由于$y=\plusmn 1$，很容易看出这个表达式的合理性。

### 最小化
现在我们已经有了损失函数，那么就要最小化损失函数了。最显然的看法是
$$
\theta^* = \argmax_\theta \mathcal{R}_D^\text{emp}(\theta)
$$
当然，在$D$大小足够大的时候结果会很好，因为经验风险和真实的期望风险非常接近。而如果我们将$D$的大小缩减到很小，那么统计学告诉我们，没有任何有用的信息能够从$D$当中提取出来。有趣的情况出现在$D$不非常大（以至于简单地最小化损失函数就能够找到合适的$\theta$）也不非常小（以至于没有足够的信息能够让我们找到合适的$\theta$）的情况。这时，$p_r(\bold{x}, y)$的主要特征仍然保留在了$D$当中，但是数据的波动也非常明显。此时简单地最小化损失函数不能够把$p_r$包含的信息提取出来。这个现象的原因在于，$D$中正常的波动可能被当成有用的特征，因此模型发生了**过拟合**。

通常（TODO：什么时候？），波动需要$f$取更复杂的形式去拟合，因此表现能力强的假设反而会导致过拟合，因为$\theta$可以取非常巧妙的配置来很好地拟合波动，而将真正重要的特征忽略。

实际工作中$D$可能并不大，而且混有噪声。那么，我们就不能够指望按照上面的方法产生的$\theta^*$代表了应该取的$\theta$。这时，损失函数可能有多个**极小值**，其中的最小值可能是过拟合的情况，而更大一些的极小值则可能是正确的结果。为了获得正确的结果而不是过拟合，我们需要在优化目标函数中加入一些项，让优化结果更接近正确结果。

通常我们假定**参数$\|\theta\|$越大，$f(\cdot;\theta)$越复杂。** 那么，我们可以在损失函数后面加上一个$\|\theta\|^2$项，使$\theta$不会太大而发生过拟合。于是，我们将最优化问题改写为
$$
\theta^* = \argmax_\theta \mathcal{R}_D^\text{emp}(\theta) + \frac{1}{2} \lambda \|\theta\|^2
$$
称
$$
\mathcal{R}_D^\text{struct}(\theta) = \argmax_\theta \mathcal{R}_D^\text{emp}(\theta) + \frac{1}{2} \lambda \|\theta\|^2
$$
为结构风险，计算$\theta^*$的方法为结构风险最小化准则。

### 损失函数和贝叶斯方法

考虑一个用于给数据贴标签的回归问题。记用于训练的样本为
$$
X = \{(y_i, \bold{x}_i) \},
$$
模型为
$$
\hat{y} = f(\bold{x};\theta).
$$
实际我们得到的样本通常含有一定噪声，即
$$
y = f(x;\theta) + \mathcal{N}(\sigma). 
$$
$\theta$本身在不同场景下可以发生变化，因此将它看成一个随机变量。这样
$$
p(y|\bold{x},\theta)  = \frac{1}{\sqrt{2\pi} \sigma} \exp \left( - \frac{(y - f(\bold{x};\theta))^2}{2\sigma^2} \right).
$$
如果认为$\bold{x}$和$\theta$的分布是独立的（这么想是不失一般性的，因为我们没有指定$\theta$到底是什么，把$\bold{x}$和$\theta$的分布当成独立的只会让模型学习到一个确实和$\bold{x}$的分布独立的$\theta$），那么就有
$$
p(y, \bold{x} | \theta) = p(y | \bold{x}, \theta) p(\bold{x}).
$$
做极大后验估计，即
$$
\hat{\theta} = \argmax_\theta p(\theta | X) = \argmax_\theta \frac{p(X | \theta) p(\theta)}{p(X)},
$$
$p(X)$和$\theta$无关；$p(X|\theta)$由
$$
p(X|\theta) = \prod_i p(y_i, \bold{x}_i | \theta) = \prod_i p(y_i | \bold{x}_i, \theta) p(\bold{x}_i)
$$
给出，而$p(\bold{x}_i)$和$\theta$也没有关系。这样，$\hat{\theta}$就可以这样计算出来：
$$
\begin{aligned}
    \hat{\theta} &= \argmax_\theta p(\theta) \prod_i p(y_i | \bold{x}_i, \theta) \\
    &= \argmax_\theta (\sum_i \ln p(y_i | \bold{x}_i, \theta) + \ln p(\theta)),
\end{aligned}
$$
代入正态分布表达式就得到
$$
\hat{\theta} = \argmax_\theta \left( - \frac{1}{2\sigma^2} \sum_i (y - f(\bold{x};\theta))^2 + \ln p(\theta) \right),
$$
显然，这就意味着损失函数应该取为
$$
\mathcal{L} = \frac{1}{2} \sum_i (y - f(\bold{x};\theta))^2  - \sigma^2 \ln p(\theta),
$$
认定$\theta$服从不同的先验分布，就可以得到不同的正则化项。正则化项会让$\theta$更加接近它比较可能出现的那些值。
例如如果有
$$
p(\theta) \propto \exp \left( - \frac{\|\theta\|^2}{2\tau} \right),
$$
即我们认为模型几乎总是简单的，那么损失函数就是
$$
\mathcal{L} = \frac{1}{2} \sum_i (y - f(\bold{x};\theta))^2 + \lambda \|\theta\|^2.
$$

### 对过拟合和欠拟合的定量分析——偏差-方差分解
为了以一种更加正式的方法分析过拟合和欠拟合，我们分析一个平方损失函数的回归问题。

$$
\mathcal{R}(f) = \mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[(y-f(\bold{x}))^2]
$$
先前我们使用一个形式确定的$f(x, \theta)$并且调节它的参数，所以风险函数可以写成$\theta$的函数，而现在我们使用更加一般的情况——任何一种模型都要考虑。

我们进一步认为$y$近似可以认为是完全由$\bold{x}$确定的，即
$$
y = \mathbb{E}_{y \sim p_r(y|\bold{x})}[y]+n,
$$
$n$代表噪声。

可以看出，
$$
f^*(\bold{x}) = \mathbb{E}_{y \sim p_r(y|\bold{x})}[y]
$$
能够让风险函数最小。为了证明这一点，我们考虑
$$
\begin{aligned}
    \mathcal{R}(f) &= \mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[(y-  f^*(\bold{x}) + f^*(\bold{x}) - f(\bold{x}))^2] \\
    &= \mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[(y-  f^*(\bold{x}))^2] + 2 \mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[(y-  f^*(\bold{x}))(f^*(\bold{x}) - f(\bold{x}))] + \mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[(f^*(\bold{x}) - f(\bold{x}))^2]
\end{aligned}
$$
第一项与$f$无关。第二项是零，因为
$$
\begin{aligned}
    \mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[(y-  f^*(\bold{x}))(f^*(\bold{x}) - f(\bold{x}))] &= \sum_{\bold{x},y} p_r(\bold{x}, y) (y-  f^*(\bold{x}))(f^*(\bold{x}) - f(\bold{x})) \\
    &= \sum_x p_r(\bold{x}) (f^*(\bold{x}) - f(\bold{x})) \sum_y p_r(y|\bold{x}) (y-  f^*(\bold{x})) \\
    &= \sum_x p_r(\bold{x}) (f^*(\bold{x}) - f(\bold{x})) \left( \sum_y p_r(y|\bold{x})y - f^*(\bold{x}) \right) = 0.
\end{aligned}
$$

由于
$$
p_r(\bold{x}) = \sum_y p_r(\bold{x}, y),
$$
第三项为
$$
\mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[(f^*(\bold{x}) - f(\bold{x}))^2] = \mathbb{E}_{\bold{x}\sim p_r(\bold{x})} [(f^*(\bold{x}) - f(\bold{x}))^2]
$$

我们定义
$$
\epsilon = \mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[(y-  f^*(\bold{x}))^2] = \mathbb{E}_{(\bold{x}, y)\sim p_r(\bold{x}, y)}[n^2]
$$

就得出

$$
\mathcal{R}(f) = \mathbb{E}_{\bold{x}\sim p_r(\bold{x})} [(f^*(\bold{x}) - f(\bold{x}))^2] + \epsilon
$$
于是取$f$为$f^*$就将风险函数最小化了。

实际的机器学习算法都是在有限大小的数据集上最小化风险函数，对数据集$D$给出训练结果$f_D$，则可使用不同数据集上风险函数的平均度量**机器学习算法的效果**。（下面的$\epsilon$可能和之前定义的有所不同，虽然两者正相关）

$$
\begin{aligned}
    \text{total error} &= \mathbb{E}_D \mathbb{E}_{\bold{x}}[ \mathcal{R}_D (f_D)] \\
    &= \mathbb{E}_D \mathbb{E}_{\bold{x}} [(f^*(\bold{x}) - f_D(\bold{x}))^2] + \epsilon \\
    &= \mathbb{E}_D \mathbb{E}_{\bold{x}} [(f^*(\bold{x}) - \mathbb{E}_D [f_D(\bold{x})] + \mathbb{E}_D [f_D(\bold{x})] - f_D(\bold{x}))^2] + \epsilon \\
\end{aligned}
$$
同样，展开括号，会发现交叉项为零，于是
$$
\text{total error} = \mathbb{E}_D \mathbb{E}_{\bold{x}}[(f^*(\bold{x}) - \mathbb{E}_D [f_D(\bold{x})^2] + \mathbb{E}_D \mathbb{E}_{\bold{x}} [(\mathbb{E}_D [f_D(\bold{x})] - f_D(\bold{x}))^2] + \epsilon.
$$
或者
$$
\begin{aligned}
    \text{total error} &= \text{bias}^2 + \text{variance} + \text{noise}, \\
    \text{bias}^2 &= \mathbb{E}_D \mathbb{E}_{\bold{x}}[(f^*(\bold{x}) - \mathbb{E}_D [f_D(\bold{x})^2], \\
    \text{variance} &= \mathbb{E}_D \mathbb{E}_{\bold{x}} [(\mathbb{E}_D [f_D(\bold{x})] - f_D(\bold{x}))^2].
\end{aligned}
$$
第一项是模型距离理论最佳值的**偏差**，第二项是模型在不同的训练数据集上的**方差**，第三项是无可设法的噪声。**偏差**表征了模型的**拟合情况**，偏差越小拟合越好；**方差**表征了模型的**泛化情况**，方差越小泛化越好。

现在我们知道为什么会过拟合了——不适当的算法让（往往表现力很强、什么都能够描写）的模型过度减小了偏差，而方差却太大了。增大训练数据集容量有助于减小方差，但是很多时候现实条件让训练样本数不够。

如果我们增大模型复杂度，那么偏差项会快速降低，而方差项降低得不甚明显，此时学习算法会主要倾向降低偏差项，从而在不同的训练数据集上非常精确地做拟合，结果就是过拟合（注意学习算法不会自行考虑泛化能力！）。反之，如果减小模型复杂度，偏差项难以降低，则学习算法会倾向于降低方差项，结果就是欠拟合。

### 优化算法

## 评估模型
Accuracy, precision, recall

Precision = true positive / (true positive + false positive)

Recall = true positive / (true positive + false negative)

A model with high precision rarely gives false positive predicts, and a model with high recall rarely gives false negative predicts. We may want a fingerprint recognition system to have high precision, while an HIV test should have high recall.

