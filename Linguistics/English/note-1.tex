\documentclass[UTF8, a4paper, oneside, scheme=plain]{ctexrep}

\usepackage{libertinus}
\usepackage{geometry}
\usepackage{float}
\usepackage{titling}
\usepackage{titlesec}
\usepackage{paralist}
\usepackage{footnote}
\usepackage[inline]{enumitem}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{gb4e}
\noautomath
\usepackage{bbm}
\usepackage{textcomp}
\usepackage{soul}
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage[ruled, vlined, linesnumbered, noend]{algorithm2e}
\usepackage{xr-hyper}
\usepackage[colorlinks, citecolor = purple]{hyperref} % linkcolor=black, anchorcolor=black, citecolor=black, filecolor=black
\usepackage[most]{tcolorbox}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[figuresright]{rotating}
\usepackage{acro}
\usepackage[round]{natbib} 
\usepackage{nameref,zref-xr}
\zxrsetup{toltxlabel}
\zexternaldocument*[alignment-]{../alignment/alignment}[alignment.pdf]
\zexternaldocument*[exercise1-]{../Exercise/2021-3}[2021-3.pdf]
\zexternaldocument*[method-]{../methodology/glossing}[glossing.pdf]
\usepackage{prettyref}

\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}

\DeclareMathOperator{\timeorder}{\mathcal{T}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\legpoly}{P}
\DeclareMathOperator{\primevalue}{P}
\DeclareMathOperator{\sgn}{sgn}
\newcommand*{\ii}{\mathrm{i}}
\newcommand*{\ee}{\mathrm{e}}
\newcommand*{\const}{\mathrm{const}}
\newcommand*{\suchthat}{\quad \text{s.t.} \quad}
\newcommand*{\argmin}{\arg\min}
\newcommand*{\argmax}{\arg\max}
\newcommand*{\normalorder}[1]{: #1 :}
\newcommand*{\pair}[1]{\langle #1 \rangle}
\newcommand*{\fd}[1]{\mathcal{D} #1}

\newcommand*{\citesec}[1]{\S~{#1}}
\newcommand*{\citechap}[1]{Ch~{#1}}
\newcommand*{\citefig}[1]{Fig.~{#1}}
\newcommand*{\citetable}[1]{Table~{#1}}
\newcommand*{\citepage}[1]{p.~{#1}}
\newcommand*{\citepages}[1]{pp.~{#1}}
\newcommand*{\citefootnote}[1]{fn.~{#1}}
\newcommand*{\citechapsec}[2]{\citechap{#1}.\citesec{#2}}

\newrefformat{sec}{\citesec{\ref{#1}}}
\newrefformat{fig}{\citefig{\ref{#1}}}
\newrefformat{tbl}{\citetable{\ref{#1}}}
\newrefformat{chap}{\citechap{\ref{#1}}}
\newrefformat{fn}{\citefootnote{\ref{#1}}}
\newrefformat{box}{Box~\ref{#1}}
\newrefformat{ex}{\ref{#1}}

% color boxes

\tcbuselibrary{skins, breakable, theorems}

\newtcbtheorem[number within=chapter]{infobox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=blue!5,
    colframe=blue!5,
    coltitle=blue!50,
    borderline west={4pt}{0pt}{blue!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}
\newtcbtheorem[number within=chapter, use counter from=infobox]{theorybox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=orange!5, 
    colframe=orange!5, 
    coltitle=orange!50,
    borderline west={4pt}{0pt}{orange!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}
\newtcbtheorem[number within=chapter, use counter from=infobox]{learnbox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=green!5,
    colframe=green!5,
    coltitle=green!50,
    borderline west={4pt}{0pt}{green!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}

% Shorthands
\newcommand*{\concept}[1]{\textbf{#1}}
\newcommand*{\term}[1]{\emph{#1}}
\newcommand{\corpus}[1]{\emph{#1}}

\newcommand{\redp}{\textasciitilde}

\newcommand{\deictictime}{T$_{\text{d}}$}
\newcommand{\referredtime}{T$_{\text{r}}$}
\newcommand{\orientationtime}{T$_{\text{o}}$}

\DeclareAcronym{blt}{short = BLT, long = Basic Linguistic Theory}
\DeclareAcronym{cgel}{short = CGEL, long = The Cambridge Grammar of the English Language}
\DeclareAcronym{dm}{short = DM, long = Distributed Morphology}
\DeclareAcronym{tag}{long = Tree-adjoining grammar, short = TAG}
\DeclareAcronym{sfp}{long = sentence-final particle, short = \textsc{sfp}}
\DeclareAcronym{np}{long = noun phrase, short = NP}
\DeclareAcronym{vp}{long = verb phrase, short = VP}
\DeclareAcronym{pp}{long = preposition phrase, short = PP}
\DeclareAcronym{advp}{long = adverb phrase, short = AdvP}
\DeclareAcronym{cls}{long = classifier, short = CLS}
\DeclareAcronym{dist}{long = distal, short = DIST}
\DeclareAcronym{prox}{long = proximate, short = PROX}
\DeclareAcronym{dem}{long = demonstrative, short = DEM}
\DeclareAcronym{classify}{long = classifier, short = \textsc{cl}}
\DeclareAcronym{dur}{long = durative, short = DUR}
\DeclareAcronym{neg}{long = negative, short = \textsc{neg}}
\DeclareAcronym{cc}{long = copular complement, short = CC}
\DeclareAcronym{cs}{long = copular subject, short = CS}
\DeclareAcronym{tam}{long = {tense, aspect, and mood}, short = TAM}
\DeclareAcronym{past}{long = past, short = PST}
\DeclareAcronym{nonpast}{long = non-past, short = NPST}
\DeclareAcronym{present}{long = present, short = PRES}
\DeclareAcronym{progressive}{long = progressive, short = \textsc{poss}}
\DeclareAcronym{perfect}{long = perfect, short = \textsc{perf}}
\DeclareAcronym{passive}{long = passive, short = \textsc{pass}}
\DeclareAcronym{copula}{long = copula, short = COP}
\DeclareAcronym{possessive}{long = possessive, short = \textsc{poss}}
\DeclareAcronym{coca}{long = Corpus of Contemporary American English, short = COCA}

\newcommand{\asis}[1]{\textsc{#1}}
\newcommand{\oneof}[1]{{#1}}
\newcommand*{\homo}[2]{#1$_{\text{#2}}$}
\newcommand{\category}[1]{\textsc{#1}}
\newcommand{\corpuscat}[1]{\textsc{#1}}
\newcommand{\emptymorpheme}{$\emptyset$}
\newcommand*{\fromto}[2]{\langle {#1}, {#2} \rangle}

\newcommand{\alignment}{\href{../alignment/alignment.pdf}{my notes about alignment}}
\newcommand{\exerciseone}{\href{../Exercise/2021-3.pdf}{this exercise}}
\newcommand{\method}{\href{../methodology/glossing.pdf}{this note about my understanding of descriptive grammars}}

\newcommand{\ala}{Ã  la}
\newcommand{\translate}[1]{`#1'}
\newcommand{\vP}{\textit{v}P}

% Make subsubsection labeled
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
% reset example counter every chapter (but do not include the chapter number to the label)
\counterwithin{exx}{chapter} 

% Reference formats
\renewcommand{\bibname}{References}
\setcitestyle{aysep={}} 

% List format
\setlist[enumerate,1]{label=\alph*\upshape)}

\title{Aspects of English morphosyntax}
\author{Jinyuan Wu}

\begin{document}
    
\maketitle

\automath

\tableofcontents

\chapter{Introduction}

\setcounter{page}{1}

TODO: contents I don't know where to put:
\begin{itemize}
    \item Causative use of motion verbs \citep[\citepage{103}]{dixon2005semantic}
    \item passivization
\end{itemize}

\section{The language and its speaker}

The modern English language is a West Germanic language,
with heavy Latin and Romance influence. 

The English language is arguably the most important language in the world,
taking factors like the number of both first and second language speakers,
geographical distribution,
the amount of written materials in it,
and the influence of English-speaking countries \citep[\citepage{3}]{quirk1985}.
The wild popularity of English 
makes it the default language in linguistics study,
both as the metalanguage or as the object language.
This work is aimed to give a theory-informed and unified overview of English grammar.


\section{Theoretical preliminaries}

\subsection{Motivation of this work}

This work is not a ``framework-free'' descriptive work.
Rather, it has a clear theoretical commitment.
Since I will use this theoretical framework from the first chapter to the last,
it's probably a good idea to outline the framework before everything else starts.

To make the narrative more smooth, 
I insert many boxes about the general principles of morphosyntactic structure building 
that look like this:
\begin{theorybox*}{Description of the content of the box}
\end{theorybox*}
\noindent These boxes can be safely ignored if you are only interested in English grammar itself.
For more ``substantial'' (as opposed to more formal) information,
like terminological issues or crosslinguistic comparison,
a box with a different style like the follows will be provided.
In a real descriptive grammar,
you may see contents in these boxes appear in introductory parts.

\begin{infobox*}{Description of the content of the box}
\end{infobox*}

In short, this note is based on Basic Linguistic Theory 
\citep{dixon2009basic1,dixon2010basic2,dixon2012basic3}
with generative flavor.
Here by the term \term{generative}
and especially \term{modern generativism}, 
I mean Distributed Morphology and Cartography
(but probably not Antisymmetry).
I'm fully aware of other frameworks,
like classical GB or HPSG, 
but again, I need to make theoretical commitments.

A well-known (unfortunate) fact about the generative enterprise is 
people tend to focus on fragments of languages,
and writing a systematic reference grammar in terms of modern generativism
seem unpractical.
I will not go over criticisms towards generativism -- 
readers can find lots of them in Dixon's works.
It's however my belief that the descriptive theoretical framework outlined by Dixon 
is largely -- if not completely -- compatible with modern generativism.
This note is partially intended as a demonstration of this idea.

\begin{theorybox}{About begin ``framework-free''}{framework-free}
    \citet{frameworkfree} argues we need framework-free description of languages,
    because each language has its own categories.
    The fact, however, is despite Haspelmath's perfectly logical criticism towards 
    constrained metalanguages -- be it \acl{blt} or generativism -- 
    the bad aspects seem to be acceptable for the current language documentation enterprise.
    (Just have a look at how similar the metalanguage used in grammars published by Language Science Press are.)
    This note is an attempt to summarize the basic ideas underlying 
    the successful frameworks and apply them to English.
\end{theorybox}

\subsection{Existing frameworks and their relations with generativism}

\subsubsection{Basic Linguistic Theory from a generative perspective}\label{sec:blt-generative}

The dictionary between generativism and Basic Linguistic Theory is roughly the follows:
\begin{table}[H]
    \caption{Correspondence between concepts in generative syntax and \acs{blt}}
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    Generativism                               & BLT                                          \\ \midrule
    phrase (DP, \vP, etc.) with specifiers     & dependency relations                          \\
    phrase without specifier                   & marking of grammatical category               \\
    specifier-complement relation of phrase    & grammatical relation (subject, object, etc.)  \\
    functional head                            & grammatical category                          \\
    several layers of co-occurring projections & constructions                                 \\
    root in Distributed Morphology             & head                                          \\
    a batch of spellout result                 & a phrase (verb phrase = \vP-TP-CP span) or word    \\
    phase (DP or CP)                           & word or constituent                           \\
    tree structure                             & order of ``closeness'' of dependency relations  \\
    movement                                   & dependency network                            \\ \bottomrule
    \end{tabular}
\end{table}

One important thing is Basic Linguistic Theory often recognizes 
the spellout of a functional projection 
as a phrase -- 
the spellout of the TP-\vP{} projections, 
for example, is Dixon's \term{verb phrase}, 
if there are multiple words in it.
Since in practice, if the TP-\vP{} projections are realized as affixes, 
we recognize them as a part of the word to which the affixes are attached,
then if the TP-\vP{} projections are realized as auxiliaries,
then calling the sequence of these auxiliaries as a phrase in the surface-oriented analysis 
isn't quite wrong.
(But it also means ``\acs{blt}-style'' constituency relations 
don't always reflect the order in which morphosyntactic devices are applied.)

Basic Linguistic Theory still assumes a constituency tree,
but it's a highly flat one:
The only levels are words, noun phrases and clauses.
Inner structures of these constituents are not represented as trees -- 
dependency relations are used instead:
Of course, there has to be some ways 
to take into account phenomena that are easily caught be a constituency-based analysis,
and even in works by Dixon himself,
we can find notions like ``the verb together with the object is modified by an adverb''
\citep[\citepage{376}]{dixon2005semantic}.
These differences in the notation are superficial:
We can see it's easy to translate between Basic Linguistic Theory 
and modern lexical-decompositional generative syntax
in the table above.
What Dixon calls ``underlying structure'' is actually ``syntax proper'' in generative syntax:
The former simply can't be the real semantic structure 
(\prettyref{box:negation-position}, \prettyref{sec:semantics-argument},
\prettyref{box:quantifier-position}).
\citet{dixon2009basic1} also firmly argues against the notion of functional heads,
but this may be from misunderstanding of what the notion of functional heads are supposed to catch:
introduction of each layer of grammatical relation or category slightly changes 
the syntactic properties of the structure.
This note is aimed to be comprehensible as a descriptive one,
so the notion of functional heads isn't emphasized,
but I will be fully aware of the fact that 
grammatical relations and categories are in a hierarchy 
about how ``close'' they are to the lexical head (i.e. the root).

\subsubsection{Constituency-based structuralism}

Another notable tradition is the structuralist tradition,
under which the most important recent work is probably \citet{cgel}.
Constituency trees in \citet{cgel} are more like generative trees,
but there are still differences.

First, the notion of head in \citet{cgel} is still not ``functional heads'' 
in modern generative grammar, but lexical heads similar to \citet{dixon2009basic1},
though \citet[\citepage{357}]{cgel} seems to want to achieve a compromise between lexical and functional heads 
and certain inconsistencies arise because of that (\prettyref{box:auxiliary-single-clause});
sometimes auxiliaries that are collective realizations of several functional heads 
are also recognized as heads in \citet{cgel}, 
and controversies like whether prepositions are heads then arise
(\prettyref{box:auxiliary-single-clause}).
And now since functional heads are removed,
the dependency relations introduced by these heads
now have to be introduced by adding a \emph{syntactic function} tag 
to every subtree in a tree
(the inner content of the subtree is the \emph{form}).
Thus ``the DP is in the specifier position of TP''
is replaced by ``the NP is in the subject position'',
and the tag of that NP in the tree is now ``subject: NP'',
not just ``NP''.

Second, dependency relations that can't be reflected by the surface tree structure are still required:
Since \citet{cgel} reduce the use of movements,
the relation between the subject and the main verb 
is said to be that ``the subject is the external complement of the verb phrase''
(here verb phrase means the verbal complex plus internal complements,
i.e. Dixon's verb phrase plus inner arguments).
And similarly prepositional phrases in noun phrases that are licensed by an adjective far from it 
are called ``indirect complements''.

The main problem of the approach in \citet{cgel} is 
if a constituent is broken by some further movements,
then it's impossible to draw a constituency tree that 
both respects the surface adjacency relations 
and the deep dependency relations.
It's impossible, for example, to talk about the verb phrase in a VSO language:
We know it's in principle to do so because
there are strong evidences suggesting there is a movement that fronts the main verb,
but writing a grammar in such a manner definitely will result in criticisms like 
``you are a language colonizer''.
Fortunately, this is not the case for basic constructions in English,
but even so we can still occasionally find cumbersome treatments of some constructions in \citet{cgel},
in which constituency analysis is done but it doesn't tell us much about 
how to generate correct utterances,
or linear order-based analysis is done while constituency relations are simply ignored.
(And a further inconsistency is \citet{cgel} stick 
to the notion of words as terminal nodes in the constituency tree,
so in the end it still has a little \acl{blt} flavor 
in that a span spellout is recognized as a unit.)
That's why this note is mostly carried out in terms of Basic Linguistic Theory.

Still, I think making the hierarchy structure of dependency (or constituency) relations clear 
is important,
so I will use the term \term{verb phrase} in the way of \citet{cgel} (\prettyref{box:verb-phrase})
and do a fine anatomy of clausal syntax (\prettyref{fig:clause-template})
instead of mixing all clausal grammatical relations together on the same plane.

\cite{cgel} also keeps a strict complement-modifier 
(they use the name \term{adjunct} for clausal ones) distinction.
Some constituents -- like the negative adverb \corpus{not} or \corpus{rarely} -- 
are claimed to modify a lexical head (say, a verb),
but that ``modification'' actually changes 
both the syntactic and semantic properties of the whole structure drastically.
Some modifications, like ordinary adverbs,
change the properties of the modified structure more slightly,
but still there is a strong tendency of the relative order of these modifications,
and each modification, therefore, still changes the syntactic property 
about what further modifications are possible.
For convenience, the complement-modifier distinction will appear in this note,
but I will be fully aware of relevant phenomena
and do away with the notion of 
``freely added adjuncts or modifiers fundamentally different from complements'' (\prettyref{box:tp}).

To summary, the relation between the three formalisms are shown in \prettyref{fig:three-formalisms}.

\begin{figure}[H]
    \centering
    \input{trees/formalisms.tex}
    \caption{The relation between the three formalisms;
    \acs{cgel} means the framework outlined in \citet{cgel},
    and \acs{blt} means the framework outlined in \citet{dixon2009basic1}}
    \label{fig:three-formalisms}
\end{figure}

\subsubsection{Notes on psycholinguistic reality}\label{sec:psycho-real}

Though in the above discussion, 
I interpret the dependency relation-based approach in \acs{blt} 
and the constituency trees labeled by form-function pair in \citet{cgel}
as coarse-grained trees in generative syntax,
ironically, it may be the case that 
it's \emph{these surface-oriented notions} that 
are close to what really happens in our mind 
when we speak
(and hence have significance in analyzing change of morphosyntax).
Generativism -- and Merge-based Minimalism -- arose to explain acceptability judgement,
but it doesn't mean Merge is invoked \emph{whenever} we talk or read or write,
and the structure-building mechanism in real world language use 
may be like Tree-Adjoining Grammar,
and what are stored in the brain 
are pre-built trees
\citep{brain-syntax-1,brain-syntax-2}.

\subsubsection{Previous study on the dependency-constituency equivalence}

The correspondence between dependency relations and constituency relations 
has been noticed (independently?) 
both within Minimalism
\citep{schneider1998linguistic,osborne2011bare,kobele2021minimalist}
and out of it \citep{kahane2015syntactic}. %TODO: https://languagelog.ldc.upenn.edu/nll/?p=48725
Note that practically, dependency relations see more usages in 
the natural language processing community,
as an annotation formalism or as a tool 
for interpretation of what a network learns \citep{chi2020finding}.
Joint effort of the linguistic community and the deep learning community
has been called for \citep{pater2019generative} 
but is still largely lacking.
This topic, of course, is far beyond the scope of this work.

\subsection{Morphosyntax}

Having reviewed previous frameworks in language description,
now I outline basic guidelines concerning how to analyze language structures.

\subsubsection{Organization of grammar: from the lexicon to linguistic structures}\label{sec:orgianization-of-grammar}

This note is aimed to reveal the bottom-up structure building machine of grammar,
and the latter is unavoidably related to the discussion on the lexicon.
On the other hand,
the characterization of parts of speech and derivation is important for well-organized lexicography.

The formation of utterances starts with roots, 
which vaguely express an object or an action or a state,
and in principle are without any word class categorization 
\citep[\citepage{13}]{greenough2013allen},
though usually depending on the meaning,
most of roots have strong preferences to be the core of nouns or verbs or adjectives or maybe two of them.
These roots may be combined with existing structures,
be combined with grammatical items like affixes,
and receive their category label like nouns or verbs at a certain stage.
Note that here I assume categorization happens \emph{after} some kind of morphological derivation,
because we actually have so-called verb-centered compound adjectives
(\prettyref{sec:pos.noun.compound.verb-centered}).
This progress goes on to form phrases and clauses,
with largely the same structure building mechanisms:
Grammatical items attached now are function words,
and category labels are ``complete \acs{np}s'', ``nominals'', ``finite/nonfinite clauses''.

From a generative perspective, 
affixation, merging with function words, etc. 
happen when a functional projection without a specifier is formed,
while compounding, selecting complement, modification 
happen when a functional projection with a specifier is formed
-- so it's frequent that in the latter processes,
there are affixation on the lexical head (i.e. the ``complement'' in the generative X-bar scheme).

Two things complicate the above process. 
Each step the structure assembled may receive an established meaning,
rendering compositional semantic interpretation invalid.
Another phenomenon is 
an expected phonetic realization of a structure 
may be replaced by a ``fused'' realization:
For example, instead of \corpus{*go-ed}, we have \corpus{went}.

Thus, ideally a dictionary should contain three aspects of information.
The first aspect is about available roots and important grammatical concepts
(tense, aspect, number, gender, case, word class labels like noun/verb, etc.),
and their mutual compatibility.
The second aspect is about how these roots and grammatical concepts are substantialized:
The verb nominalization process involves the suffix \corpus{-tion} or sometimes \corpus{-ing}, etc.
The third aspect is about established structures and their meanings:
The structure \corpus{[fire-man]_{\text{compound}}} 
is a compounding structure,
with \corpus{man} being the lexical head and \corpus{fire} being the modifier,
but it doesn't mean \translate{any man who has something to do with fire},
which is the aboutness interpretation of compounding 
(\prettyref{sec:pos.noun.compound}),
but has a fixed meaning: \translate{a firefighter}.
So it deserves its own dictionary entry.
A grammar written in the ``everything is about usage of parts of speech'' format, 
as is mentioned at the beginning of this chapter,
is an abbreviated version of this kind of dictionary.

In Distributed Morphology,
the three aspects are the three lists in the lexicon:
List A or abstract features and roots,
List B or the Vocabulary Items that are inserted when a structure is phonetically realized,
and List C, the Encyclopedia, recording the established meaning of a complex syntactic object.

Of course, no one would write a dictionary like this.
In practice, abstract features,
or in other words,
available grammatical categories and how they are realized -- like affixes -- 
are often left for another book about grammar.
Roots are presented as the simplest categorized surface form of them.
Complex structures with established meanings (specified in List C) 
should have their own dictionary entries,
and what is recorded is usually not the abstract feature structure but the phonetic realization.
Thus, \corpus{in spite of} deserves a dictionary entry;
we know it's better to analyze it as a template of 
a hierarchical structure \corpus{in [spite [of $x$]]}
\citep[\citepage{620}]{cgel},
but in most dictionaries the constituency relations (or equivalent dependency relations)
are simply ignored.
Another case is verbal idioms or ``phrasal verbs'' \citep[\citepage{273}]{cgel}.
Note that this also demonstrates a dictionary entry 
is not necessarily a constituent in the generative sense.
(Of course, a dictionary entry that is a span spellout and is commonly recognized as a word, 
like \corpus{went}, is also not a constituent.)

Since most structures with established meanings 
are also phonologically units,
they are presented as ``words''
(or to be more exact, \term{lexemes}, 
because usually only the principal forms are given in the dictionary,
the rest inflectional forms are left for the grammar to discuss),
though it's impossible to draw a one hundred percent clear line 
between words and phrases (\prettyref{sec:wordhood}).
Sometimes the line is drawn simply by orthography.
Discussion on parts of speech is therefore usually about word classification,
and not abstract feature structures.
There are still structures much larger than the usual concept of ``words'' 
with established meanings or even non-standard syntax,
just like words may have inner structure that is only historically analyzable
(as in, say, the archaic \corpus{till death do us part} that is still used today) -- 
they are documented as idioms or formulaic speech,
and may be left for another book.

The position of this note is there is only one structure building engine in grammar:
the syntax proper.
There is no such thing as a separate morphological component in the lexicon.
Of course, this doesn't mean there is really no difference at all 
between semi-productive morphology and 
fully productive syntax:
Semi-productive processes 
are modeled as ``fossilized'' processes:
The functional heads, etc. involved in this process 
are stored in some dusty corners of List A,
with little interaction with the rest of the features and roots,
and their products have limited inner details exposed to further morphosyntactic processes.
Of course, fossilization has several stages:
a fossilized construction created by a fossilized process 
be totally historical and no longer analyzable in contemporary morphosyntax,
or analyzable in contemporary morphosyntax but already with an established meaning,
or compositionally analyzable but the relevant process is limited in productivity.
In this perspective, 
the paradigm of a word -- which a native speaker can recall without thinking too much -- 
is somehow similar to a phrase with established meaning (like, say, the cleft construction),
and this claim seems to have some psycholinguistic support
\citep[\citepages{polinsky2018}]{polinsky2018}.

\subsubsection{Determining parts of speech}\label{sec:pos}

Parts of speech in this note are mainly determined 
by morphosyntactic tests of both form and syntactic function,
like the standards listed in \citet[\citesec{3.3}]{dixon2009basic1}.
Despite Dixon's strong opinion against the generative or ``formalist'' approach,
his criteria for word classes don't go against generativism,
because what are taken for granted in generative syntax 
is not concrete, surface-oriented labels like ``English-like nouns'' or ``Latin-like verbs'', 
but labels like the noun categorizer, the verb categorizer,
the light verb heads, \acs{tam} heads, etc.,
and the allowed combinations of them, 
like whether a noun is able to replace the main verb in a clause 
(which may be realized by a \category{be} light verb, or something else)
are definitely language-specific:
Some combinations just don't spellout in one language,
but spellout well in another.
I claim tags like nouns or verbs are universal,
because my guess is the relevant functional heads are available for all human beings.
The behaviors of \emph{concrete} nouns differ cross-linguistically
because the noun categorizer interacts with other ingredients differently.

\begin{theorybox}{The notion of \term{comparative concepts}}{comparative-concept}
    People like Haspelmath may say the universality of \term{noun} 
    is a ``comparative concept'' and is rooted in communicative functions of language.
    The problem with the first claim is its ignorance of equivalence between 
    two ways to formulate a grammatical theory:
    One is to use primitive concepts to construct larger objects,
    and the other is to show the relation between the larger objects.
    Modern generativism is done in the first way,
    while ``comparative concepts'' belong to the second approach.
    They are mathematically equivalent,
    and asserting there are useful comparative concepts 
    is equivalent to asserting the existence of primitive features.
    (This is, of course, true for a theory of \emph{competence};
    a theory about psycholinguistic reality and \emph{performance} is another story.)

    The problem with his second claim is the domain of 
    the so-called domain general communicative functions 
    are actually narrow.
    To express the concept do some action to something,
    you don't really need a noun-verb distinction:
    In functional programming, which is created by the domain-general problem solving skills by the human race,
    everything is a function -- or maybe a ``verb'',
    yet you never find a group of people speak like this.
    And similarly the TOML format is a concise way to communicate facts,
    while still you never find a tongue with such a structure,
    though it's understandable using our domain-general cognitive abilities.
    Sometime semantic information that \emph{are} recognized by people,
    like the scope of quantifiers, 
    are not reflected in their speech explicitly.
    So the object -- the collection of so-called communicative skills -- 
    that Haspelmath's comparative concepts work on 
    is not semantics or pragmatics,
    and this object only appears when people choose to ``talk'' or ``sign'' or ``write''
    -- not when they are solving puzzles.
    This target of Haspelmath's comparative concepts therefore has to be the \emph{syntax proper}.
    Only in it do we constantly work with things like the verb and its arguments,
    noun phrases, etc., 
    which, if understood as semantics and pragmatics,
    are malfunctioning in some aspects
    and can be recast into equivalent formalism,
    yet people are content with the former 
    and never do the latter.
    Note that the above discussion is about the abstract structure building devices,
    and even for concrete grammatical categories,
    there are evidences suggesting their innateness \citep{satik2022cartography}.
\end{theorybox}

That means I don't use terms like \term{noun clause} or \term{adjective clause},
because what they mean are clauses filling argument slots, 
clauses filling attributive slots, etc.,
and these clauses are similar with nouns and adjectives in their syntactic functions 
but not their internal forms,
so they are not nouns or adjectives.
I will also avoid paying too much attention to the semantics of a word,
because the same semantics can be expressed in several ways in the grammar,
and the focus of this note is the latter.

Purely grammatical items, like auxiliary verbs, inflectional suffixes, determiners,
don't really need part of speech tags:
They are added by the grammar and are phonetic realization of grammatical categories and relations,
or in generative terms, phonetic realization of functional heads.
\citet{cgel} still assigns part of speech tags for grammatical items,
but that's not the position of this note.

\subsubsection{The notion of \term{word}}\label{sec:wordhood}

It's impossible to establish an uncontroversial definition of the term \term{word}.
Phonologically we can define a word as a unit in the utterance
that has clear pauses as its boundaries and 
whose inner makeup is targeted by phonological rules much more frequently
than larger units \citep[\citesec{10.3}]{dixon2010basic2}.
The problem is such a unit sometimes doesn't bear any morphosyntactic significance:
It may contain two morphosyntactic words,
it may be just a part of a morphosyntactic word,
or it may even be the combination of two segments from two different morphosyntactic words.

We can also recognize morphosyntactic words. 
The definition given by \citep[\citesec{10.4}]{dixon2010basic2} is:
\begin{enumerate*}
    \item a unit that is made of one or more roots and morphological processes, and
    \item has a conventionalized meaning, and
    \item is unable to have its parts scattered through the clause,
    \item and have relatively strictly ordered inner components.
\end{enumerate*}

The problem then is the standards conflict with each other,
and they are also true for some constructions that clearly are not words.
\begin{enumerate*}
    \item A root-plus-morphology construction 
    can be created in the syntax,
    as in Chinese verbal resultative or directional complement constructions.
    \item Phrases can have conventionalized meanings as well,
    especially in specialized fields.
    \item Speakers are sometimes aware of the inner parts of words 
    and occasionally split them in the syntax,
    as in \corpus{pre- and post-processing},
    while on the other hand,
    some orthographical multiple word constructions 
    are also not active in syntax,
    like \corpus{apple tree} or \corpus{American history teacher},
    but people usually don't say they are words.
    \item As syntactic cartography shows,
    in many languages syntax is much more ``rigid'' then we previously thought,
    and it's also possible to have words in which a part of affixes are not in a completely rigid order
    (with a difference in the meaning, obviously, but the same is also true for syntax).
    The fact that functional heads are often realized as affixes on one word
    also poses a bracketing dilemma:
    \corpus{American history teachers} should be syntactically partitioned as 
    \corpus{[American history teacher]-s},
    but this goes against the common sense conception of the construction.
\end{enumerate*}

From the Distributed Morphology perspective,
this is expected.
Morphosyntactic words recognized by the above criteria 
are sometimes small phrases
(as in \corpus{American history teacher}, 
the grammar of which is about grammatical relations 
as is mentioned at the end of \prettyref{sec:morphology-meaning}) 
and sometimes span spellout of a functional projection
(the grammar of which is about inflectional pattern 
as is mentioned at the end of \prettyref{sec:morphology-meaning}).
Both constructions have phrasal counterparts (\prettyref{sec:blt-generative}).
The first has no substantial difference with a, say, subject-predicate structure,
and the latter has no substantial difference with a syntactic constituent or 
a sequence of auxiliary verbs
(``verb phrase'' in the definition of \citet{dixon2009basic1}).

It seems, then, 
it's better to define a morphosyntactic word as the \emph{smallest} unit 
that has some of the above properties,
as a layer in \prettyref{fig:clause-template}.
After introducing this concept,
we can split the burden of describing morphosyntactic 
into several chapters about ``morphology''
and several chapters about ``syntax'',
and the grammar will be very organized 
for someone who just wants to read at least \emph{something} about the language 
before figuring out the grand general structure.

Some say we can define the morphology-syntax distinction based on speech production -- 
there are generally less speech errors in the morphology component,
the morphology component is more ``automated'', etc.,
but this also doesn't go beyond the ``word as small syntactic constituent'' definition 
or the ``word as phonologically processed constituent'' definition,
because trivially, small constructions are easier to fossilize.

In conclusion, the notion of \term{word} is a good descriptive concept
if defined with a few clear criteria,
but we shouldn't put too much theoretical emphasis to it.
And definitely we shouldn't talk about ``categorical differences between words and phrases'' 
\citep{bruening2018lexicalist}.

\subsubsection{The exact meaning of \term{morphology} and \term{syntax}}\label{sec:morphology-meaning}

In generative syntax, the subject-auxiliary inversion is usually attributed to 
a T (or other functional heads)-to-C movement.
This notion reminds us the inherent vagueness of the term \term{morphology} in linguistic description:
If we equate \term{morphology} with the stuff about post-syntactic operations 
i.e. \emph{details of how a syntactic tree is realized},
then definitely the subject-auxiliary inversion is a part of morphology.
This claim, however, is too outrageous for descriptive linguistics.

It's better to say there are two dimensions 
when we divide the grammar of a language into parts,
one is the structure-realization axis,
the other is the word-phrase axis
(just mentioned in \prettyref{sec:wordhood}).
The structure-realization axis is about 
whether a part of grammar is about abstract categories, dependency relations, constituents, etc. 
or just the linearization i.e. surface realization of the above.
Note that the first part -- constantly called the underlying structure by \citet{dixon2009basic1} 
-- is still not the semantic structure,
because the same semantic concept can be realized by several structurally heterogenous constructions.
The word-phrase axis has its own vagueness,
because the phonological standard of wordhood 
(how easily a construction undergoes internal phonological processes 
compared with its interaction with the neighbors)
and the morphosyntactic standard of wordhood 
(how small a construction is)
don't always agree (\prettyref{sec:wordhood}).

In traditional grammars,
morphology and syntax are discussed separately,
and the morphology-syntax distinction is made according to the word-phrase distinction.
Since words may be mini-phrases on their own or exponents of a span of functional projections,
this means too many largely independent concepts are mixed into the same chapter.
For example, verb morphology in this sense includes 
the marking of \acs{tam} categories 
(which, in the perspective of the abstract, underlying structure of syntax, 
belongs to the clause, not the verb),
synchronic verbal derivations 
(which is essentially syntax within the verb -- a good example is \citet{de2019negation}),
and historical verbal derivations 
(patterns in the lexicon),
and a reader uninterested in the details of conjugation classes 
has to painfully search for a while before he or she finds 
whether the language in question has future tense.

The wisest idea therefore may be the follows:
Instead of the vague and cumbersome morphology-syntax division,
we divide the grammar into the following parts.
The first part roughly corresponds to ``inflection'' 
but includes periphrastic constructions.
This part deals with how functional categories 
(especially those that are kind of obligatory) are attached to 
-- phonologically or syntactically -- a noun/verb/adjective/\dots{} root.
In generative terms, it's the syntax of the supine of functional projections.
The second part roughly corresponds to ``grammatical relations''
or simply ``syntax'' in older grammars.
It's about how other constituents are linked to the complex mentioned in the first part.
In generative terms, it's the syntax of specifiers (SpecTP = subject, SpecTransP = object, etc.).
The third part -- in principle optional but in practice always needed -- 
is about ``transformations'', or maybe ``derivations'' 
-- note that transformations are no longer used in contemporary generative syntax 
and derivations are used simply as a synonym for ``structure building'' -- 
about how a construction is related to a more canonical one.
(It's always the case that transformations miss some subtle differences between the two constructions,
and that's why transformations are no longer recognized as primitive concepts in generative syntax.
Also, transformation-based account is awkward 
when the key point of a construction involves some highly semantic operations 
(\prettyref{box:valency-changing})
Do this with care.)
An optional fourth part is devoted to historical forms,
usually called \term{derivations} of words 
(not that \term{derivation} in the third part above!).

This is not always used in actual grammar writing,
but it's important to have this division of labor in mind.

\subsubsection{Locality in grammar}

Both the syntax proper and its interface with other cognitive components 
show a strong tendency to make things local.
This fact is captured by the phase theory when it comes to the syntax proper.
Once a functional head is merged into a tree 
-- or, in other words, once a certain grammatical category or relation is involved -- 
the part of the tree below it becomes no longer syntactically active.
The construction is ``sealed'' by the merging of the ``phase head''.
This can be observed in several semantically unrelated phenomena:
impossibility to move an \acs{np} out of a finite complement clause (TODO: ref);
nominal gerund is much regular than other nominalization devices 
(\citealt[\citepage{11}]{embick2010localism}; TODO: ref). %Enumerating

Locality at the interfaces is also important,
and may be used to make sense of some constraints 
that are awkward to account for if we insist on purely syntactic explanations.
Indeed, selection, 
like subcategorization of verbs or mutual compatibility of auxiliaries and/or affixes,
can largely be accounted for by spellout-related mechanisms:
We may say a transitive verb can only be spelt out 
together with a ``Trans'' functional head,
whose specifier is the object. 
Of course, there may be other Trans heads in the clause,
but they are far from the verb in question and therefore don't lead to overgeneration.
Note that the realization favored by the locality condition at the 
syntax-PF interface may blur the underlying syntactic structure:
this again can be seen in several semantically unrelated cases. %Enumerating

\subsubsection{About gradience}

An important theoretical issue with difference between the generative tradition 
and the descriptive tradition (the \acs{blt}'s approach or the structuralist approach)
is gradient acceptability in syntax.
But gradience of acceptability, 
even when irrelevant to non-linguistic factors, 
can be captured in a theory with hard structures,
using techniques like competing grammars with different rates.
(For readers with physics background,
recall that the output of a model with discrete degrees of freedoms 
-- most frequently a spin model -- is also continuous,
but that doesn't mean there is no discrete structure in the theory.)

Another type of gradience comes from deviation of a construction
from prototypical form classes,
like, say, the derivation of \corpus{near} from prototypical prepositions.
This does not come from uncertainty in grammar itself, 
but the inability of the grammar writer:
Occurrence of this kind of gradience means 
in principle we need a series of more fine-grained form classes 
-- and if they are extremely fine-grained, they are essentially \emph{features},
as in generative syntax --
to capture the behaviors of these constructions.

\subsubsection{Relation with Construction Grammar}

Readers may have found the framework outlined above dubiously similar to Construction Grammar.
That's correct.
The main difference between the framework of this note and orthodox Construction Grammar is 
I still think an established construction 
has analyzable inner structure 
subject to the constraints and conditions in generative grammar.
In the language of Construction Grammar,
the inner structure of constructions and how constructions are linked are more constrained 
in the view of this note.

\subsection{Semantics}\label{sec:semantics}

\subsubsection{Semantics has ``side effects'' and is related to pragmatics}\label{sec:semantics.side-effect}

The last topic I discuss here is semantics.
This note doesn't take a strict truth-value semantics position
(but compositionality can still be kept,
although now each part of the utterance should be considered as a function 
mapping a conversational context to another,
instead of a pure expression).
Rather, I treat natural languages like \emph{imperative programming languages} here,
regarding each utterance as a command that changes 
the context in the mind of the speaker/writer and the listener/reader.
For example, in pure logic, 
a variable bound by a quantifier never appears outside the scope of the quantifier.
So when we talk about the interpretation of 
\corpus{[Some students]_{i} are rather frustrated by the new policy. 
[They]_i are protesting outside for their rights.},
we have two choices.
We may consider the two sentences as \emph{one} sentence
and regard the anaphoric \corpus{they} as a partial spellout 
of an \acs{np} already appearing before
and there is some sort of ``LF extraction'' so that the whole utterance is interpreted as 
\translate{$\exists x (x \subseteq \text{the-students-in-question} \  
\land \forall y (y \in x \rightarrow \text{$y$ is frustrated}) )
\land \text{$x$ are protesting outside} $} 
(the two conjunction branches need further interpretation).
The second approach, a less tedious%
\footnote{
    Of course, experts in formal semantics 
    will tell you that the side-effectful approach 
    can always be reduced into a side-effectless approach,
    and the mathematical structure underlying is remarkable.
    But here we are just finding one handy tool for language description,
    and if the contextualist way works well, 
    then it's good to use.
}
formalism, is to assume utterances have \emph{side effects}:
So if an \acs{np} appears in one utterance, 
its reference is pushed into an ``old information'' recourse list,
and when a pronoun appears in a following utterance, 
the listener/reader searches for a plausible entry in the recourse list 
and interpret this as the reference of the pronoun (\prettyref{sec:np.semantics}).

We may also conceive this as a default $\exists$-elimination:
When I hear \corpus{some students are rather frustrated by the new policy},
I interpret this by turning it into 
\translate{$\exists x (x \subseteq \text{the-students-in-question} \cdots)$},
but then I immediately apply the $\exists$-elimination rule 
and add a variable $a$ to my memory such that 
$a$ is a subset of the students in question and \dots
Similar processes happen when I interpret an object \acs{np}.

The second approach, i.e. the side-effectful,
will be followed thorough this note.
Note that reliance on the context also means the boundary between semantics and pragmatics 
is somehow blurred.

\subsubsection{Semantics and syntax have non-trivial relation}\label{sec:semantics-argument}

To illustrate the claim in the title of this section, note that
it's often said that the argument structure is semantic, 
and the semantic relations are coded as syntactic relations like subject or object
\citep[\citepage{111}]{dixon2005semantic}.
Here we need to note that ``argument slots'' or ``semantic roles'' \emph{in syntax}
is not the same as the semantics of an argument slot \emph{in logic},
and therefore,
we actually need a three-step process to describe how a semantic verb-argument concept 
is coded as syntactic relations:
The first step is about purely semantic concepts,
the second step about ``syntactic semantic roles''
(or \term{$\theta$-roles}, though this jargon isn't accepted among descriptive linguists),
and the third step is about clausal dependent positions 
(\prettyref{sec:valency.overview.steps}).

Consider the sentence: \corpus{John didn't drive that night}. 
It's the negation of a usual predicate-argument structure
-- but what kind of \term{predicate}?
Can you find a predicate with the time specified in a logic textbook?
Definitely not. 
The word \corpus{drive}, despite being called a predicate (or \term{predicator}) in syntax,
is \emph{not} a predicate in the sense of logic.
The correct semantic interpretation of the sentence should be 
\translate{It's [not] the case that there is an event $e$, such that
[$e$ happens at that night], and [$e$ is about driving], 
and [John is the agent in $e$]} \citep{zeijlstra2013}.
Three predicate-argument structures occur in the interpretation.
None of them is ``drive''.
And there is an argument -- the ``event argument'' --
which is described by the the whole sentence but (of course) 
never appears in any of the \emph{syntactic} argument slots.
The \emph{syntactic} structural information,
like that \corpus{John} is somehow higher than the verb \corpus{drive} in the clause,
also receives no representation in the semantics of the sentence.
The conclusion is syntactic structures encode semantic information,
but the mapping isn't trivial:
Similar concepts, like \term{predicate} or \term{argument position},
have different meaning in syntax and in semantics, and 
some structural information -- like c-command effects as in pronoun binding --
helps us interpret the sentence correct,
but it doesn't appear in the final semantic representation 
(with the help of formal semantics, like $\lambda$ expressions,
we are still able to assign a semantic interpretation to each subtree in the sentence,
but see \prettyref{sec:semantics}),
and some semantic information, like the existence of the event argument,
doesn't appear explicitly in at least the PF, 
and whether it's introduced in the syntax proper depends on 
your take about how much burden the syntax proper should shoulder.

The position of this note is to make the syntax proper as natural and plausible as possible,
following the guidance of Minimalism.
Semantic and pragmatic factors are favored 
when accurate account for a phenomenon seems to 
require ``monster syntax''.

Although I will discuss semantic classification of words following \citet{dixon2005semantic},
I still don't follow a completely semantics-based approach,
and follow the Y-model often seen in generative syntax instead:
The main advantage of this approach 
is sometimes, clear syntactic patterns are not motivated by semantic considerations,
as can be found in idioms and \acs{tam} marking.
Thus, to say that first a syntactic structure is built 
and \emph{after that} it's connected to semantics 
is of descriptive and explanational value.
This Y-model of course says nothing about the implementation:
It's of course highly likely that the semantics part of the brain 
guides syntactic structure building.

\subsubsection{There are more than one layer of semantics}

A final remark concerning semantics is,
when people talk about semantics, 
they are talking about quite different things.
At least three layers of ``semantics'' can be distinguished:
\begin{itemize}
    \item The syntax-semantic interface,
    or how syntactic features are mapped to semantic expressions. 
    When we say ``the semantic interpretation of the past tense 
    is $\text{R} < \text{S}$'',
    we are talking about semantics in this level.
    What are different in this level may be equivalent in the next layer,
    after some lines of logical reasoning:
    A clause in a tenseless language 
    is by definition different from a clause in a language with a tense system 
    semantically in the sense of this level, 
    but they may also be the same semantically at the next level
    if temporal adverbials in the first clause covers the $\text{R} < \text{S}$ meaning.
    contain 
    \item The meaning of a syntactic unit 
    after semantic processing, like logical inferences, etc. 
    Change of the scope of negation 
    is likely done in this layer: 
    Since \corpus{I don't think this is the case} 
    refers to a situation that isn't far from \corpus{I think this is not the case},
    we say the scope of \corpus{not} is expanded,
    but this is not done by syntactic processes:
    It's logical inference that is the key point here
    \citep{zeijlstra2018does}.
    \item The ``real-world'' semantics, 
    which is about how people conceptualize what they see and undergo everyday.
    When we say there are \category{affect}-type verbs or \category{motion}-type verbs, 
    we are dealing with semantics at this level.
\end{itemize}

\section{About this work}

As is said above,
this work is aimed to give a theory-informed and unified overview of English morphosyntax,
in which analysis of one part of the grammar is determined by the rest of the grammar.

\begin{infobox}{About the ``holistic'' view of gramar writing}{holistic}
    An unfortunate fact about contemporary generative linguistics -- 
    and pretty much all theoretical approaches to linguistic analysis -- 
    is they are paper-based,
    and one paper only targets one explanation for one phenomenon.
    Few are willing to sit down 
    and review these (often mutually incompatible) components 
    and assemble them into a comprehensive grammar. 
    This fact pushes some to argue in favor for a ``holistic'' view of grammar writing,
    in which a construction is never taken out of its context 
    and all things are wired together.
\end{infobox}

\subsection{Previous studies}

This work heavily consults the following existing grammars or grammar sketches of English:
\citet{cgel}, \citet{dixon2005semantic}, \citet{quirk1985}, TODO: list 
I essentially declare \emph{no} real originality here: 
This work is intended as a companion to these great books.
(All mistakes, of course, remain mine.)

\subsection{Organization of chapters}\label{sec:introduction.organization}

\subsubsection{Guilding principles}

This note is intended to resemble a usual descriptive grammar 
once all theory-oriented boxes are removed.
The working procedure of this work is outlined as follows.
I start with a system (say, the whole grammar, 
or the clause structure,
or the verb-argument relations in the clause)
and casually list some of its subsystems and their possible values
(respectively, they are nouns and verbs and their phrases; 
verbal complex, arguments, information packaging strategies;
the steps from semantic argument structure to clausal dependents).
This list is then extended as I increase the coverage of examples of the system in question,
until I decide it is long enough to contain all descriptive parameters I need.
This step results in an overview chapter or section
(\prettyref{chap:overview}, \prettyref{chap:simple-clause}, \prettyref{sec:valency.overview}).
Then I try to enumerate the possible values of these parameters 
and their compositional possibilities,
and thus enumerate over all possible configurations of the system in question
(all chapters after \prettyref{chap:overview}, 
chapters about the verbal system before \prettyref{chap:simple-clause},
and the rest of \prettyref{chap:valency}).
Of course, very frequently, it takes the completion of one chapter 
to decide descriptive parameters of a larger system.
This process can be repeated over and over again,
focusing different systems with different sizes.

\subsubsection{The order of chapters chosen in this note}

I roughly follow the structure of, say, \citet{Friesen2017},
and carry out the note with five main parts.
(The part about phonology is skipped,
because it doesn't play a very important role in English morphosyntax,
though when we document a previously unknown language,
there has to be a chapter or two about it.)

The first part is \prettyref{chap:overview} and \prettyref{chap:pos}.
\prettyref{chap:overview} gives some typological information and macroscopic topics,
while \prettyref{chap:pos} covers the most microscopic topics.
The second part is \prettyref{chap:np}, %Enumerating: nominal system
which covers the nominal system.
The third part goes from \prettyref{chap:verb-inflection} to \prettyref{chap:simple-clause},
which covers the verbal system.
The fourth part is \prettyref{chap:clause-combining},
covering clause combining,
which has something to do with the nominal system 
(in relative clause constructions, for example)
and something to do with the verbal system,
so it's better to extract all relevant information out 
and place them in a single chapter.
Finally, we come to discuss variations of English
in different dialects and genres, 
which have close relation to sociolinguistics and language use.

Most chapters also start with an overview section,
containing macroscopic information and necessary top-down argumentation
(like deciding descriptive parameters,
arguing for subtypes of constructions, etc.),
which roughly correspond to the 
steps in which I segment a large system into subsystems 
and decide descriptive parameters.
The following sections contain bottom-up guidance 
on how to generate all grammatical forms.
This may be beneficial for both the writer and the readers,
for it's extendable
and contains both motivations of the linguistic analysis 
and compositional formulae for the impatient.

\subsubsection{Other possible orders}

It's possible to change the order of chapters.
When deciding how to do top-layer divisions,
I divide the grammar roughly into 
the part about the nominal system, 
the part about the verbal system,
and the part about clause embedding,
and this is the strategy in \citet{jacques2021grammar}.
But of course it's also possible to 
divide the grammar according to the size of constructions, 
i.e. according to the morphology-syntax distinction
\citep{greenough2013allen,forker2020grammar};
\citet{maurer2021grammar} also makes use of the nominal-verbal distinction,
but relative clause constructions are described within the chapter about noun phrases,
while \citet{jacques2021grammar} places it in the part about clause embedding.
Concerning how to deal with relatively optional constituents,
\citet{cgel} gives a separate chapter to adjectives and adverbs,
while I describe them partly in the part of speech chapter \prettyref{chap:pos}
and partly in the chapters about the modified constituents.
This note puts derivational morphology at the start,
because they have strong relation with the structure of the lexicon,
while \citet{cgel} and \citet{maurer2021grammar} place it at the end of the grammar,
so that readers who read the grammar from the first page to the last page 
easily understand the distribution of derived lexemes.

The choice of the arrangement of chapters depends on the intention of the grammar,
as well as the properties of the language in question 
(for example, for a language like Mandarin Chinese, 
the morphology-syntax order makes no sense.)
The order of this note may be suboptimal for many languages,
but usually it doesn't fail too badly:
it's a reasonable starting point for looking for what to study.
The taste of the author also contributes to the choice of the arrangement:
The part that the author is especially interested is of course longer 
and may be covered by several chapters and sections.
Indeed, this note pays more attention to the verbal system,
and thus less space is given to the nominal system in the grammatical sketch chapter;
if you want to talk more about the nominal system,
then it's a good idea to move some parts of \prettyref{sec:np.template}
to \prettyref{sec:overview.np}
(and then there will be more boxes about theoretical hot points 
in \prettyref{sec:np.template}).

\subsection{Notations}

This work refrains from using many tree diagrams, TODO: show some diagrams

Bracketing -- equivalent to tree diagrams but more concise -- 
is added to examples.
For a book about a previously unknown language,
this may not be a good idea,
because raw data is precious and 
the author's responsibility is to represent what is observed as it is,
but for a well known language like English,
imposing my analysis to the examples 
won't do much harm:
It I'm wrong with my analysis,
people with native speaker intuition will easily point it out.
Note that a bracketed group of words don't necessarily 
correspond to a constituent in the sense of generative syntax: 
It can be a ``span'', 
like Dixon's verb phrase mentioned in \prettyref{sec:blt-generative}.

\chapter{Grammatical overview}\label{chap:overview}

TODO list:
\begin{itemize}
    \item Position of spatial PPs (prototypical peripheral arguments) in clause structure: vP or TP?
    \begin{itemize}
        \item See Non-oblique syntax for a dative experiencer in Korean: experiencer PP as one element in VP
        \item The book The order of prepositional phrases in the structure of the clause may be very useful;
        but it turns out it only covers abstract concepts that can be used to motivate the PP-as-peripheral argument analysis and how to derive the order of PPs; it doesn't contain a list of all types of PPs
        \item But From Minimalism to Cartography: towards a unified account1
        Silvia MartÃ­nez-Ferreiro and Meritxell Mata-Vigara claims the above book indeed contains 
        a sequence of PPs; I found this, it's around p107
    \end{itemize}
    \item Types of numerals 
    \item Comparative constructions
\end{itemize}

This chapter presents basic (and unavoidably fragmentary) typological information of English,
as well as basic principles to be followed in this note,
and the arrangement of some sections are more function-oriented, 
with several structurally heterogenous implementations of 
similar semantic concepts placed in one section.
I will overview word classes -- or more generally, form classes -- 
as well as classes of phrases and clauses,
and also their subclassification and distributional information.
Topics like combinatorial possibilities of constructions
are not touched in this chapter:
For more organized, structure-oriented summaries of 
\acs{np}s and clauses, 
see, for example, \prettyref{chap:np} and \prettyref{chap:simple-clause}.
A lot of boxes concerning my theoretical orientation appears in this section,
which can be safely skipped if you are not interested in them.

\section{Morphology}

Compared with its ancestors, 
English has already lost a large proportion of its morphology.


\section{Parts of speech}


\subsection{Nouns, verbs and adjectives}

English has a quite clear distinction between the noun class and the verb class.
The inflection pattens are different, 

The English adjective class is not quite similar to the noun class or the verb class 
\citep[\citepage{73}]{dixon2010basic2}.
The adjective class has the following properties.
Attributives in \acs{np}s are most frequently adjective phrases.
Adjectives are 

\section{Nouns and noun phrases}\label{sec:overview.np}

The constituent order of English is Dem Num A N
(\prettyref{ex:overview.np.1}, \prettyref{sec:np.template}). 
English \acs{np}s may have -- sometimes must have -- 
one determiner, 
which may be a demonstrative (\prettyref{ex:overview.np.1}),
an article (\prettyref{ex:overview.np.2}),
or others (\prettyref{sec:np.det});
if we remove the determiner, 
the resulting constituent -- which we call a \concept{nominal} -- 
can still have limited distribution (\prettyref{ex:overview.np.3}, \prettyref{sec:np.nominal}).

\begin{exe}
    \ex\label{ex:overview.np.1} He was frightened by [[these]_{\text{Dem}} [three]_{\text{Num}} [ugly]_{\text{A}} [bears]_{\text{N}}].
    \ex\label{ex:overview.np.2} This is 
    [[a]_{\text{article}} book about learning Vim in [[the]_{\text{article}} difficult way]_{\text{\acs{np}}}]_{\text{\acs{np}}}.
    \ex\label{ex:overview.np.3} We plan to plant four more [Fuji apple]_{\text{nominal}} trees.
\end{exe}

\begin{theorybox}{The cartography of \acs{np}s (DPs)}{quantifier-position}
    In generative terms, 
    the nominal corresponds to the NumP domain.
    The NumP itself is similar to the role of TP,
    and the various adjectives are similar to specifiers of AdvPs in the TP domain,
    and the complementation is similar to the VP layer
    \citep{laenzlinger2017view}. 

    Though quantifiers are often seen inside \acs{np}s,
    their semantic scopes are definitely larger.
    This is TODO

    It should be noted that when studying the structure of DP,
    we should distinguish semantics and syntax.
    The meaning of \emph{determination} may be realized by something like the English articles,
    but it may also be realized by something that looks very like an adjective,
    as is the case in Latin.
    What is uncontroversially universal is a set of atomic syntactic features 
    and related semantic meanings, 
    not how they are packaged into concrete constructions,
    and whether \acs{np}s and clauses follow the same cross-linguistic template
    is still a disputed problem 
    (\prettyref{box:negation-position}).
\end{theorybox}

\section{Verbal morphology and the clause}

\subsection{\acs{tam} categories}

English has two simple tenses: the past and the present.
The aspectual systems are more complicated. 
The concept of composition 
-- whether the inner makeup of an event is important \citep[\citesec{19.10}]{dixon2012basic3} -- 
is marked by the so-called plain-progressive distinction.
This is a restricted version of the imperfective-perfective distinction \citep{dixon2012basic3}:
A clause representing a state instead of an event 
is never progressive,
even if it's usually semantically imperfective.
The English plain-perfect distinction marks 
a distorted version of the completion concept 
-- whether the time of an event is before the time of narratives defined by tense 
\citep[\citesec{19.7}]{dixon2012basic3},
because sometimes the event time in the English \category{perfect} 
is the starting time of the event in question,
not the finishing time,
and this disagrees with the term \term{completion}.
English also has several modal constructions.
The above categories interact freely (\prettyref{sec:auxiliary-chain}, TODO: really?).

The category of tense is always realized morphologically 
on the main verb when there is no auxiliary 
or on the highest auxiliary verb (\prettyref{sec:verb-forms}).
The category of the two aspect categories are marked by auxiliary verbs, 
as well as modality (\prettyref{sec:auxiliaries}). 

There is no future tense in English:
The future time is marked by the auxiliary \corpus{will} or \corpus{would} 
or the \corpus{be going to do} construction (\prettyref{sec:future}).

Besides the regular \acs{tam} system,
there are also some periphrastic constructions marking specific \acs{tam} configurations,
like \corpus{used to} or \corpus{would rather} (\prettyref{sec:semi-auxiliary}).
Adverbs are also a important part in expressing \acs{tam} information in English,
and have relative positions with auxiliaries that are more rigid than previously thought (TODO: ref).

There are usual compatibility issues between \acs{tam} categories 
with some moods (\prettyref{sec:tam-mood-compatibility}).

\begin{theorybox}{The TP projections}{tp}
    What happens here is the span spellout of grammatical categories in the TP layer.
    \paragraph*{Some sentential adverbs as a part of the verbal system} 
    Some adverbs are also involved in the TP domain.
    Historically they are viewed as adjuncts,
    but this notion reaches some theoretical challenges 
    (it makes no sense to introduce two structural building mechanism)
    as well as empirical ones \citep{sportiche2017fewer}.
    I follow the practice in Cartography syntax and regard them as specifiers of functional heads,
    while auxiliaries are a part of the inflection pattern of the verb 
    with the term \term{inflection} defined 
    at the end of \prettyref{sec:morphology-meaning}.
    In this way it's easy to account for the fact that 
    in the surface form, verbs occur between adverbs:
    If adverbs are specifiers,
    then their corresponding heads can be sites of vocabulary insertion.

    Indeed, cross-linguistically, 
    we find the order of adverbs (so-called adjuncts) and the order of related functional morphemes 
    show a very strong correlation -- called the Mirror Principle,
    and disagreements between the two can usually be resolved 
    within the syntax-centered framework \citep{harley2010affixation}.

    \paragraph*{Adverbials as ``arguments'' of \acs{tam} categories} In the prototypical case, 
    the specifier of, say, an Asp$_{\text{continuous}}$ head 
    tells us more about \emph{how} continuous the event is,
    just like that the object -- the specifier of the Trans head -- 
    tells us more about \emph{what} is the patientive argument.

    In Cartography, the positions of prepositional phrases receive relatively less attention compared with adverbs,
    but their positions can also be seen as a part of \prettyref{tbl:auxiliary-chain}
    (\citealt[\citepage{106}]{schweikert2005order}),
    though usually prepositional phrases appear at the end of a clause 
    and don't really appear in \prettyref{tbl:auxiliary-chain} in the surface order.
    The correspondence between the order of \acs{pp}s and verbal extensions 
    -- realization of functional heads -- 
    can also be found \citep[\citepage{160}]{cinque2006restructuring}.
    
    \paragraph*{Gradience between specifier and head?} 
    It's also frequent that the ways to fill this specifier is highly limited,
    and in this way the semantic function of the adverb 
    is almost the same as the head, though the former is ``in the format of specifier''
    \citep{shlonsky2010cartographic},
    and they are by all means a part of the sequence in \prettyref{tbl:auxiliary-chain}.
\end{theorybox}

\subsection{Negation} 

Negation in English clauses is usually realized by the negator \corpus{not}
or negative forms of auxiliaries (\prettyref{sec:verb-inflection.negation}). 
Negative pronouns like \corpus{nobody} can also be used to express a negative idea (TODO: ref).
It should be noted that the relation between the semantic scope and the constituent order of negator 
is subtle:
Several factors are involved in determining the former.

\begin{theorybox}{Negation in Cartography}{negation-position}
    \paragraph*{Negation in specifiers and in heads}
    The exact status of negation in syntax is still a debated topic.
    Some quick analysis tells us that besides 
    the complement clause construction-based strategy of negation,
    clausal negators can be roughly divided into two subtypes:
    One is the type of ``phrasal negators'',
    which doesn't disrupt the behavior of the verbal complex,
    like verb inflection or V-to-C movement (\prettyref{sec:morphology-meaning}),
    and fits in the negation-like-adverb picture 
    (\citealt[\citepage{101}]{zanuttini1997negation};
    \citealt[\citesec{4.7}]{radford2009analysing});
    The other is the type of ``negation heads'',
    which in turn has two subtypes with respect to their morphologically properties,
    the first being the type of verb inflectional affixes,
    the other particles that are somehow closely attached to the verb \citep{zeijlstra2013}.    

    \paragraph*{Negation in syntactic structures} 
    The position of NegP shows strong cross-linguistic variation.
    This is especially demonstrated by looking at morphologically rich languages,
    because spelling out a span of functional heads into one phonological word
    is unmarked compared with incorporating a specifier of a functional head 
    into the word,
    and while \acs{tam} affixes have a strong tendency to be ordered 
    according to the preposed order in Cartography, 
    the position of the negation affix seems to be free \citep[\citepage{15}]{moscati2010negation}.%
    \footnote{
        Note that since the order of morphemes in the verb has a strong correlation 
        with the syntactic functional head hierarchy motivated by \emph{other} evidences,
        it's not a good idea to claim that the position of the negation affix 
        is completely an affair only about the realization of underlying grammatical structures.
    }
    The category of negation, which is purely logical, is therefore in sharp contrast with 
    the hierarchy of TP, 
    which encodes more substantial semantic information
    and has a relatively rigid order cross-linguistically.

    \paragraph*{Semantics of negation} 
    The structural position of negation 
    doesn't faithfully represent the semantic scope of negation.
    Theoretically speaking it also doesn't have to:
    By tricks of $\lambda$-expressions,
    we can let a structurally lower constituent 
    ``eat'' a structurally higher constituent
    and put the interpretation of the latter 
    under the scope of an operator in the former.

    This mismatch between the syntactic position and the semantic scope of negation 
    is prevalent and diverse: 
    Both narrowing and widening the scope are possible cross-linguistically
    \cite[\citepage{40}]{moscati2010negation}.
    If we assume the syntactic structure faithfully 
    represents the semantic scope of negation,
    we need to set multiple negator positions in the TP 
    (and also CP -- think about the Latin negative complementizer \corpus{ne})
    layer, while the PF realization of the negation is fixed to a specific position 
    (in the case of English, after the first auxiliary verb).
    We can also assume a smaller number of NegPs,
    as many as the amount enough for describing constituent order variations,
    but then LF must be able to arbitrarily change the negation scope \citep{moscati2012cartography}.

    The second approach -- that negation 
    which may give rise to the theoretical problem 
    if LF operates on the Neg head,
    because then there now seems to be ``real'' head movements that change the semantics.
    However, as is shown above, syntactic negation can be seen as determined by the specifier,
    and LF scope widening by specifier movement at least doesn't face theoretical barriers,
    and agrees with the theory of LF raising of quantifiers (\prettyref{box:quantifier-position}).
    The meaning of the Neg head, then,
    is just to remind the listener that the sentence involves \emph{some} kind of negation,
    without specifying what exactly is negated.
    This phenomenon -- mismatch between PF and LF, 
    or even the syntax proper and LF 
    if we follow the uniform NegP followed by specifier raising approach --
    is actually quite prevalent (\prettyref{box:quantifier-position}, \prettyref{sec:semantics-argument}).

    Finally, it should be noted that some LF-PF (or even LF-syntax proper) mismatches 
    come from pragmatic implications, 
    instead of direct structure-based semantic interpretation
    \citep{zeijlstra2018does,crowley2019neg}.
    For example, \corpus{I don't think he will come} 
    usually means \translate{I think he will not come},
    but if this is due to syntactic reasons,
    then we see a counterexample of the phase theory 
    (raising of the negator breaks the CP phase boundary).
\end{theorybox}

\subsection{Transitivity and alignment}

English is a typical accusative language.
A subject can be identified syntactically 
according to constituent order, case, semantic role, and more criteria 
(\prettyref{sec:simple-clause.subject}).
The usual tests of syntactic accusativity,
like extraction in coordination (\prettyref{ex:overview.accusative-1}), can be run on English.

\begin{exe}
    \ex\label{ex:overview.accusative-1} 
    I [wondered around]_{\text{intransitive}} and [saw something weird]_{\text{transitive}}
    \ex\label{ex:overview.accusative-2}
    I didn't hurt him, but he hurt me.
\end{exe}

In finite clauses we have \concept{subject-verb agreement},
usually when the tense is \category{present}
and the subject is third-person singular 
(\prettyref{sec:verb-inflection.agreement}).


\begin{theorybox}{Alignment and the subject}{alignment-subject}
    \term{Alignment} means how arguments in the clause 
    are matched with their clausal dependent statuses:
    The agentive argument usually receives the nominative case and sits in the subject position, 
    the objective argument usually receives the accusative case and appears after the verb, etc.
    In accusative languages,
    the subject is higher than the tense marker
    and is in the SpecTP (or SpecSubjP, if we are to do fine-grained Cartography) position.
    When extracted from \vP{},
    the subject is \emph{probed} and therefore \emph{agrees} with the probing head,
    so we have subject-verb agreement.
    Of course it's still possible to have object-verb agreement
    when the object is assigned the accusative case, 
    which is also a probe-goal process,
    but English doesn't show this pattern.

    In world languages, sometimes we see alignment patterns other than the nominative-accusative scheme.
    When the agentive argument in a transitive clause is assigned an inherent case, 
    we get so-called morphological ergativity,
    while syntactic ergativity is caused by an early EPP feature 
    targeting the absolutive \acs{np} \citep{aldridge2008generative}.
    We even have more unusual direct-inverse system,
    which possibly arises from the fact that 
    somehow the probe (roughly the tense head T) responsible for agreement of verb with arguments 
    searches for a person feature \emph{and} a discourse participant feature,
    so if a first person argument is present,
    the agreement affix becomes the first-person version,
    and the inverse affix appears to avoid two identical person features appearing together,
    as is observed in the Spanish \corpus{se lo} construction
    \citep{oxford2017inverse}.
    The Austronesian focus system \citep{chen2019western} is another interesting phenomenon,
    which may be symmetric voice constructions or obligatory topicalization 
    and isn't comparable with accusative or ergative alignment in the latter case.
\end{theorybox}

\subsection{Finite clause types}

English has the following major types of finite main clauses with regard to the related speech act
(note that there are mismatches between form and meaning when it comes to mood (\prettyref{box:mood})):
the imperative, the declarative, 
the open interrogative, the closed interrogative,
the exclamative (\prettyref{sec:moods}).
No further morphosyntactic marking of sentential speech act (such as sentence-final particles)
exists in English.
The moods are \emph{not} marked morphologically.
The interrogative moods, for example, are formed by introducing an interrogative pronoun (for open interrogative)
and subject-auxiliary inversion (\prettyref{sec:sai}). 

Finite relative clauses look similar to open interrogative clauses,
though usually without subject-auxiliary inversion,
and finite complement clauses look similar to either declarative clauses or interrogative clauses 
(\prettyref{sec:clause-combining}).
English also has nonfinite constructions (\prettyref{sec:overview.nonfinite-construction}).

\begin{theorybox}{Clause and sentence}{clause-sentence}
    The above classification is about \emph{sentences}, 
    and not necessarily anything that can be called a clause \citet[96]{dixon2009basic1}.
    (Here Dixon is trapped into another extreme by claiming 
    the clause linking procedure is flat,
    and the sentence is the ultimate product of grammar.
    But of course clause linking can be done recursively,
    with a tree-like order.)
    In generative syntax, 
    a TP or a low-level CP is already well qualified as a clause,
    but in order to construct a sentence -- a verbal constituent 
    that serves as a ``full'' utterance --
    we still need to include the full functional projections marking speech acts or speech ``forces''.
    In Mandarin Chinese, for example,
    a clause often needs sentence-final particles attached to it to be an acceptable independent sentence,
    while clauses without sentence-final particles appear regularly in 
    clause linking,
    and even more impoverished ``small clauses'' -- basically \vP{}s -- also appear in clause embedding.
    Thus, there are several types of clauses with different sizes.

    Such phenomena also appear in English, arguably in all languages.
    Non-embedded finite clauses are of course full CPs,
    but some embedded finite clauses,
    like the indirect quoted question in \corpus{I asked [why he was always late]},
    show different behaviors with their non-embedded counterparts:
    In the bracketed example, the subject-auxiliary inversion is absent.
    Participle constructions are likely to be TPs, as well as infinitives in control constructions
    \citep{pires2006minimalist},
    while infinitives are impoverished CPs. 

    In practice, covering all kinds of TPs and CPs with the catch-all term \term{clause}
    doesn't create much confusion,
    because non-embedded finite clauses, 
    embedded finite clauses, and nonfinite clauses are usually discussed in different places 
    and it's easy to infer whether the term \term{clause} 
    means a full CP, a defective CP or a TP. 
    So to say mood (or \term{clause type}, 
    with the specific meaning of the imperative/declarative/interrogative distinction;
    for terminology see \prettyref{box:mood})
    is marked on a finite clause doesn't create much confusion, 
    and nor do wordings like ``the clause type or the mood marks the speech force'',
    though the latter is not universally true
    (in Chinese there are several syntactic systems marking the speech force).
\end{theorybox}


\subsection{Valency changing}\label{sec:overview.valency-changing}

\begin{theorybox}{Valency changing}{valency-changing}
    \paragraph*{There is no transformation step in valency changing} 
    Valency changing involves the lexicon, the \vP{} layer, and the TP layer.
    The term \term{valency changing} is kind of misleading,
    because what actually happens is \emph{valency corresponding},
    and the transformational rules used to describe valency changing 
    are just phenomenological.

    \paragraph*{Valency changing as multiple subcategorization frames} 
    Valency changing occurs because of 
    the verb in question has two subcategorization frames.
    The clause \corpus{John and Mary will meet tomorrow} 
    has the same meaning of \corpus{John will meet with Mary tomorrow},
    but it's unlikely the relation between the two arises from some syntactic operations in the \vP{} layer:
    The case may just be that \corpus{meet} is compatible with two \vP{} structures,
    which turn out to have the same semantic interpretation.
    A transformation-based account for this argument structure variation 
    inevitably involves transformation on \emph{semantic} concepts,
    which makes things complicated without any benefits.

    \paragraph*{Light-verb-attachment-induced valency changing} 
    A specific case where transformation-based description \emph{is} appropriate 
    involves two \vP structures, 
    with one structure being 
    another with an additional \term{v} head,
    and the additional \term{v} head 
    extracts one of the arguments introduced in the smaller \vP into the specifier,
    or introduces a new argument.
    This is frequently seen in Old Chinese as well as its sisters,
    and is still the main way Modern Mandarin Chinese does valency changing.

    \paragraph*{Alignment-related valency changing} 
    It's also possible to have two (or more) \vP{} structures that both work for a group of verbs,
    and for some reason (e.g. the agentive argument is assigned an inherent case, 
    so it's no longer visible for the A-movement to SpecTP),
    one of them disrupts the way TP usually works,
    like, say, the Voice head does something 
    so that the agentive argument somehow receives an inherent case 
    and becomes the \corpus{by}-phrase and can no longer be promoted to the subject position.
    This seems to be the way the English passive works.
    (This is close to the mechanism of morphological ergativity (\prettyref{box:alignment-subject}).)

    In more descriptive terms,
    the \vP-internal strategy lies on the blur line between derivation and inflection
    (and if the additional \term{v} head is realized as a word, 
    that it lines on the line between multi-verb predicates and auxiliary verb constructions),
    while the \vP-TP strategy involves the \emph{alignment}.
    It's hard to draw a clear line between the first and the second strategy.
\end{theorybox}

There are only two regular valency changing device in English,
and both of them belong to the passive or the \term{passive voice}.
The first is the \corpus{be}-passive (\prettyref{ex:be-passive}), 
and the second is the lately grammaticalized \corpus{get}-passive.

\begin{exe}
    \ex\label{ex:be-passive} \begin{xlist}
        \ex {} [%
            [A car]_{\text{subject, agent}} %
            [hit]_{\text{past}} [me]_{\text{object, patient}} [%
            this morning]_{\text{time adverbial}}]_{\text{active}}
        \ex {} [%
            [I]_{\text{subject, patient}} %
            [was]_{\text{passive, past}} %
            [hit]_{\text{\corpuscat{ed}-participle}} %
            [by a car]_{\text{agent}} %
            [this morning]_{\text{time adverbial}}]_{\text{passive}}
    \end{xlist}
    \ex\label{ex:} {} [%
    [I]_{\text{subject, patient}} %
    [got]_{\text{past}} %
    [hit]_{\text{\corpuscat{ed}-participle}} %
    [by a car]_{\text{agent}} %
    [this morning]_{\text{time adverbial}}]_{\text{passive}}
\end{exe}

\subsection{Light verb constructions}

English has several verbs whose semantic contents are somehow bleached.

\begin{exe}
    \ex \begin{xlist}
        \ex I [gave [the target]_{\text{object}} [a hit]_{\text{action}}]_{\text{light verb construction}}.
        \ex I hit the target.
    \end{xlist}
\end{exe}

\subsection{Nonfinite constructions and nominalization}\label{sec:overview.nonfinite-construction}

English nonfinite constructions include two participles 
(the \corpuscat{ing}-participle and the \corpuscat{ed}-participle),
the bare infinitive and the \corpuscat{to}-infinitive (\prettyref{sec:simple-clause.nonfinite-clause}).
They are all morphologically marked (\prettyref{sec:verb-forms}).
English nonfinite constructions are largely restricted to relative clauses and complement clauses;
adverbial nonfinite clauses are possible,
but there are always finite counterparts (\prettyref{ex:overview.nonfinite-finite-adverbial-ex-b1}).
This makes English different from languages like Japanese,
in which nonfinite adverbial clauses are much more frequent and sometimes are the only choice.

\begin{exe}
    \ex \label{ex:overview.nonfinite-finite-adverbial-ex-b1} \begin{xlist}
        \ex I usually watch jail shows [when waiting for the results of my program]%
        _{\text{temporal:\corpuscat{ing}-clause}}
        \ex I usually watch jail shows [when I wait for the results of my program]_{\text{temporal:finite}}
    \end{xlist}
\end{exe}

\subsection{Information structure}

Apart from the sentential topic and focus positions,
there exist other ways to convey weather a piece of information is new or old,
like word stressing.
TODO: for NP, this seems analyzable as a peripheral modifier,
in a similar position with \corpus{even} or \corpus{just}
For verb \cite[\citepage{125}]{kahnemuyipour2009syntax}, how to do it?
Possibly it works on ``V-node'', i.e. since like verbal categorizer phrase, etc.
This is also semantically motivated:
a verb tells us the property of the event argument ($\text{event}(e, \text{verb})$),
while syntactic arguments are interpreted like $\text{agent}(e, \text{someone})$

\section{Adjectives, adverbs, prepositions, and their phrases}

Adverb phrases and prepositional phrases 
prototypically fill \concept{clausal adjunct} (or \concept{adverbials}) positions, 
which can be distinguished from clausal complements -- which in English are mostly core arguments
-- by tests described in \citet[\citechapsec{4}{1.2}]{cgel}.
It's also possible for them to modify adjectives.

There are many subclasses in the catch-all adverbial class
regarding the syntactic function.
Some adverbials -- both adverb phrases and prepositional phrases -- 
are peripheral arguments (\prettyref{chap:peripheral-arguments}) -- 
the mean, instrument and manner of an event,
the spatial and temporal location, etc. 
Some adverbs are \acs{tam} markers (\prettyref{sec:tam.adverbs}),
and of course, temporal peripheral arguments also have \acs{tam} meanings.
Some adverbs have higher scopes and are more or less about speech acts.

\section{Clause combining}\label{sec:clause-combining}

All English clause combining devices are on the level of complete clauses:
There is no complex predicate or clause chaining.
Thus, TODO: types of clause combining

\section{Constituent order}\label{sec:overview.constituent-order}

\begin{theorybox}{Constituent order and syntactic structure}{order-structure}
    Many functionalists and some generativists have repeated the idea that 
    the real constituency structure of natural languages 
    is much flatter than we previously thought.
    But then they have to use dependency relations to make up for lost information,
    and there is a strong tendency that 
    there exists a rigid hierarchy of how ``close'' the dependency relations are.
    This note is aimed to mimic how ordinary reference grammar works,
    so I won't really draw deep, binary constituency trees with lots of movements,
    but for each so-called constituent order rule,
    I will point out its structural origin.
\end{theorybox}

As is said above, probably because of the erosion of the morphology system in historical stages
(\prettyref{sec:nouns.overview}, TODO: more ref),
English has highly rigid constituent orders. 
Moving of syntactic objects usually indicates 
non-trivial information structure (TODO: ref) 
or is triggered by the syntactic environment (TODO: interrogative, etc.).

English doesn't show V2 order in canonical clauses which is frequent in many Germanic languages.
It does show V2 order when \concept{subject-auxiliary inversion} appears,

\section{Pragmatics}

English has some remarkable phenomena for the study of pragmatics.
Scalar implications can be observed in several syntactically unrelated cases (TODO: ref):
Speakers tend to maximize the information contained in their utterance,
and thus if the meaning of construction A implies 
the meaning of construction B,
then A is preferred as long as saying A doesn't mean anything unintended.

\chapter{Parts of speech and derivational morphology}\label{chap:pos}

\section{Overview and preliminaries}\label{sec:nouns.overview}

This section discusses form classes -- or parts of speech, using terms in traditional grammar -- in English.
I will talk about lexical entries roots, derivational processes of them,  
and the phrases the roots project into.
In principle, the structures of phrases can be covered when discussing their head words,
so in some traditional grammars,
all morphosyntactic information -- besides phonology, the writing system, cultural background, etc. -- 
falls under the part about ``parts of speech''.
This note is strongly influenced by the structuralist-generative tradition
and reject to do so, 
because it the size difference of objects in grammar.
Indeed, the structures of the extended phrases of nouns and verbs are too large 
to be placed into one chapter:
They are the main focus of the following several chapters.
The structure of adjective phrases and adverb phrases, however, are covered in this chapter,
as well as some sub-word components, like affixes and roots.

\begin{learnbox}{Describing parts of speech involves forward references}{pos-forward-ref}
    Characterization of parts of speech and their contexts unavoidably involves 
    information about larger constructions like \acs{np}s or clauses.
    Forward references to the following chapters are to be expected in this chapter.
\end{learnbox}

\subsection{Wordhood in English}


\subsection{Distinguishing parts of speech}

Now we talk about parts of speech division in English.
We can assume universal noun-like features or verb-like features,
but how they are related to concrete, language-specific form classes needs argumentation 
(\prettyref{sec:pos}).
With respect to the parameters of 
openness, the content-function dichotomy,
and whether function items are similar to content items enough,
there are roughly four types of parts of speech:
\begin{enumerate*}
    \item open content categories with clear part of speech labels like noun, verb or adjective;
    \item close content categories with clear part of speech labels like noun, verb, or adjectives;
    \item close grammatical categories which may still be seen as noun-like or verb-like (like pronouns), and 
    \item close grammatical categories like particles or affixes that don't really need part of speech labels.
\end{enumerate*}
The four types are going to be discussed immediately below.

\begin{theorybox}{Grammatical words}{grammatical-words}
    The third and the fourth classes are usually primarily exponents of functional heads.
    A word in the third class may contain some features making it look like a word from the first two classes,
    like the categorizer feature or the person/number/case feature,
    while a word in the fourth class may not.

    Gradience occurs between the boundaries of the four types of parts of speech.
    Surface realizations of a specifier position,
    if limited to a few (like adverbs filling certain positions),
    may be bleached into realization of functional heads,
    thus coming into the third and fourth types of parts of speech.
    Competing analyses occur when this change is happening.
    The boundary between the latter isn't clear,
    and so is the boundary between the first type and the second type
    (because many so-called closed content word classes 
    sporadically accept new members),
    and the second type and the third type
    (for example, when the number of verbs is so-limited -- say, only a handful -- 
    then is it a better idea to regard the verb class as the exponents of different light verbs?),
    and also the third type and the fourth type
    (since the criteria of ``looking like a noun or a verb'' are never clear).
\end{theorybox}

TODO: combining forms \citep[\citepage{1661}]{cgel}

\subsubsection{Open content categories}

Since English still has some inflectional morphology,
the class of \concept{countable nouns} can be easily told from others:
When we see the single/plural \corpus{-\emptymorpheme}/\corpus{-s} alternation, it has to be a countable noun.
The class of \concept{uncountable nouns} can be tell from 

The verb class can be distinguished by its inflection (\prettyref{sec:verb-forms}). 

TODO: strike n. strike v.

The English adjective class -- there is only one adjective class, not two or more,
which is the case in Japanese -- 
can be distinguished by 

\begin{theorybox}{Why semantics doesn't decide form class}{content-word-semantics}
    It's often said that nouns are about objects, 
    verbs are about events,
    and adjectives are about properties.
    This mapping from word class to semantics is a coarse one 
    and should be refined for more systematic description of languages.

    It should be noted that actions and processes can be conceptualized as objects:
    We have, for example, \corpus{his playing of the national anthem},
    where \corpus{play} is nominalized into \corpus{playing}
    (this is not an \corpuscat{ing}-participle -- see TODO: ref).
    The boundary between objects and properties is also hard to draw:
    Apart from pronouns or demonstratives 
    that directly refer to the conversation context 
    and pull out a specific object from the listener/reader's memory
    (and therefore introduce a free variable in the semantic interpretation of the utterance),
    nouns denote \emph{sets of objects},
    and we know we can have a one-to-one mapping 
    between a set $A$ and a predicate in the form of $\cdot \in A$:
    A noun like \corpus{toothbrush} 
    can be immediately mapped to an adjective, like \corpus{toothbrush-like},
    and therefore whether \corpus{toothbrush} \emph{really} means 
    a set or a predicate becomes an undecidable question.
    And similarly a property can also be conceptualized as an object: 
    as a set, or maybe as a kind of ``essence''
    (compare \corpus{the ice harvesters are [manly]_{\text{about property}} men}
    and \corpus{the ice harvesters have strong [manliness]_{\text{object?}}}).

    The boundary between actions and properties is also not clear:
    In traditional grammar they are all called ``predicates''.
    When translated into logical expressions,
    a clause about an event introduces an event argument (\prettyref{sec:semantics-argument}),
    The difference between events and properties may be that
    while a clause about the fact that an object has a property 
    can be simply interpreted as \translate{property($x$)},
    or if we want to reduce the number of logical predicates 
    (to avoid the necessity of using higher-order logic),
    \translate{$x \in \text{the-set-with-the-property}$}.
    But of course having a property is temporal,
    so \corpus{this is beautiful} is to be interpreted as 
    \translate{$\exists e (\text{time}(e, \text{speech-time}) \land 
    \text{$\in$-in-a-time}(x, \text{what-is-beatuful}, e) )$}.
    This doesn't seem quite different from the meaning of a clause about an event,
    although there may still be some subtle differences like 
    whether the $e$ in clauses about properties can be the invisible topic, 
    which seems to be the reason for the mysterious \corpus{wa}/\corpus{ga} alternation in Japanese
    \citep{heycock2008}.

    So in the end,
    nouns are prototypically about objects,
    and they may denote events, 
    and whatever they denote, they can be thought as properties in semantic interpretation.
    What makes a root a noun 
    is essentially its \emph{syntactic environment}.
    Intuitively, we say nouns are similar to pronouns, demonstratives, etc., 
    which, however, can never be interpreted as properties.
    That's because these words contain a determiner fused inside 
    and therefore have clear and direct reference (\prettyref{sec:np.fused-head}),
    and the reason we say nouns are like them 
    is that a noun can be placed at the center of a DP, 
    and the DP now has almost the same syntactic distribution with pronouns, etc. 

    Semantically, verbs are about actions and properties,
    but again, they are \emph{categorized} as verbs 
    not because of inherent semantic properties, 
    but by the syntactic environment
    (being immersed in the \vP-TP-CP projections).
    Thus, in principle we don't really need content words other than nouns,
    which is indeed the case in some languages
    with very limited verb classes.

    The semantic function of adjectives can in principle always be realized by nouns or verbs.
    The role of them is highly language-specific,
    and they appear when a meaning is hard to convey using existing constructions concerning nouns or verbs.
    For example, in English, when it comes to gradience of properties
    (manifested in comparative constructions),
    nouns are of limited use,
    so adjectives are indeed necessary.
    But we still have \corpus{he's more a scientist than a public health official},
    and the adjective version \corpus{he's more scientist-like than public health official-like},
    despite being grammatical, is awkward
    and only appears in language games instead of natural, everyday speech.

    Note that the above discussion may be well found in an introduction to, say, 
    ``Radical Construction Grammar'',
    in which it's argued that grammatical categories only make sense 
    in constructions.
    This note, however, takes the stance that 
    constructions are not routinized structureless strings,
    but are made of building blocks that are subject to universal constraints.
    It's my theoretical assumption that a root being categorized into a noun 
    has nothing substantiality different from adding an article before a noun,
    although when it comes to processing,
    the first may be more ``automated'' and ``fossilized''.
\end{theorybox}

\subsubsection{Closed content categories}

Languages like Japanese have the second type of words 
(usually verbs, adjectives in the case of Japanese),
but that's not the case for large word classes in English.
Still, some subclasses of verbs seem to be closed TODO: ref.

\subsubsection{Grammatical words looking like nouns, verbs, etc.}

The prototypical members of this type are all classes of pro-forms.
Division between this class and ``pure'' grammatical items however 
is sometimes hard to make (\prettyref{box:grammatical-words}). %Enumerating: all blurred case

\subsubsection{``Pure'' grammatical items}

Grammatical words in this type -- the type without much resemblance to prototypical content words -- 
don't really need part of speech tags,
but since they are surface realizations of different grammatical categories,
and exponents of different values of the same set of categories 
usually have similar distributions,
dividing these items into groups helps us to organize the grammar,
though unlike labels like noun or verb,
these labels have less substantiality in the mind of native speakers.

\begin{infobox}{Part of speech tags for pure grammatical items in other languages}{pos-grammatical}
    For example, in a language with case particles,
    we may set up a word class called ``case particles'',
    which falls under the class of ``particles''.
    This is the case for traditional Japanese grammar,
    which proves to be useful:
    If you find the usage of an item (word or morpheme, 
    depending on your standard of words (\prettyref{sec:wordhood}))
    strange and from the position,
    you are sure it's a particle,
    then you can go straight to a reference grammar or a ``grammar dictionary''
    and search this item and find grammatical constructions listed in its entry.
\end{infobox}

\citet[\citepage{330}]{cgel} introduces the class of determinatives.
A full list of determinatives are given by \citet[\citepage{356}]{cgel}.

\subsection{Derivational devices}

\subsubsection{Derivation-inflection distinction in English}

This section only covers derivational processes.
The accepted wisdom is ``derivation relates one lexeme to another lexeme,
while inflection relates one lexeme to its form in the final utterance''.
This definition however still has intrinsic vagueness.
It involves two parameters:
structure size
and fossilization.
Regarding structure size,
derivation is on the level of lexemes,
which are smaller than phrases,
and also smaller than ``finished words'' -- inflected words -- 
that involve influences from the external syntactic environment.
Regarding fossilization, 
derivation should be less synchronically active than inflection
(and therefore less productive).
There is certain amount of correlation between the two parameters:
Small units are easier to lexicalize, 
so compound words are more likely to have established meanings,
and compounding is therefore prototypically derivational.
But of course the parameters may not always agree with each other,
and both parameters have vagueness.
The derivation-inflection distinction is therefore not appropriate 
in some cases \citep[\citepage{221}]{dixon2009basic1}.

\begin{infobox}{Example in vagueness of the derivation-inflection distinction}{derivation-def}
    Here are some examples of the vagueness.
    Concerning structure size, in case stacking, 
    should the inner case markers be considered as inflection?
    And note that a valency changing device also doesn't apply to all verbs that seem to have 
    an appropriate number of arguments --
    indeed, \citet{jacques2021grammar} calls valency changing \term{derivation}.
    A further subtlety is the parameter of fossilization should be further split into two:
    some constructions may appear less frequently but still have largely compositional meaning,
    while others -- like the Latin \corpus{com-} prefix -- 
    appear everywhere but the meanings of resulting words
    can hardly be inferred regularly.
\end{infobox}

In English a relatively clear derivation-inflection distinction can be established,
partly because English inflection has already been simplified.
Certain subtleties still exist.
Inflection sometimes still occurs before inflection,
as in, say, dephrasal derivations like \corpus{his holier-than-thou attitude} \citep[\citepage{1646}]{cgel};.
Whether the \corpus{-ly} suffix for adjective-to-adverb derivation 
should better be considered as an inflection is debated (TODO: ref).

\begin{infobox}{Terminology in derivational morphology}{terminilogy-derive}
    The most general term for units participating derivation is \term{base}.
    A root with no category is a primitive base,
    and a fully derived, ready-to-inflect unit is a maximal base.
    People sometimes call the latter a \term{stem}.

    It should be noted that the term \term{base} may denote a \emph{form} of base.
    In agglutinative languages like Japanese,
    attaching a suffix to an existing unit slightly changes its tail
    (we may say each suffix carries a morphophonological command at the initial
    dictating this change),
    and there are a finite number of such changes.
    Thus, we may say ``this unit is conjugated into the 2nd base before accepts that suffix''.
    Here the term \term{base} means a particular type of ending 
    of a base in this note.
\end{infobox}

\subsubsection{The hierarchy of derivational morphology and order of processes}

Roots don't have categories,
but of course, for some (usually semantic) reasons,
each root usually has a prototypical part of speech,
so we may still informally talk about a \term{noun root} or a \term{verb root} 
(\prettyref{sec:orgianization-of-grammar}).

\begin{infobox}{What's the level that derivation works on?}{derivation-root-or-not}
    The above terminology leads to a confusion:
    When we say a verb undergoes a deverbal nominalization procedure
    and is turned into a noun,
    does it mean the noun is obtained by 
    adding a ``noun'' label to the category-free root of that verb,
    or does it mean the noun is obtained by adding a ``noun'' label 
    \emph{outside of} the ``verb'' label?
    It seems both mechanisms exist in derivational morphology.
    Some ``symmetric'' word class conversion seems to be 
    alternation between two possible categorizations of the same category-free root,
    while asymmetric conversion involves two part of speech labels 
    (\citealt[\citepage{1641}]{cgel}; \citealt[\citepage{62}, (15)]{siddiqi2009syntax}).
    And note that derivational affixes are not merely part of speech tags:
    There are subtle (yet inferrable, not fossilized) meaning differences between 
    \corpus{healthful} \corpus{healthy}.
\end{infobox}

The symmetric/asymmetric distinction seems to be orthogonal to 
whether the conversion has zero marking.
A symmetric conversion can have explicit marking
(\corpus{speech} \corpuscat{n} \translate{the action of speaking} -- 
note that here I'm not talking about the meaning \translate{an event in which someone publicly speaks}), 
and a non-symmetric conversion can have zero marking
(\corpus{attempt} \corpuscat{n} \translate{the action of attempting}).

A general tendency is compounding happens before derivation.
Many so-called violations of this tendency comes from the fact 
that the orthographical wordhood 
(roughly corresponding to the phonological wordhood)
doesn't necessarily imply the underlying morphosyntactic structure.
The compound noun \corpus{acceptability judgement},
for example, is better analyzed as 
\corpus{[acceptability judge]-ment},
which follows the derivation-after-compounding scheme well.

The compatibility between derivational devices involves several factors.
\begin{enumerate*}
    \item Most derivational devices select categorized bases,
    and wrong part of speech tags cause incompatibility.
    Specifically, some affixes are terminal ones:
    The part of speech tags carried by them are never accepted by any other derivational devices.
    Once they are added,
    no further derivation is possible. %Enumerating: all examples 
    \item Some combinations of affixes are not possible because of redundancy:
    the complex \corpus{??-ness-ful},
    for example, is extremely rare,
    because usually \corpus{-ness} is attached to an adjective,
    and the whole sequence \corpus{-ness-ful} therefore adds nothing new semantically.
    The fact that it does appear in manufactured examples, like \corpus{awkwardnessful},
    to show a sense of cumbersomeness,
    confirms the above claim that its rarity is largely semantically motivated.
    \item Some combinations of affixes are not possible because of realizational reasons:
    \corpus{*-ic-ly} is not possible 
    because this combination is somehow ``hard to pronounce'' in English,
    and there is no vowel insertion rule pertaining to this configuration to ease the problem.
    We have to add a \corpus{-al} between the two suffixes.
    On the other hand, although \corpus{-ize-tion} is also awkward,
    \corpus{-a-} is inserted, and the resulting \corpus{-ization} is completely fine.
    \item A variant of the realizational incompatibility problem is 
    not due to phonology, but (possibly hostorical) stylist reasons.
    The combination \corpus{*-ness-al} isn't good,
    because \corpus{-ness} is of Germanic origin,
    while \corpus{-al} is of Romance origin.
    Thus, usually the two affixes are not used together. TODO: why?
\end{enumerate*}

Certain -- although highly limited -- degree of recursion exists in English derivational morphology.
The sequence \corpus{-ize-tion-al} is an example.
The verb \corpus{renormalize} is a term in physics,
which means to systematically modify the effective values of constants in a theory 
when throwing away unneeded degrees of freedom 
(and a formally similar procedure used to solve divergence problems).
From it we have \corpus{renormalization},
and hence the adjective \corpus{renormalizational},
\translate{having something to do with renormalization,
or is expressed in the theoretical framework of renormalization}.
The form \corpus{*renormalizationalize} is not acceptable.
This however seems to come from the absence of a feasible meaning.
In a highly marked context,
where we talk about 
``how to make a theory that is usually not written down in the renormalizational framework
renormalizational'',
\corpus{renormalizationalize} is no longer completely unacceptable,
and hence we have \corpus{renormalizationalization} or even \corpus{renormalizationalizational}, etc.
The reason why people decide that such use of derivation is not authentic English is complicated:
It involves the tendency to reject long words, 
rejection of replication,
lack of established meaning,
and maybe even more.

It should also be noted that mismatch 
between the realization and the underlying structure 
is also possible in derivation.
The structure \corpus{[cross-language]-ic} is realized as 
\corpus{cross-linguistic}.
Here \corpus{linguistic} is not to be interpreted as 
``related linguistics'',
but merely a collective realization of the root \corpus{language} and the adjectivizer \corpus{-ic},
ignoring the real constituency structure.

\subsubsection{Compounding}\label{sec:pos.overview.derivation.compound}

Although there are prototypical ways to interpret a compound
when it is created for the first time,
most compounds have gained established meanings.



\subsection{Origin of words and roots}

Finally we discuss the sources of the lexicon inventory of English.

A generalization is Romance affixes are usually added before Germanic affixes,
which seems expected,
because the Germanic affixes are integrated parts of the grammar 
and interact naturally with external environments
(TODO: coordination of affixes, etc.),
while Romance affixes are not,
so Romance affixes are unable to appear at the edge 
between the inner structures of the lexeme and the external morphosyntactic surroundings.

\section{Nouns}

\subsection{Compound nouns}\label{sec:pos.noun.compound}

Compound nouns -- a compound where the two immediate constituents are all nouns -- 
can be divided into centered an non-centered ones
\citep[\citepages{1646-1648}]{cgel}.
The semantic relation between the two branches of a centered compound noun
is highly diverse; 
some compounding structures seem to be head-complement or head-modifier constructions,
while for others, what relates the two branches is merely ``aboutness'':
when an established meaning is absent,
the form A-B means ``B that has something to do with A''.
Non-centered compound nouns 
(or \concept{dvandva nouns}, which is the term in Sanskrit) 
are relatively rare
compared with the case in Sanskrit.

\subsubsection{Conditions for centered noun compouding}

The two constituents in a compound noun usually can't bear any inflection.
However, irregular plurals are sometimes permitted.
This means the threshold of noun compounding has a ``lightweight'' requirement:
The branch A \emph{has to} bear the ``category is noun'' feature,
but \emph{nothing more}.
Thus ordinary plurals have a number feature higher than the category feature 
and are excluded from engaging in noun compounding,
while in fused plurals like \corpus{mice},
the root, the noun category feature and the plural number feature 
are all realized into one unit,
so compounding is licensed \citep[\citesec{7.1}]{siddiqi2009syntax}

\subsection{Adjective-noun compounding}

An adjective-noun compound is usually a modifier-head structure, 
but not always: 
\corpus{sick-bed} receives an aboutness interpretation outlined in \prettyref{sec:pos.noun.compound},
where the adjective \corpus{sick} is used as a category-less root,
which means \corpus{sickness} here.

\subsection{Verb-centered compound nouns}\label{sec:pos.noun.compound.verb-centered}

\subsection{Deverbal nominalization}

Nominalization of a verb either gives a noun about the action or state described by the verb
\citep[\citepage{1700}]{cgel},
or gives a noun referring to an object or person 
that is a semantic argument of the verb \citep[\citepage{1697}]{cgel}.
The two kinds of nominalization are semantically similar to 
content clauses and relative clauses, respectively.
Thus, cross-linguistically, 
we often see nonfinite forms of a verb serving as 
its normalized forms,
either in the first meaning or in the second meaning mentioned above.
In English, the relative clause-like use of participles is rare, 
but the content clause-like use of participles is highly frequent
(\prettyref{ex:pos.noun.deverbal.1}, \prettyref{ex:pos.noun.deverbal.2}).

\begin{exe}
    \ex\label{ex:pos.noun.deverbal.1} {} [His playing the national anthem]_{\text{\corpuscat{ing}-participle complement clause}} amazed us.
    \ex\label{ex:pos.noun.deverbal.2} {} [His playing of the national anthem]_{\text{\corpuscat{ing}-nominalization}} is amazing.
\end{exe}

\subsubsection{Zero derivation}

the one doing something: \corpus{coach}, \corpus{spy}

the action of \corpus{read}, \corpus{go}, \corpus{attempt}

\section{Pronouns}

\subsection{Personal pronouns}

\subsection{Demonstratives}

\section{Numerals}

There are four types of numerals in English:
the cardinal numerals, 
the ordinal numerals,
the adverbial numerals,
and the multiplicative numerals.
There is no affixational derivation to show the rank or quality of something 
(which is attested in the Latin ordinal numeral plus \corpus{-Äris} derivation):
The meaning is conveyed by 

Cardinal numerals prototypically appear in \acs{np}s,
possibly in a 

\section{Adverbs and adverb phrases}\label{sec:pos.adverb}

Derivation into adverbs is terminal:
No further derivation is possible after that.

\subsection{Distributions}

Adverbs appear at the initial (\prettyref{ex:overview.adverb-1}) or
at the end of a clause (\prettyref{ex:overview.adverb-2}, \prettyref{ex:overview.adverb-5}), 
or in the verbal complex (\prettyref{ex:overview.adverb-3}, \prettyref{ex:overview.adverb-4}).
The verbal complex positions can be further divided into 
the positions after the first auxiliary (\prettyref{ex:overview.adverb-3})
and the position before the main verb (\prettyref{ex:auxiliary-chain-breaking-4}).
Similarly -- though less apparently -- 
there are also two types of clause final adverbs,
one with a pause in utterance, usually shown by a comma (\prettyref{ex:overview.adverb-2}),
the other without a pause (\prettyref{ex:overview.adverb-5}).
All the five positions -- actually there are further subtypes -- have structural and meaning differences
(\prettyref{tbl:clausal-dependent}):
(\prettyref{ex:overview.adverb-1}, \prettyref{ex:overview.adverb-2}) 
are in the speech act-related positions,
(\prettyref{ex:overview.adverb-3}, \prettyref{ex:overview.adverb-5}) 
are in the manner-like positions,
and (\prettyref{ex:overview.adverb-4}) 
is in the \acs{tam}-related region.

\begin{exe}
    \ex\label{ex:overview.adverb-1} [Strikingly], he is a liar.
    \ex\label{ex:overview.adverb-2} He is quite smart, [frankly].
    \ex\label{ex:overview.adverb-5} He finished the task [quite cleverly].
    \ex\label{ex:overview.adverb-3} He might [now] be hoping to skip the test.
    \ex\label{ex:overview.adverb-4} If you were me, you would have [smartly] answered the question.
\end{exe}

\subsection{Origins}

\subsubsection{The \corpus{-ly} derivation}

TODO: terminal derivation; only \corpus{-c-al-ly} is acceptable,
except \corpus{puclicly}.

\section{Prepositions}

Prepositions are usually regarded as extensions of the case system 
\citep[\citesec{5.4}]{dixon2009basic1}.
From this perspective, in a surface-based analysis,
we should do away with the term \term{preposition phrase},
because in this case prepositions aren't lexical heads
(they are realization of functional heads
and therefore are markers of grammatical relations 
in a surface-oriented analysis).
Some English prepositions can indeed be seen as such,
but there are more complicated cases.
Prepositions can take modifiers (\prettyref{ex:np.pp.ex-1}),
and may be stacked in limited cases (\prettyref{ex:np.pp.ex-2}).
The prepositions in the above cases also 
seem to have lexical meanings instead of mere grammatical functions.
Also, prepositions can be attached to non-\acs{np} constituents \citep[\citepage{609}]{cgel},
The prepositional constructions in English therefore deserve more careful treatment.

\begin{exe}
    \ex\label{ex:np.pp.ex-1} The spot is [[ten meters]_{\text{degree}} [behind]_{\text{preposition}} the house]_{\text{\acs{pp}}}
    \ex\label{ex:np.pp.ex-2} The sample is collected [from under] the glacier.
\end{exe}

TODO: case-like preposition, place preposition, path preposition \citet{spatialpp}

\subsection{Distributions}

TODO: copular PP and adverbial PP

\subsection{Comparison with adjectives and adverbs}

The word \corpus{worth} has an exceptional property
that makes it similar to prepositions:
It takes an \acs{np} complement directly.
The overall properties however are still adjectival \citep[\citepage{607}]{cgel}.

\begin{exe}
    \ex The paintings are worth thousands of dollars.
\end{exe}

\chapter{The structure of the noun phrase}\label{chap:np}

\section{Overview}

\subsection{The template of the noun phrase}\label{sec:np.template}

As is said in \prettyref{sec:overview.constituent-order},
English has a pretty rigid surface constituent order,
directly reflecting the inner structure of \acs{np}s.
Top-level layers of the noun phrase is given in \prettyref{fig:np-template}.
Note that although traditionally, complement clauses are regarded as \term{nominal clauses},
this notion is given up in this note,
because the inner structure of complement clauses is too different from prototypical \acs{np}s,
and they are therefore excluded from the class of \acs{np}s.

\begin{figure}[H]
    \centering
    \input{templates/np.tex}
    \caption{The structure of English noun phrase (the indentation means linear order and not constituency relations)}
    \label{fig:np-template}
\end{figure}

It should be noted that the positions listed above are about function and not form.
And it's also not guaranteed that 
each position has to be filled by an independent word.
The demonstrative \corpus{these}, for example, 
may appear as a determiner, 
but may also appear in a fused-function construction,
covering the functions from the head to the determiner
(\prettyref{sec:np.fused-head.dem}).


\subsubsection{The template of the nominal}

In \prettyref{fig:np-template}, 
I set up a level called \concept{nominal} (\prettyref{sec:np.nominal}),
following the notation in \citet[\citepage{329}]{cgel}.
It's possible for a nominal to appear without any determiner
as an attributive,
but not an \acs{np} (\prettyref{sec:np.nominal.nominal-attributive}).
The statuses of the attributives are not the same:
TODO: ref

\subsubsection{The determiner-like region}

Above the nominal layer, 
we have a series of determiner-like grammatical functions,
filled by various forms (\prettyref{sec:np.det}).
In this note, 
I define the prototypical grammatical function of articles, demonstratives, 
and ``determining'' possessives as the \concept{central determiner}.
I also assume a quantification function over the determiner function
to account for expressions like \corpus{all the things},
where \corpus{all} is the syntactic quantifier and \corpus{the} the central determiner.

\begin{theorybox}{The determiner-like region or the DP field}{cartography-dp}
    The higher determiner-like region corresponds to the DP domain,
    which contains D_{\text{det}} (the DP version of FinP; \prettyref{sec:np.det.definite}),
    the quantifier Q position (\prettyref{sec:np.det.quantifier}),
    which is placed over the determiner \citep{gianollo2021reference},
    the DP version of topic (\prettyref{sec:np.det.specific}),
    and the D_{\text{deixis}} position (\prettyref{sec:np.det.deixis}),
    which corresponds to the ForceP in the CP domain
    and is about whether the DP is referential, etc.,
    quite similar to the way ForceP expresses what the clause is intended for
    \citep{laenzlinger2005french}.
    Note that in English we don't have \acs{np}-inside topics and focuses,
    between D_{\text{deixis}} and D_{\text{det}},
    although some Romance languages allow them.
\end{theorybox}

\begin{infobox}{About \term{determiners} and \term{predeterminers}}{predeterminers}
    \citet[\citepage{331}]{cgel} takes a slightly different definition of the term \term{determiner},
    and it also recognizes a syntactic function called the \term{predeterminer}.
    The rules seem to be the follows: 
    If there is no article or demonstrative or any other thing that is prototypically a determiner,
    then the lowest determinative is the determiner;
    otherwise the article or demonstrative or \dots is the determiner,
    and determinatives lower than it are modifiers.
    Thus, in \corpus{the three cute cats},
    \corpus{three} is a modifier, while \corpus{the} is the determiner 
    \citep[\citepage{356}, {[4ii]}]{cgel},
    although in \corpus{three cute cats}, \corpus{three} is the determiner 
    \citep[\citepage{355}, {[2ii]}]{cgel}.
    In \corpus{all vases}, \corpus{all} is the determiner,
    while in \corpus{all the vases}, \corpus{all} is the predeterminer
    \citep[\citepage{356}, {[4i]}]{cgel}.

    I find the term \term{predeterminer} unnecessarily complicate the matters,
    and to say something is a predeterminer 
    tells us nothing about its position in \prettyref{fig:np-template}
    or its possible semantic interpretations.
    Predeterminers in \citet[\citepage{433}]{cgel}
    all seem to be some kind of quantification,
    so I just skip the term \term{predeterminer} in \prettyref{fig:np-template},
    and explicitly inserts a quantifier position.

    On the other hand, the analysis that the cardinal numeral is the determiner
    when there is no other determiner
    does make some sense,
    because it seems the article \corpus{a} is very similar to 
    the numeral \corpus{one} without \corpus{the},
    and therefore a cardinal numeral without a higher determiner 
    appears to be an indefinite determiner.
    An alternative analysis is to assume that 
    the so-called article \corpus{a} in fact a specific cardinal numeral
    \citep[\citesec{2.5}]{lyons1999definiteness}.

    So, a wise terminology is to replace the term \term{predeterminer} with \term{quantifier}.
    Since some grammars use the term \term{determiner} to cover all determiner-like grammatical functions,
    \citet[\citepage{253}]{quirk1985} call the position prototypically filled by 
    articles and demonstratives 
    the \term{central determiner}. TODO: whether to use this notation
\end{infobox}

\subsubsection{Peripheral syntactic functions}

The layer of \concept{peripheral modifiers} contains 
various high-level syntactic functions,
filled by adverbs like \corpus{even} or \corpus{alone},


\subsection{The syntax-semantics interface}\label{sec:np.semantics}

The surface realization of the template \prettyref{fig:np-template} 
is not the same as the underlying structure
because of fused-function constructions (TODO: ref),
and the semantic interpretation of even the underlying structure 
is not a direct translation.
When, for example, there is no syntactic quantifier,
the \acs{np} still receives semantic quantification.
This section talks more about how to understand the meanings of \acs{np}s.

The (final, not immediately -- see \prettyref{box:quantifier-definite}) 
interpretation of a form \corpus{\dots something \dots} basically is 
\translate{$\forall/\exists x$ ($x$ is something $\land$ \dots $x$ \dots)};
we may add more branches containing $x$ after the logical quantifier.
Thus, the meaning of an \acs{np} 
is to leave a logical variable at its position
introduce a conjunctive branch like \translate{$x$ is a student}
introduce a quantifier to bind the variable,
and probably change the context of conversation.
Below is an example of this procedure.
\begin{enumerate}
    \item The sentence \corpus{[students] usually take [at least four courses] [each year]}
    -- which contains three \acs{np}s -- 
    is to be interpreted as 
    \translate{$\forall x (
        \text{is-student} (x) \land 
        x \in \text{context } \land$
        $x$ usually take at least four courses each year)}.
    \item The part \corpus{$x$ usually take at least four courses each year} 
    is in turn interpreted as 
    \translate{$\forall y (
        \text{is-year}(y) \land 
        \exists e (
            \text{time}(e, y) \land 
            \text{frequency} (e, \text{habitual}) \land 
            \text{$x$ takes at least four courses in the event $e$})
    )$}.
    \item The part \corpus{$x$ takes at least four courses in the event $e$} 
    can further be interpreted as 
    \translate{$
        \exists S (
            |S| \geq 4 \land 
            S \subseteq \text{all-courses} \land 
            \text{action}(e, \text{take}) \land 
            \text{agent}(e, x) \land 
            \text{patient}(e, S)
        )
    $}.
    The number 4 here can further be expanded into things like 
    \translate{$
        \exists c_1, c_2, c_3, c_4 (
            \text{$c_1, c_2, c_3, c_4$ are all different} \land 
            \cdots
        )
    $}.
\end{enumerate}

Despite simple, the interpretation procedure outlined above 
shows several semantic parameters that are especially important 
in interpreting \acs{np}s.
They are listed below.

\subsubsection{Definiteness}

The coverage of a nominal can be extremely huge.
to decide what are being talked about,
a simple way, which is used in the above example, 
is to add quantification on them.
but the speaker/writer may instead invite the listener/reader to 
identify the object(s) referred by the \acs{np} 
from the conversational context
and/or some uniqueness conditions.
The usual syntactic device to send such an invitation 
is \concept{definiteness} 
(in this note, it's the determiner function),
and the corresponding semantic concept is called \concept{identifiability}
(\prettyref{sec:np.det.definite}).

\begin{theorybox}{The weakness of the naive theory of description}{theory-of-description}
    The fact that definiteness implies identifiability has long been noticed in the study of semantics.
    Russell's theory of description interprets \corpus{the} 
    as a logical symbol $\iota$,
    and $Q(\iota x P(x))$
    means $\exists x (P(x) \land Q(x) \land \forall y (P(x) \land P(y) \rightarrow  x = y)) $.
    This is a neat approximation of the definiteness concept,
    but still has some subtle differences from definiteness in natural languages.
    When the uniqueness condition is broken, 
    usually we don't say the sentence has a false truth-value:
    We say it doesn't make sense at all.
    (Some may develop more delicate logic systems to handle this,
    but I feel this is not necessary:
    as is outlined in \prettyref{sec:semantics.side-effect},
    I guess natural language sentences are more like 
    ``commands'' in imperative programming than logical expressions,
    and of course a subroutine can throw an error and give no return value.)
    The position of this note is 
    theory of description is not one hundred percent correct,
    and is better replaced by a contextual account \citep[\citepage{368}]{cgel},
    though the techniques used in the theory of description
    are of course of great importance:
    We may, for example, correct the description theory 
    by letting $P$ be the mix of the interpretation of a nominal and contextual information.
\end{theorybox}


\subsubsection{Quantification}

In mathematics, quantification 
is about bound variables,
while definiteness 
is essentially a template which 
maps a predicate to a set (\prettyref{box:quantifier-definite}).
In natural languages, there are some differences.

The first difference is 
what looks like quantification in natural languages 
involves two parameters:
one is the universal-existential distinction
(as in mathematics),
the other is the joint-distributive distinction.
The speaker/writer may only talk about a certain part of the objects retrieved
from the conversational context (universal), 
or he or she may talk about all of them (existential).
The object denoted by \acs{np} may jointly participate in the predication (joint)
so that it's not correct to say 
one object participate in the predicate,
or maybe individually (distributive).
Ambiguity may occur here.
Someone says the student selects four courses -- 
does it mean the student takes the four courses one by one in the course selection system
(distributive), 
or does it mean the student selects the four courses at once 
(by, say, using the worksheet of the course selection system)?

The second difference is 
syntactic marking of quantification can be applied on top of definiteness:
We have \corpus{all the things I've heard about} 
and \corpus{both the parents}:
Quantification can act as a ``filter'' 
to further filter what is retrieved from the conversational context.
The reverse is not possible, 
possibly for semantic reasons.

\subsubsection{Referentiality}\label{sec:semantic.ref}



\subsection{Definiteness}\label{sec:semantic.definite}


\section{The (extended) noun}\label{sec:np.head}


\section{The structure of nominals}\label{sec:np.nominal}

\subsection{Nominal attributives}\label{sec:np.nominal.nominal-attributive}

A \concept{nominal attributive} is an attributive that is a nominal.
There seems to be a tendency that 
a nominal attributive should normally be ``small'' enough:
It can contain adjectives or another nominal attributive,
but the modification construction usually has an established meaning
and is regarded ``as a word''. TODO: more precise definition

\begin{exe}
    \ex {} [The [Ministry of Defense]_{\text{nominal attributive}} officials]_{\text{\acs{np}}} are having a secret meeting in that room.
    \ex We planted [an [apple]_{\text{nominal attributive}} tree]_{\text{\acs{np}}} yesterday.
    \ex {} [The [[Fuji apple]_{\text{nominal attributive}}_{\text{nominal attributive}} tree] variety]_{\text{\acs{np}}} has a reddish-green color.
\end{exe}

\subsection{Adjectival attributives}

\subsection{Attributive possessives}

Possessive \acs{np}s can also serve as attributives. 

\begin{exe}
    \ex There are three teachers' books on the desk.
\end{exe}

\subsubsection{Interpretation of attributives: restrictive and non-restrictive}

If an attributive is removed in an \acs{np} 
and the reference of that \acs{np} remains the same,
we say it's non-restrictive.
Non-restrictive attributives are ``comments'' or ``afterthoughts'' concerning the reference of the \acs{np}.
In \corpus{members of the music club, 
[who have developed very close friendship], 
are all going to the same college},
the relative clause (TODO: ref) is not necessary to decide who the members of the music club are.

If the concept of definiteness were perceived according to Russell's theory of description 
(\prettyref{box:theory-of-description}),
then the distinction between restrictive and non-restrictive attributives 
would by definition be categorical:
Restrictive attributives are about uniqueness of the \acs{np}'s reference,
while non-restrictive attributives are not.
The position of this note is however more contextualist,
TODO: how we treat 
Of course, \emph{some} attributives are still bound to be restrictive 
or non-restrictive for various reasons:
If an \acs{np} is definite, 
TODO: why removing some attributives makes a definite NP unnatural??
(TODO: ref).

\subsection{Ordering and compatibility of attributives}

\subsection{Cardinal numerals}

There can be zero or one cardinal numeral in a nominal,
and it always appears over all attributives.

\begin{exe}
    \ex 
\end{exe}

\section{The determiner and the like}\label{sec:np.det}

One typological property of English is 
the prominence position of determiner,
as opposed to some other Indo-European languages, like Latin.
In Latin the determiner -- like a demonstrative -- 
looks just like an attributive:
Morphologically speaking, it has the adjectival declension pattern
(there is no such thing as an article category),
and its surface position in the \acs{np} 
is as flexible as other attributives,
modulated by the information structure.
In English, on the other hand, we have prototypical fillers of the determiner position
-- articles \corpus{a} and \corpus{the} -- 
and 

\subsection{The determiner function and the identifiability meaning}\label{sec:np.det.definite}

\subsubsection{The articles \corpus{the}}

There are several degrees of identifiability that may be conveyed by \corpus{the};
with low-degree identifiability, 
the reference of an \acs{np} containing \corpus{the} is 
to be decided partially by its inner attributives and partially by the context.

Logical uniqueness is the strongest, 
but this is usually constrained to mathematical objects
(\prettyref{ex:np.det.math-1}).
Uniqueness from empirical observation or man-made rules is slightly weakened:
The article \corpus{the} in (\prettyref{ex:np.det.decline-to-comment})
is almost never replaced by \corpus{a},
because for almost all companies,
the CEO position is unique.

A further weakened version is uniqueness in the conversational context.
In \eqref{ex:np.det.conversation-1}, 
of course the speaker isn't implying that there is only one T-shirt in the world:
but if \emph{in the context of the conversation},
there is only one T-shirt,
then the sentence makes perfect sense.
This gives rise to the famous \corpus{a}-\corpus{the} alternation in discourses:
When a person or an object first appears,
\corpus{a} is used,
and then the entity is referred to with \corpus{the}.

But even this can be loosen:
It may be the case that there are several entities in the conversational context
that satisfy the conditions,
but it's OK to randomly pick up one,
and this is still a kind of identifiability.

\begin{exe}
    \ex\label{ex:np.det.math-1} [The set containing no element] is [the empty set].
    \ex\label{ex:np.det.decline-to-comment} The CEO of this company declined to comment.
    \ex\label{ex:np.det.conversation-1} Pass [the green T-shirt] to me.
\end{exe}

\subsubsection{The abstract generic usage of \corpus{the}}

\begin{exe}
    \ex I like playing the guitar.
    \ex The computer replaces the typewriter.
    \ex The kangaroo lives in Australia.
    \ex The dermatologist specializes in skin care.
\end{exe}

Modification also destroys the possibility of the abstract generic reading.
This is also a piece of evidence that 
there are more fine-grained structure within the nominal,
specifically, an ``extended noun'' (TODO: ref).

\begin{exe}
    \ex *The towel absorbs water.
    \ex I like playing the high-quality guitar. \\
    \translate{I like play that specific guitar that has high quality.
    / *I like play all high-quality guitars.}
\end{exe}

\subsubsection{The subject-determiner possessives}

Note that the possessive \acs{np} is also a complement or ``argument''
of the head noun,
and in some morphologically rich languages,
the possessive \acs{np} is indeed marked as an argument 
\citep[\citesec{5.1.2.1}]{jacques2021grammar}.
Thus we may say the possessive is the subject in the \acs{np},
and it's therefore the subject-determiner \citep[\citepage{467}]{cgel}.

\subsubsection{\corpus{We} and \corpus{you} as determiners}

\begin{infobox}{About \corpus{we the people}}{we-the-people}
    Not all personal pronouns appearing at the initial of an \acs{np}
    are determiners.
    In \corpus{we the people}, 
    \corpus{we} seems to be TODO: appositive
\end{infobox}

\subsubsection{Indefiniteness and numerals as determiners}

Indefiniteness is the opposite of definiteness,
and occurs whenever identifiability can't be established.

The function of \corpus{a} 
and the function of \corpus{one} when there is no other determinative in the \acs{np}
seems to be the same \citep[\citepage{372}]{cgel},
which may be the reason why \citet[\citepage{385}]{cgel} claims 
the numeral sometimes is the determiner. TODO: so what should be my analysis?

It should be noted that there is something asymmetric between definiteness and indefiniteness.
A definite \acs{np} directly refers to some objects \emph{on its own},
while an indefinite \acs{np} doesn't:
It may gain specificity from the context (TODO: ref), 
but itself doesn't have specific reference.
Thus, an indefinite \acs{np} \emph{always} introduces a bound variable when interpreted 
and involves quantification,
while a definite \acs{np} doesn't necessarily involve quantification.
The status of indefinite is not the same as the status of definite semantically,
and also possibly syntactically \citep{gianollo2021reference,klockmann2020article}

\begin{theorybox}{About the ``quantifier-less'' interpretation of definite \acs{np}s}{quantifier-definite}
    The end of \prettyref{box:theory-of-description}
    shows that even in the contextualist approach taken in this note,
    an existential quantifier can still bind the logical variable introduced by a definite \acs{np},
    so in the first glimpse, 
    definiteness and indefiniteness has nothing different concerning quantification.
    But for a definite \acs{np},
    in principle, 
    \emph{immediately after it is interpreted},
    it's possible that we don't see any quantifier introduced:
    The interpretation of a subject \acs{np} 
    may just be \translate{$P(\text{concept-to-set}(\text{interpretation-of-nominal}))$},
    where $P$ is the interpretation of the \acs{vp} (in the sense of this note).
    Of course, to \emph{finally} eliminate the function concept-to-set, 
    we still need to use the techniques in \prettyref{box:theory-of-description}
    and introduce quantifiers,
    but it's not the \emph{immediate} result of interpreting the definite \acs{np}.
    On the other hand, 
    for an indefinite \acs{np},
    its \emph{immediate} interpretation \emph{always} comes with a logical quantifier.
\end{theorybox}

\subsection{Syntactic quantifiers}\label{sec:np.det.quantifier}

Syntactic quantifiers in English are given by \citet[\citepage{361}, {[9]}]{cgel},
replicated here:

\subsubsection{The quantifiers}

\subsubsection{The negative polarity items}

The \corpus{any} family

\begin{theorybox}{Is the semantico-pragmatic approach correct?}{npi-semantic}
    One problem is whether we are heading to the wrong direction here.
    It may just be the case that the distribution of \corpus{any}, \corpus{anyone}, etc. 
    is determined by syntactic factors.
    Indeed, usually people consider the misuse of these items 
    a \emph{grammatical} problem 
    instead of a logical or feasibility problem
    \citep[\citepage{812}]{zeijlstra2013}.
    \corpus{I know the current King of France} is of course wrong,
    but it's valid;
    \corpus{*I know anything about this topic} is grammatically wrong.
    This criticism however doesn't kill the semantico-pragmatic approach,
    because the latter focuses on the syntax-semantic interface 
    instead of purely semantic or pragmatic issues.
    Using the programming language metaphor,
    misusing negative polarity items doesn't break AST generation,
    but it does break the compiling procedure
    because the AST can't be mapped to machine codes.
    For ordinary people, the machine of grammar contains the syntax proper-LF interface.
    A comparable example is the English \corpus{wa}-\corpus{ga} alternation,
    which seems to be motivated pragmatically 
    but is usually regarded as a part of the grammar.
\end{theorybox}

\subsection{Specificity}\label{sec:np.det.specific}

It should be noted that definiteness doesn't necessarily imply \emph{specificity},
because while any kind of specificity implies identifiability, 
the weakest sense of identifiability 
is not specificity;
and specificity -- or more generally, identifiability -- 
also doesn't imply definiteness.
In \corpus{a man was sent to hospital after the shooting}, 
\corpus{a man} usually receives a identifiable reading 
because of scalar implicature: 
If I say there is one man sent to hospital,
then it's highly unlikely that I mean there are two men sent to hospital.
So there is sort of a uniqueness condition concerning \corpus{a man}.
But still, we use the indefinite article \corpus{a},
because the nominal \corpus{man} itself 
isn't enough for us to retrieve who is sent to hospital from the conversational context
(while, say, even if Tom's father is unknown to us,
we know there is someone -- and likely only one -- who is his father,
so \corpus{Tom's father} still fixes the reference).

\begin{infobox}{Specificity as a syntactic function}{syntax-specificity}
    Here in English, 
    specificity is purely semantic.
    Cross-linguistically, the semantic concept of specificity 
    may be realized by a syntactic function
    higher than the determiner,
    which also serves as the ``\acs{np}-inside topic'' position 
    \citep{ihsane2001specific},
    which is absent in English.
\end{infobox}


\subsection{Referentiality}\label{sec:np.det.deixis}

Another semantic parameter of \acs{np}s is whether it's referential,
i.e. whether its appearance introduces a new entry in the old information list 
that can be referred to by a following pronoun.
There is no explicit syntactic marking of referentiality in English.

Note that referentiality is not strongly coupled to determination or quantification:
Although the reference of an indefinite \acs{np} cab never be determined on its own 
(even with contextual information),
indefinite \acs{np}s are still referential.

\begin{exe}
    \ex {} [Teachers]_{\text{indefinite \acs{np}}, i} here are expected to be patient. 
    They_i shouldn't give up on a child too quickly.
\end{exe}

Non-referential usages of \acs{np}s are relatively limited.
The cases include negative \acs{np}s (TODO: ref), 
interrogatives (TODO), 
and meta-linguistic usages as in \corpus{[``Mary''] is a famous name for girls}
\citep[\citepage{400}]{cgel}.

\begin{infobox}{Referentiality as a syntactic function}{d-deixis}
    
\end{infobox}

\subsection{Ordering and compatibility}

The order of all determiner-like elements is highly rigid (\prettyref{tbl:det-region-template}).
The compatibility between them however shows certain degree of variations.

\begin{table}[H]
    \caption{Possible values of the determiner-like region}
    \label{tbl:det-region-template}
    \centering
    \begin{tabular}{llll}
    \toprule
    Quant.       & Det.                     & Num.                        & Nominal            \\ \midrule
    \corpus{}    & \corpus{}                & \corpus{}                   & \corpus{things}    \\
    \corpus{}    & \corpus{}                & \corpus{a/one}              & \corpus{thing}     \\
    \corpus{}    & \corpus{}                & \corpus{two/three/four/...} & \corpus{things}    \\
    \corpus{all} & \corpus{}                & \corpus{}                   & \corpus{things}    \\
    \corpus{all} & \corpus{}                & \corpus{three/four/...}     & \corpus{points}    \\
    \corpus{all} & \corpus{the/these/those} & \corpus{}                   & \corpus{things}    \\
    \corpus{all} & \corpus{the/these/those} & \corpus{three/four/...}     & \corpus{things}    \\
    \corpus{}    & \corpus{we/you}          & \corpus{}                   & \corpus{engineers} \\ \midrule
    \end{tabular}
\end{table}

\section{Peripheral modifiers}

\section{Possessive constructions}

Possessive \acs{np}s appear in TODO

\section{Fused-head constructions}\label{sec:np.fused-head}

A fused-head \acs{np} is an \acs{np} in which the function of the main noun 
-- the (lexical, not functional) head -- 
is fulfilled by another constituent.
We know \corpus{all} in \corpus{[all] of these statements}
carries the function of head as well as its usual function of quantification,
because it selects complementation (\corpus{of these statements}):
Compare, say, \corpus{all [instances]_{\text{head}} of these statements}
(and also because of the theoretical orientation of this note 
that the ``noun category'' feature has to be realized by something).

Fused-head constructions allow less variations than ordinary \acs{np}s.
For example, when the quantification and the head is fused,
modifications are no longer possible.

\subsection{Personal pronouns}

\begin{exe}
    \ex\label{ex:np.fuse.negative-np-1} *[No car in the race]_i broke down and [it]_i had to be repaired.
\end{exe}

\begin{theorybox}{Pronouns are not gap fillers}{pronoun-not-gap-filler}
    Pronouns are not residue of \acs{np}s moved out,
    even with coreferential relations.
    In (\prettyref{ex:np.fuse.negative-np-1}),
    for example, if the pronoun \corpus{it} can be analyzed by the trace left by \corpus{no car in the race},
    then there is no reason for the unacceptability.
    This means coreferences are not always generated by movement.
\end{theorybox}

\subsection{Demonstratives}\label{sec:np.fused-head.dem}

\section{Preposition constructions}


TODO: \corpus{in spite of} is an established form but still has a synchronically meaningful constituency structure


\chapter{Verb inflection and \acs{tam} marking}\label{chap:verb-inflection}

This chapter is the first chapter concerning clausal structure.
Some forward references are unavoidable when we decompose a clause into its parts
and describe its parts and then assemble everything together,
and the latter is described in \prettyref{chap:simple-clause}.

\section{Overview of the verb paradigm}

\subsection{Forms}

\subsection{Agreement}

\subsection{Overview of \acs{tam} parameters}

The \emph{semantics} of an event or a state -- 
a \concept{situation} -- is roughly summarized below:
\begin{enumerate}
    \item First we consider the (objective) inner structure of the situation.
    It may be classified according to \citet[\citepage{118}, {[6]}]{cgel}.
    \item The second parameter is 
    how this situation is referred to by a clause. 
    The clause may represent the situation as a whole (\concept{perfective}),
    or it may just only refer to a small region in the situation (\concept{imperfective}).
    \item TODO: habitual, frequency, etc. 
    \item Finally, we package the references of the clause into a single point, 
    and compare the position of this point and the ``speech time'' 
    (for more details see 
    \prettyref{sec:verb-inflection.tenses}).
    This corresponds to the concept of tense.
\end{enumerate}

An example of this procedure can be found in (\prettyref{ex:verb-inflection.semantics.1}),
which contains the imperfective, habitual, and simple present concepts. 
The semantics is visualized in \prettyref{fig:semantics-tam-1}.

\begin{exe}
    \ex\label{ex:verb-inflection.semantics.1} He [is usually having] lunch at this moment. 
\end{exe}

\begin{figure}[H]
    \centering
    \input{processes/tam-1.tex}
    \caption{The semantics of (\prettyref{ex:verb-inflection.semantics.1})}
    \label{fig:semantics-tam-1}
\end{figure}

It should be noted again that the above concepts are semantic,
or to be precise, 
they lie at the interface between the grammar and semantics.
Thus, a \emph{semantically} imperfective situation 
is not always coded in a \emph{syntactic} construction 
that prototypically express a semantically imperfective situation
(and thus the construction may be called a \term{imperfective construction}).

Still, there is a strong tendency TODO: cartography
Indeed, \prettyref{fig:semantics-tam-1} can be seen as 
the interpretation procedure of (\prettyref{ex:verb-inflection.semantics.1}).
Similar to \prettyref{sec:valency.overview.steps}, 
we need a three-step or four-step model to account for the \acs{tam} system:
\begin{enumerate*}
    \item The surface constituent order of all the markers;
    \item A level deeper, 
    the clausal dependent positions of them;
    \item The syntactic positions where they originate from,
    which are closely linked to semantic concepts
    (this is important for analysis of \acs{tam} adverbs -- see below --
    because adverbs can be moved for information structural reasons), and 
    \item The purely semantic concepts,
    which may and may not be expressed by the last step.
\end{enumerate*}

Not all \acs{tam} semantic concepts are coded as inflection or auxiliary verb constructions.
Some, however, are marked by adverbs that have a fixed position 
compared with auxiliary verbs (\prettyref{sec:verb-inflection.adverb-auxiliary-chain}).
The adverb \corpus{usually}, 
for example, is a marker of the habitual concept, 
and its position seems quite rigid compared with other \acs{tam} adverbs (TODO: ref).
Note that the (syntactic) habitual category still shows some level of compositionality 
with other \acs{tam} categories. 
(\prettyref{ex:verb-inflection.overview.1}), 
retrieved from \ac{coca}, 
is a rare example containing 
a habitual adverb \corpus{usually}, 
the present perfect tense i.e. the \corpus{have done} construction,
and the progressive aspect i.e. the \corpus{be doing} construction.

TODO: cross-linguistic ?

\begin{exe}
    \ex\label{ex:verb-inflection.overview.1} So far, patients who received those tainted spinal epidural injections [have usually been showing] symptoms within a 30-day window.
\end{exe}

\section{Inflectional forms}\label{sec:verb-forms}

\subsection{Lexical verbs}

\begin{theorybox}{Inflectional forms are about realization and not underlying structure}{morphological-form}
    Traditional grammars usually have a large paradigm
    with its row and column headers being grammatical categories.
    (When there are too many categories 
    -- and in this case the language in question is usually agglutinative -- 
    the paradigm will be unbearably large, 
    and another way -- like the School Grammar of Japanese -- is needed to cover verb inflection.
    Still, partial paradigms are useful in this case.) 
    This is a morphosyntactic way to represent the inflection of a word, 
    but if we are talking purely about the \emph{morphological} part
    (i.e. how grammatical relations and categories are realized),
    then it's sometimes not necessary to recognize so many forms:
    If a verb appears exactly the same in two different syntactic environments,
    then we say there is only one \emph{inflectional form} of that verb.
    For languages like Latin, 
    the traditional large-paradigm way is handy,
    while for English, we can zip the paradigm severely \citep[\citechapsec{3}{1.2}]{cgel}.
\end{theorybox}

Modern English has already lost most of its verb inflection.
Following the analysis of \citet[\citechapsec{3}{1.1}]{cgel},
for lexical verbs,
there are six remaining inflectional forms: 
the past form, the plain present form, 
the 3sg present form,
the plain form, the \corpuscat{ing}-participle,
and the \corpuscat{ed}-participle.
The two present forms and the past form appear solely 
with trivial aspectual values and trivial modality.
They are \concept{primary} forms:
They already have all \acs{tam} categories marked on them.
The plain form and the two participles are \concept{secondary} forms:
They usually appear after auxiliaries 
in a periphrastic construction to have full \acs{tam} marking,
though a subjunctive clause may sometimes get rid of any auxiliary verb,
as in \corpus{he suggests that she [complete] this task first} (\prettyref{sec:complement.subjunctive}).

Examples of these forms are illustrated in \prettyref{tbl:lexical-inflection}. 
This is a copy of [1] in \citet[\citesec{1.1}]{cgel}.
It can be noticed that the plain form is usually the same as the plain present form.
However, since modal verbs (see below) have no plain form,
and that the syntactic environments of the plain form and the present plain form are too different,
if \prettyref{tbl:lexical-inflection} is to be regarded as a paradigm
-- that is, to be incorporated with morphosyntactic information -- 
then the two forms should occupy two cells.

\begin{table}[H]
    \caption{Paradigms of lexical verbs}
    \label{tbl:lexical-inflection}
    \centering
    \begin{tabular}{@{}llllll@{}}
    \toprule
    \multicolumn{1}{l}{}       &                               &       & \corpus{take}   & \corpus{want}    & \corpus{hit}     \\ \midrule
    \multirow{3}{*}{Primary}   & past form                     &       & \corpus{took}   & \corpus{wanted}  & \corpus{hit}     \\
                               & \multirow{2}{*}{present form} & 3sg   & \corpus{takes}  & \corpus{wants}   & \corpus{hits}    \\
                               &                               & plain & \corpus{take}   & \corpus{want}    & \corpus{hit}     \\ \midrule
    \multirow{3}{*}{Secondary} & plain form                    &       & \corpus{take}   & \corpus{want}    & \corpus{hit}     \\
                               & \corpuscat{ing}-participle       &       & \corpus{taking} & \corpus{wanting} & \corpus{hitting} \\
                               & \corpuscat{ed}-participle        &       & \corpus{taken}  & \corpus{wanted}  & \corpus{hit}     \\ \bottomrule
    \end{tabular}
\end{table}

\begin{infobox}{The name of the forms}{verb-form-name}
    Here I deviate from the practice in \citep[\citechap{3}]{cgel} 
    and pick up the more common names for some of the forms. 

    The \corpuscat{ing}-participle is frequently called the \term{gerund},
    because it now has the function of both a gerund and an active participle.
    \citet{cgel} call it the \term{gerund-participle}.
    Some grammars use the term \term{present participle}.
    Since in Modern English,
    the \corpuscat{ing}-participle no longer carries any tense information,
    the historical term \term{present participle} is abandoned in this note.

    The traditional name \term{past participle} for the \corpuscat{ed}-participle makes more sense,
    because it's morphologically related to the past form for regular verbs 
    and it still has some sense of ``past'':
    It is strongly related to the \category{perfect} and therefore has some sense of the past,
    though it doesn't carry the past tense.
    A better term would be the one in Latin grammar: the \term{perfect passive participle},
    but this is in conflict with the name of the \corpus{having been done} construction.

    A usual name for the plain form is the infinitive form,
    which I reject here because the morphological marking of 
    the main verb after modal auxiliary verbs  
    (\corpus{would [like]}),
    the verb in a subjunctive clause 
    (\corpus{he suggests that she [complete] this task first}),
    and the verb in a real infinitive clause are all the same,
    and therefore it makes no sense to use the term \term{infinitive} 
    to cover the \emph{morphological} form of all the three.
\end{infobox}

The \corpuscat{ing}-participle is regularly formed by adding \corpus{-ing} to the end of the plain form
(TODO: -tt- in splitting).
The \corpuscat{ed}-participle and the past form are usually obtained 
by adding \corpus{-ed} to the end of the plain form,
but for irregular verbs they can't be inferred from the plain form.
Thus English verbs have three \concept{principal forms}:
the plain form, the past form, and the \corpuscat{ed}-participle.
We may also say there are three stems in English:
the plain form, the past form, and the \corpuscat{ed}-participle,
with only the first one being productive for further morphological processes.

\subsection{Types of irregular verbs}

As is mentioned above, for a number of irregular verbs,
the \category{ed}-participle and the past form can't be inferred from the plain form.
Whether there are still some patterns between the three,
or in other words,
the formation of the principal parts,
is investigated in detail in \citet[\citepages{105-120}]{quirk1985}.

\subsection{Auxiliary verbs}\label{sec:verb-inflection.auxiliary}

English also has a number of auxiliary verbs (\prettyref{sec:auxiliaries}).
All auxiliary verbs have tense-dependent forms,
because all of them may appear as the first word in an auxiliary chain,
and the tense category is to be marked on the highest i.e. the first of them (\prettyref{sec:auxiliary-chain}).
Thus, we say English auxiliaries also have primary forms.
Modal auxiliaries don't have a separate 3sg present form,
but \corpus{do}, \corpus{have} and \corpus{be} (when used as auxiliary verbs) do.
It should be noted that the past forms of many auxiliary verbs don't just appear in past clauses:
They may have distinct meanings (\prettyref{sec:verb-inflection.modal-use}).

Modal auxiliaries don't have secondary forms,
probably because they never appear after another auxiliary verb 
or in nonfinite clauses,
but \corpus{do}, \corpus{have} and \corpus{be} do.

English auxiliary verbs also have negative forms,
which are obtained by attaching \corpus{-nt} to the end of auxiliary.
The \corpus{-nt} is a contraction form of the negator \corpus{not},
but in modern English the negative suffix moves together with the auxiliary in
subject-auxiliary inversion (\prettyref{sec:sai}).
Thus, it's recognized as a part of the auxiliary \citep[\citepage{91}]{cgel}.
This seems to be purely about phonetic realization:
There seems to be no large morphosyntactic differences 
between auxiliary-\corpus{not} and the negative auxiliary
besides subject-auxiliary inversion.
All auxiliaries don't have secondary negative forms,
though \corpus{do}, \corpus{have} and \corpus{be} have primary negative forms.

Since auxiliary verbs are a part of the grammar,
here I list the paradigms TODO

\begin{infobox}{Auxiliary constructions are single-clause ones}{auxiliary-single-clause}
    \citet{cgel} treat auxiliary verbs as verbs taking complement clauses 
    (as in, say, [11] in \citepage{782}).
    This is not the position of this note:
    Here I follow the standard practice in generative syntax (probably also American structuralism) 
    and assume auxiliary verb constructions are always single-clause constructions.
    \emph{Historically}, auxiliaries may origin from complement-taking verbs,
    but now \emph{synchronically}, they have the same function of inflectional affixations.
    Complement clause constructions may (or may not) have the same \emph{semantics} of 
    auxiliary verb constructions and inflectional affixations,
    but they never have the same \emph{structure}.

    The main reasons \citet{cgel} analyze auxiliary verbs as complement-taking verbs or
    \term{concatenative verbs} in their terms 
    are shown in their \citechapsec{14}{4.2.2}.
    However, these arguments are based on interpretation of constituency trees like
    \corpus{[would [like to do]]} as complement clause constructions,
    which doesn't necessarily hold.
    They also confuse lexical heads and (PF realization of) functional heads.
    They therefore bring in much inconsistency when they argue that 
    the complementizer \corpus{that} isn't a head.
    In this note, I follow \acs{blt}'s standard of headhood
    while fully being aware of the generative functional head analysis.

    Evidences supporting my claim that auxiliary constructions are indeed single-clauses ones 
    can be obtained by observing how auxiliaries interact with clausal dependents.
    If \citet{cgel} are correct on their claim that English auxiliary verbs take bare infinitive clauses,
    then we expect the verbal phrase after an auxiliary verb to receive any modification 
    that's acceptable for a bare infinitive clause.
    However, as we see in \prettyref{sec:verb-inflection.adverb-auxiliary-chain},
    there is a strong tendency for adverbs to appear after the first auxiliary,
    which can be easily explained by assuming the first auxiliary 
    undergoes some kind of fronting (\prettyref{sec:verb-inflection.negation}),
    or after all auxiliaries and before the main verb,
    and the functions of adverbs in the two positions 
    have clear correlation with the positions.
    This pattern are hard to account for 
    when we assume auxiliary verb constructions are complement clause constructions,
    because nothing motivates it.
    If, on the other hand, 
    auxiliary verb constructions are single-clause constructions,
    then we can say the distribution of adverbs and auxiliaries
    show is just the surface reflection of a deep functional hierarchy,
    just like the subject is somehow higher than the object.
\end{infobox}

\section{Periphrastic constructions with auxiliary verbs}\label{sec:auxiliaries}

\subsection{The regular auxiliary chain}\label{sec:auxiliary-chain}

\subsubsection{Minimal auxiliary chain}

In a declarative finite clause,  
the order of auxiliaries is constantly given by \prettyref{tbl:auxiliary-chain}.
\prettyref{tbl:auxiliary-chain} is a part of the larger picture of clause structure:
The auxiliary \corpus{do} (\prettyref{sec:verb-inflection.do}), 
adverbs (\prettyref{sec:verb-inflection.adverb-auxiliary-chain})
and the negator (\prettyref{sec:verb-inflection.negation})
may be inserted into somewhere between two auxiliaries.
Other types of clauses still largely follow the scheme but 
may undergo subject-auxiliary inversion (\prettyref{sec:sai}).

The auxiliaries positions can be filled by the corresponding auxiliaries or be just left blank,
without creating ungrammatical constructions.
The \category{modal} slot may be filled by a modal auxiliary.
The \category{perfect} slot may be filled by the auxiliary version of \corpus{have} with the correct inflection,
and the \category{progressive} and \corpus{passive} slots 
may be filled by the auxiliary version of \corpus{be} with the correct inflection.

The rules of inflection are the follows.
The tense category is always marked on the first auxiliary
(not necessarily one of the slots in \prettyref{tbl:auxiliary-chain}
-- it may be an inserted \corpus{do}),
and when there is no auxiliary,
it's marked on the main verb.
Note that it isn't true that if the first auxiliary is in the past form,
it always means a past event (\prettyref{sec:verb-inflection.modal-use}).
The modal auxiliary is always followed by a plain form,
and the progressive marking \corpus{be} is always followed by an \corpuscat{ing}-participle,
and the perfect marking \corpus{have} is always followed by an \corpuscat{ed}-participle,
and so is the passive marking \corpus{be}.
When the clause is finite and the tense is \category{present},
and the \category{modal} slot is empty,
if the subject is 3sg in number,
then the first non-empty slot in \prettyref{tbl:auxiliary-chain}
is in the 3sg present form,
which means for verbs other than \corpus{be}, the \corpus{-s} suffix is attached to it;
for \corpus{be} the correct form is \corpus{is}.
This is the only case subject-verb agreement happens in English 
other than the case of \corpus{be} (\prettyref{ex:verb-inflection.3sg-1}).
For \corpus{be}, the tense is still  TODO: subjunctive 

In nonfinite forms, the \category{modal} slot has to go;
the rest are still there, following the same inflectional pattern as is described above
(\prettyref{ex:verb-inflection.infinitive-1}).
Note that the subject-verb agreement is missing in all nonfinite clauses,
be it the third person singular \corpus{-s} or inflectional forms of \corpus{be}.

\begin{table}[H]
    \caption{The order of auxiliaries and some examples}
    \label{tbl:auxiliary-chain}
    \centering
    \begin{tabular}{@{}lllll@{}}
    \toprule
    \category{modal}      & \category{perfect}      & \category{progressive}        & \category{passive}            & main verb    \\ \midrule
    \corpus{}           & \corpus{}             & \corpus{}                   & \corpus{}                   & \corpus{takes}  \\
    \corpus{}           & \corpus{}             & \corpus{}                   & \corpus{am/are/is/was/were} & \corpus{taken}  \\
    \corpus{}           & \corpus{}             & \corpus{am/are/is/was/were} & \corpus{}                   & \corpus{taking} \\
    \corpus{}           & \corpus{have/has/had} & \corpus{}                   & \corpus{}                   & \corpus{taken}  \\
    \corpus{}           & \corpus{have/has/had} & \corpus{been}               & \corpus{being}              & \corpus{taken}  \\
    \corpus{will/would} & \corpus{have}         & \corpus{been}               & \corpus{being}              & \corpus{taken}  \\ \bottomrule
    \end{tabular}
\end{table}

\begin{exe}
    \ex\label{ex:verb-inflection.3sg-1} \begin{xlist}
        \ex I [like] this.
        \ex He [likes] this.
    \end{xlist}
    \ex\label{ex:verb-inflection.infinitive-1} 
    The award is reported [to have been being taken]_{\text{complement clause: \corpuscat{to}-infinitive}} 
    \ex\label{ex:verb-inflection.infinitive-2} 
\end{exe}



\subsubsection{\corpus{Do} insertion}\label{sec:verb-inflection.do}

\paragraph{Obligatory \corpus{do} insertion}

\corpus{Do} insertion happens in two circumstances.
The first is we need an auxiliary but there isn't one.
This is the case when we negate a clause with no auxiliary verb
(\prettyref{sec:verb-inflection.negation}),
and the case when subject-auxiliary inversion happens but there is no auxiliary verb
(\prettyref{sec:sai}).
In both cases, \corpus{do} is inserted before the main verb,
and is regarded as an auxiliary,
which carries the tense feature and the subject-verb agreement information
and is inflected accordingly
(\prettyref{ex:verb-inflection.do-1}, \prettyref{ex:verb-inflection.do-2}).

We may say the \corpus{do} is the default realization of the tense category and the agreement 
when these can't find an appropriate host.
It's roughly in the same position of \category{modal} in \prettyref{tbl:auxiliary-chain}.
Then, expectedly, adverbs can be inserted between \corpus{do} and the main verb
(\prettyref{ex:verb-inflection.do-3}).

\begin{exe}
    \ex\label{ex:verb-inflection.do-1} I do not like the gift. I don't like the gift.
    \ex\label{ex:verb-inflection.do-2} Did he enter the room that night?
    \ex\label{ex:verb-inflection.do-3} I do not particularly like that kind of flower.
\end{exe}

\paragraph{\corpus{Do} for emphasis} Unlike
(\prettyref{ex:verb-inflection.do-1}, 
\prettyref{ex:verb-inflection.do-2}, 
\prettyref{ex:verb-inflection.do-3}),
we can also just insert \corpus{do} to emphasize on the action,
and in this case the inserted \corpus{do} receives stress.
The morphology of \corpus{do} is the same as the obligatory \corpus{do} insertion,
and so is the distribution of adverbs.

\begin{exe}
    \ex Your company [\emph{do}]_{\text{\corpus{do} insertion}} [have]_{\text{main verb}} lots of rules!
\end{exe}

\subsubsection{Adverbs in the auxiliary chain}\label{sec:verb-inflection.adverb-auxiliary-chain}

The adverbs mentioned in this section are 
manner-like adverbs, \acs{tam}-related adverbs and speech act-related adverbs 
(\prettyref{sec:valency.overview.dependents}),
instead of adverbial peripheral arguments.
Adverbs are never inserted between the first auxiliary (if any) and the negator.
TODO: what else?

\begin{exe}
    \ex\label{ex:auxiliary-chain-breaking-1} 
    He [is]_{\text{\category{progressive}}} [vigorously]_{\text{TODO:}} [doing]_{\text{main verb}} [his job]_{\text{object}}. 
\end{exe}

\subsubsection{Negation in the auxiliary chain}\label{sec:verb-inflection.negation}

The rule of the negator \corpus{not} is close to the rule of adverbs: 
If \corpus{not} is used, it is \emph{always} after the first auxiliary
(while adverbs can appear before the first auxiliary in marked cases), 
which may be the inserted \corpus{do} (\prettyref{ex:auxiliary-chain-breaking-2}).
Any auxiliary-\corpus{not} sequence may be replaced by the negative form of that auxiliary
if there is one (\prettyref{ex:auxiliary-chain-breaking-4}, \prettyref{ex:auxiliary-chain-breaking-3}).

\begin{exe}
    \ex\label{ex:auxiliary-chain-breaking-2}
    He [does]_{\text{\corpus{do} inserted, pres, 3sg}} [not]_{\text{negation}} love his job.
    \ex\label{ex:auxiliary-chain-breaking-4}
    He doesn't love his job.
    \ex\label{ex:auxiliary-chain-breaking-3}
    He isn't vigorously doing his job.
\end{exe}

It should be noted the surface position of the negator doesn't determine the scope of negation
\citep[\citepage{668}]{cgel}.
See, for example, the ambiguity of (\prettyref{ex:verb-inflection.negation-ambiguity-1}).
Here the ambiguity is an indicator that 
there are at least two available syntactic position of the reason clause (TODO: ref).
Another ambiguity arises when negation appears together with modality
(\prettyref{ex:verb-inflection.negation-ambiguity-2}, \prettyref{ex:verb-inflection.negation-ambiguity-3}).
This means the negator-after-first-auxiliary rule is about \emph{realization} 
and not about the underlying syntactic structure (\prettyref{sec:morphology-meaning}),
if we assume the semantic difference has structural significance.
This, together with the fact that auxiliaries have negative forms
and that the existence of \corpus{not} blocks subject-auxiliary inversion 
of the main verb,
may lead to the conclusion that the negator \corpus{not} is a quasi-verbal clitic
which is always attached after the highest verbal element.
We, however, shouldn't rush to such a conclusion,
because it's also possible that 
the rule is actually the highest verbal element is always moved \emph{before} the negator.
Note that 

TODO: the Tense - Negation - Modality - Perfect - ... sequence

\begin{exe} 
    \ex\label{ex:verb-inflection.negation-ambiguity-1} 
    I don't appoint him because he is my son. \\
    \translate{I appoint him, but because of his talent, not because his relation with me. / 
    I don't appoint him, because he's my son and I don't want to appoint him and  
    leave a bad impression on my colleagues.}
    \ex\label{ex:verb-inflection.negation-ambiguity-2}
    He shouldn't play football in the streets. \\
    \translate{It's required that he doesn't play football in the streets./
    *It's not required that he plays football in the streets,
    but he can if he wants to.} 
    \ex\label{ex:verb-inflection.negation-ambiguity-3}
    He can't play football. \\
    \translate{It's not possible/permitted that he plays football./
    *He can suppress the desire to play football.}
\end{exe}   


\subsubsection{Subject-auxiliary inversion}\label{sec:sai}

In interrogative sentences and in other cases (\prettyref{sec:clause-template}),  
the first auxiliary in the chain undergoes leftward movement,%
\footnote{
    Note that this is head movement and are often attributed to post-syntactic operations 
    in Distributed Morphology,
    making the operation kind of ``morphological''.
    See \prettyref{sec:morphology-meaning} for theoretical issues concerning this.
}
often to the initial position but may be preceded by preposed constituents (\prettyref{sec:clause-template}). 
This is called \concept{subject-auxiliary inversion}.
When there is no auxiliary, 
the correct form of \corpus{do} carrying the tense and agreement features is inserted.

\begin{exe}
    \ex {} [Do]_{\text{inverted auxiliary}} [you see my umbrella]_{\text{nucleus}}
    \ex Only then do we cook
\end{exe}


\subsubsection{Summary: the structure of the regular verbal complex}

Now we can combine everything in the verbal complex together.
When there is no auxiliary needed,
the tense feature is lowered to the main verb. 
In other cases, the highest auxiliary -- the first auxiliary -- 
is lifted to the tense position,
before negation and the default position of many adverbs.

\subsection{Semi-auxiliaries}\label{sec:semi-auxiliary}

\subsection{Comparability with moods}\label{sec:tam-mood-compatibility}

\section{Subtleties in agreement}\label{sec:verb-inflection.agreement}

If you take a closer look to how native speakers of English do subject-verb agreement,
you'll find some more subtle details than 
the textbook rule that when the tense is \acl{present}
and the subject is 3sg, 
\corpus{-s} is added to the first auxiliary or the main verb
\citep[\citechap{5}, \citesec{18}]{cgel}.

\section{The tense system(s)}\label{sec:verb-inflection.tenses}

\subsection{Descriptive parameters}

Reichenbach's theory of tense distinguishes three time points, namely S, E and R.
A closer look reveals each parameter has sub-parameters.
Below is a review of the framework outlined in 
\citet[\citepages{125-126}]{cgel}
in terms of the classical Reichenbach's theory.

The semantic concepts relevant to tense and aspect marking are:
\begin{itemize}
    \item S, roughly the ``speech time'', 
    the first ``time of orientation'' in \citet{cgel}. 
    There are three time points relevant to 
    determining the S:
    \begin{itemize}
        \item The encoding time, i.e. the time when a speech/written text is made.
        \item The decoding time, i.e. the time when a speech/written text is understood.
        \item The ``suppose we are in this case'' time.
        In some novels and historical recounts, 
        all tenses are simple present,
        which means the time of orientation is placed to 
        the (historical or even imaginary) time points in question.
    \end{itemize}
    For face-to-face communication,
    the first two times are equivalent,
    and they are defined as the \concept{deictic time}.
    For a recorded or written text,
    depending on the purpose of the text,
    the deictic time may be the encoding time 
    (for example in a news report)
    or the decoding time 
    (in, say, a road sign reading \corpus{you are now leaving New York}).
    In either cases, 
    the deictic time is the deictic time in a virtual circumstance
    where the text were said face to face: 
    We may imagine the road sign tells each vehicle passing by 
    ``you are now leaving New York''
    as the passengers see the sign,
    so the decoding time is the deictic time;
    in TV news reports, reporters talk about what's going on,
    as if they are directly talking to the audience,
    so the deictic time is the encoding time.

    When the deictic time is the ``suppose we are in this case'' time,
    we say the S time is \concept{deictic},
    because it refers to a time that the speaker 
    (in a real face-to-face circumstance,
    or in a virtual one mentioned above)
    stands at and is referring to. 
    Otherwise the S time is a \concept{non-deictic} one.
    \item E, the time point in the event referred to,
    or the eventual ``time referred to'' in \citet{cgel}.
    Note that E is not necessarily the \concept{time of situation}:
    The latter is the natural extension of E,
    and E may be a proper subset of the time of situation.
    The relation between the two parameters TODO: phase of activity, or the perfective/imperfective distinction \citep[\citepage{125}]{cgel}?

    Note that the above parameters are all decided by the attitude of the speaker/writer: 
    The inner structure of the \emph{time of situation}
    is more objective,
    and involves parameters like state/dynamic, etc. (TODO: ref)
    \item R, the ``time of reference'', and the time referred to by S, as well as the orientation time of E. TODO
\end{itemize}

The relation between S and R gives the present/past distinction,
while the relation between R and E gives the perfect/imperfect distinction.
Following the terminology used in \citet{cgel}, 
I say the first relation is the \concept{primary tense system},
while the second relation is the \concept{secondary tense system}.

\begin{infobox}{The term \term{aspect}}{aspect-name}
    Other terminologies of course exist.
    The relation between R and E sometimes is also called aspect.
    This is not followed in this note,
    because there seem to be little substantial difference
    between the S-R relation and the R-E relation.
    Thus, in this note, the term \term{aspect} is reserved 
    for the progressives/non-progressive distinction,
    or sometimes the semantic imperfective/perfective distinction.

    It should be noted that \citet[\citepage{148}, \citepage{153}]{cgel}
    use the term \term{past tenses} to refer to 
    the \category{past perfect}, the \category{simple past}, and the \category{present perfect}.
    This may also be the reason why \citet{cgel}
    use the now obsolete term \term{preterite} for the \category{simple past},
    because the term \term{past tense} -- often a shorthand for the \category{simple past} -- 
    is easily confused with \emph{a} past tense,
    which can be the \category{present perfect} or the \category{past perfect}.
    Since we can always use a different font to 
    distinguish the name of a specific construction 
    and a member of a family of constructions,
    the term \term{preterite} is not used in this note.
\end{infobox}

\begin{infobox}{Multiple \referredtime{} and \orientationtime?}{cgel-tense-def}
    In \citet[\citepage{141}]{cgel}, TODO: in perfect tense
    ``Simple'' tenses mean there is only one time referred to.

    Both the classical Reichenbach's theory and \citet{cgel} have problems.
    The problem with the S, R, E system, as is shown above,
    is S is not necessarily the time of speech,
    and E is not necessarily the time of the whole event.
    On the other hand, the system in \citet{cgel} hints at 
    the possibility to have more then two time referred to-time of orientation pairs,
    which is at least rare, if not impossible. TODO: typological
\end{infobox}

When the above parameters are not completely defined,
default constructions are used.
In English, an event with an undetermined time 
is by default expressed by the \category{present tense} \citep[\citepage{129}]{cgel}.

The future time is not encoded as a tense in English.
That's to say, when R happens after S, or E happens after R,

This may have semantic motivation,
because a future time isn't something completely determined.
An almost bound-to-happen future event 
is expressed using the \category{simple present} (TODO: ref)
or the \corpus{be going to do} construction (TODO: ref),
and a normal future event is expressed using the auxiliary \corpus{will}.

\subsection{The simple present}

\subsection{The present perfect}

\subsection{The simple past}

TODO: \corpus{were I you} and \corpus{I wish he realized \dots} \citep[\citepage{153}, {[15]}]{cgel}

\subsection{Back-shift past tenses}

The distribution of back-shift is not limited to embedded clauses \citep[\citepages{152-154}]{cgel}.

The mechanism of back-shifting is best summarized as a type of agreement:
When a clause is embedded into another,
its \emph{semantic} \orientationtime is no longer used in determining its \emph{syntactic} tense category
but is instead shown by the main clause.
The tense marking of the embedded clause,
instead, is decided using the \emph{syntactic} \orientationtime of the main clause.
Note that the \emph{syntactic} \orientationtime of the main clause 
can also be semantically void \citep[\citepage{154}, {[15i]}]{cgel}.

\begin{infobox}{Back-shift is not a transformation rule}{backshift-not-transformation}
    From the above discussion, 
    we find back-shift is not a grammatical transformation rule
    \citep[\citepage{155}]{cgel},
    or otherwise we allow too powerful transformation rules 
    and the resulting grammatical theory definitely over-generates.
    Rather, interplay of features describes the phenomenon better.
    Indeed, that's why transformational rules 
    are no longer first-order citizens in modern generative syntax.
\end{infobox}

There is no back-shift for the \category{past perfect} \citep[\citepage{156}]{cgel}.

\section{The aspect system}

\subsection{Descriptive parameters}

Aspectuality and the inner organization of the situation have interaction
\citep[\citepage{127}]{cgel}.
An event can happen in a particular time point,
but a state usually lasts longer than that,
and therefore when we talk about an object being in a state,
the semantics is always always imperfective.
This may be the reason why 
static clauses are rather rarely in the \category{progressive} constructions:
Because the imperfective semantics doesn't need to be emphasized
\citep[\citepage{124}]{cgel}.

\section{Time in nonfinite clauses}

All non-finite constructions in English lack the primary tense, i.e. the present/past distinction
-- but the perfect-imperfect distinction is still present
\citep[\citepage{159}]{cgel}.

\section{Other \acs{tam} marking strategies}

Some concepts exist in English but are neither marked by affixation or auxiliary verb constructions.

\subsection{Overview of strategies}

\subsubsection{\acs{tam} adverbs}\label{sec:tam.adverbs}

Traditionally, \acs{tam} adverbs are regarded as \term{adjuncts},
which can be relatively freely adjoined to an existing structure.
More fine-grained morphosyntactic tests reveal this is not correct:
\acs{tam} adverbs appear in a rigid hierarchy of positions, 
quite like the hierarchy of core arguments.
Since they usually don't strongly interact with verb inflection
(including affixation and auxiliaries; TODO: ref),
it's better to treat them as peripheral arguments (\prettyref{chap:peripheral-arguments}),
providing more information about a syntactically relevant \acs{tam} category.
It should be noted that some positions can only be filled by a limited number of adverbs (TODO: for example ``allegedly''),

\subsection{Overview of semantic concepts}

\subsection{The future time}\label{sec:future}

\subsection{Evidentiality}

The usual idea is English doesn't have an evidentiality category.
The idea of evidentiality may be expressed by TODO: allegedly 
and by complement clause constructions about quoted speech (TODO: ref).

\subsection{Boundedness}



\section{Use and meaning of modality auxiliaries}\label{sec:verb-inflection.modal-use}


\chapter{Verb valency}\label{chap:valency}

This chapter mainly discusses the grammatical relations between the main verb and its core arguments 
in active clauses.
Information packaging devices may change the constituent order of arguments (TODO: ref)
and passivization changes the argument structure (\prettyref{sec:simple-clause.voice}). 

\section{Dimensions of verb valency}\label{sec:valency.overview}

\subsection{The three-step model}\label{sec:valency.overview.steps}

The full picture of verb valency concerns at least three steps.
The first step is about the purely semantic classification of verbs,
which is described in detail in part B of \citet{dixon2005semantic},
in which we have very fine-grained labels of arguments like ``Manip'' or ``Target''.
The second step is about how the purely semantic concepts mentioned in the first step 
are mapped into ``syntactic semantic roles'',
like ``agent'' or ``patient''.
It's about the syntactic argument structure, 
not purely semantic concepts.
And the third step is how these syntactic semantic roles are mapped into 
types of clausal dependents (subject, object, etc.) 
that can be identified by a shallow -- yet necessary -- analysis of the surface form.
Note that there is in fact a fourth step:
mapping from clausal dependent positions to the surface constituent order:
A constituent after the verb is not necessarily the object, etc. 

Each step has actual effects.
The effects of the third step can be clearly seen in the surface forms.
The effects of the first step can be seen by reflecting on how you conceptualize an event.
The effects of the second step are more subtle but are robust:
For example, in a clause with a so-called unaccusative main verb,
the only core argument is patient-like (which can be tested using some detailed syntactic tests)
but appears as the subject,
which is prototypically filled by an agent-like argument (TODO: ref);
the relative height -- or in other words, closeness with the verb -- of these syntactic semantic roles 
also guides the distribution of reflexives (TODO: ref, and reconstruction effects).

\begin{theorybox}{Semantic roles}{vp-tp-role}
    Note that the second step is just the \vP{} step in generative syntax,
    and the third step is the TP step.
    For example, the causer-like group introduced in \prettyref{sec:valency.overview.semantic-roles}
    corresponds to the DoP layer or light verbs with similar height,
    while the patient-like group corresponds to TransP.
    The term \term{$\theta$-role} as the label for roles in step 2 avoids confusion 
    between purely semantic roles (i.e. step 1) and syntactic ``semantic'' roles (i.e. step 2),
    but unfortunately this is not the notation used in descriptive works.
\end{theorybox}

Such a division however goes against the common practice in grammar writing,
especially for grammarians working with previously undocumented languages,
because this requires in-depth analysis of existing data.
Since the purpose of this note is to clarify existing concepts,
I will still outline the three steps in the rest of this section.

\subsection{The position of arguments as clausal dependents}\label{sec:valency.overview.dependents}

\subsubsection{The subject}\label{sec:simple-clause.subject}

The subject is a position for prototypical core arguments.
The grammatical relation subject, as opposed to other types of complements, 
has the following properties.

\paragraph{Semantic role}

In active transitive clauses, 
the subject is usually agentive.
In passive clauses it is the argument that is permitted to be passivized,
the semantic role of which is usually objective but not always:
Locative \acs{np}s are sometimes permitted (TODO: ref).

\paragraph{Accusativity}\label{sec:simple-clause.subject.accusative}

The usual tests demonstrating syntactic accusativity can be run on English,
like the recovering of extracted subject in coordination (\prettyref{ex:simple-clause.accusative-1}).

\begin{exe}
    \ex\label{ex:simple-clause.accusative-1} 
    \begin{xlist}
        \ex I [saw my mom]_{\text{transitive}} and [got into my house]_{\text{intransitive}} \\
        \translate{I saw my mom and \emph{I} (not my mom) got into my house.}
        \ex * My mom [I saw]_{\text{transitive}} and [got into my house]_{\text{intransitive}} \\
        \translate{I saw my mom and \emph{my mom} got into my house.}
    \end{xlist}
\end{exe}

\paragraph{The subject in clausal derivation}

In clausal derivation, the position of the subject may be altered,
but what's the subject can still be known by considering the tests listed in 
\citet[\citechap{4}, \citesec{3.2.3}]{cgel}.

\subsubsection{The passive \corpus{by}-phrase}\label{sec:valency.overview.by-phrase}

\subsection{Semantic roles in the eye of syntax}\label{sec:valency.overview.semantic-roles}

The content of this chapter doesn't touch much in \acs{tam} adverbials or speech-act-like adverbials.
For the first two or three lines in \prettyref{tbl:clausal-dependent},
it may be a good idea to briefly summarize their possible semantic roles.
Note that here the term \term{semantic role} may be slightly misleading,
for they carry purely syntactic information, 
like, say, the agentive argument usually binds the patientive argument 
(\prettyref{sec:semantics-argument}).

\begin{infobox}{Some notational issues}{patient-confusion}
    In \citet[\citepage{111}]{dixon2005semantic}, 
    the term \term{patient} (and also \term{instrument}) 
    is used similarly with the generalized semantic role label P,
    covering step 2 and step 3 in \prettyref{sec:valency.overview.steps},
    while in \citet[\citepage{50}]{payne1997describing},
    the term \term{patient} is used to cover step 1 and step 2.
    Be mindful about the difference in the meaning 
    when the names of semantic roles mentioned in this section is used by others.
    This note use \term{patient} precisely to cover step 2, 
    i.e. argument roles in the eye of grammar.
\end{infobox}

\subsubsection{The causer-like group}

In the most generalized sense,
a \concept{causer} is an argument that causes an action. 
In a narrower sense, a causer is something causing an event but not intentionally or voluntarily.
A causer in the narrow sense is also called as a \concept{force}.
An \concept{agent}, in the opposite, is something causing an event consciously.
Agents are therefore usually animate.
The causer-like argument in a clause is labeled as A (``agentive'')
(\prettyref{sec:valency.overview.sap}).

An \concept{instrument} may be an adjunct \citep[\citesec{4.2.2} [3]]{cgel},
but it can also be the subject, 
as in \corpus{the knife cut the lace}.
When no agent is using an instrument, 
whether the instrument should be analyzed as a causer in the narrow sense or an instrument
becomes not so clear.
The practice in \citet{cgel} is to use the term \term{instrument} only when 
there is indeed an (explicit or implicit) agent using the instrument.

\subsubsection{The patient and similar roles}

A patient always exists with an explicit or implicit causer, especially an agent.
The patient is \emph{influenced} by an externally originated action caused by the causer.
It does not merely undergo displacement or some transient mental change. 
Examples of prototypical patients are found in \citesec{4.2.2} [4i] in \citet{cgel}.
If there is one clear patientive argument in a clause, it's labeled as P 
(\prettyref{sec:valency.overview.sap}).

Sometimes other argument roles have rather similar syntactic and semantic properties with the patient.
For the verb \corpus{hear}, for example,
the canonical object is a stimulus rather than a patient,
but we have passive constructions like \corpus{my opinions are never heard},
in which the stimulus \corpus{my opinion} is just like 
a patient having undergone passivization and is now the subject.

\subsubsection{Experiencer and stimulus}

\concept{Experiencer} and \concept{stimulus} always appear together (though maybe one of them is implicit).
They appear in situations of emotional feeling or sensory perception, as well as cognition.

For some verbs, the experiencer is more agentive, while for others, the stimulus is more agentive.
This is easy to expect:
metaphorically, both the experiencer and the stimulus can be imagined to ``do something'' to the other.

\subsubsection{Themes}

The term \concept{theme} covers a large number of roles,
the common feature of which is there is no change of inner status of the argument:
There may be change of external property, like the possessor or the location,
but the thing denoted by the argument isn't really changed.
The prototypical ``property'' is the location: 
in \corpus{she ran home}, \corpus{she} is the theme, and \corpus{home} the goal.
Another property, metaphorically related to the location, is (change of) possession.
Thus \corpus{the key} in \corpus{he gave me the key}, and \corpus{the key} in \corpus{the key is mine}
are all possessive themes.
Themes also exist in clauses about more abstract properties, like mental states, 
which often but not necessarily have predicative complements.
In this way, 
\corpus{she} in \corpus{she went mad}, 
\corpus{her} in \corpus{it made her angry},
\corpus{Kim's} and \corpus{Pat's} in \corpus{Kim's writing resembles Pat's}
are all themes.

Similar to the case in experiencers and stimulus,
a theme can be agentive or patient-like, depending to the semantics of the verb.

\subsubsection{(Change of) location}

For a process involving changing location,
we have \concept{path}, \concept{source} and \concept{goal}.
In a clause about a state instead of an event,
there is only a \concept{location} role.

The \concept{recipient} is a role related to verbs like \corpus{give}.
The \concept{beneficiary} is a role that something is done for,
as in \corpus{I've bought [you] a present}.
The two roles are subtypes of the goal.

\subsubsection{Prototypical peripheral arguments}

Compared to complements, the relation between peripheral semantic concepts,
peripheral syntactic ``semantic roles'' 
and clausal dependent positions (i.e. adjunct positions)
is much more clear. 
Therefore, there is no need to list all peripheral argument roles here 
and then link them to adjunct positions: 
it is fine to introduce an adjunct position and at the same time introduce its semantic role,
because there is almost a one-to-one mapping between the two.
Frequent peripheral argument positions include %Enumerating: all peripheral argument positions
instrument (TODO: ref).

\subsection{Semantic classification of verbs}

Finally it's time to discuss \emph{pure} semantics of verbs and arguments.
The semantic classification of verbs strongly influences -- but by no means completely decides --
its syntactic argument structure 
and hence the mapping of arguments to clausal dependents.
In principle the semantics of each verb has its own subtleties,
and here I follow the practice of \citet{dixon2005semantic}
and just list some semantic classes with largely uniform syntactic properties.

\subsection{Labeling the arguments in each step: the S, A, P, G, T labels}\label{sec:valency.overview.sap}

The typological literature widely uses the generalized argument labels -- the S, A, P, G, T, etc. labels
(P is written as O in \citet{dixon2009basic1}).
These labels (and similarly, terms like \term{agentive} or \term{patientive}) 
sometimes are coarse-grained semantic roles, 
no matter the purely semantic version or the syntactic version
(for example, A is a shorthand for the causer-like group -- see below),
and sometimes are coarse-grained clausal positions
(for example, O is a shorthand for anything that looks like the prototypical object).
The two roles are not contradictory, 
because the latter is actually an important criterion 
in determining the correct way of coarse-graining of the former.
In a carefully carried out work,
if two argument positions appearing around two verbs with different semantic classes 
are given the same S, A, O label,
their positions as clausal dependents should be largely similar,
which is a strong indication that their syntactic semantic roles 
(agent-like or patient-like, etc.)
should also be similar. 

\begin{infobox}{Splitting of the S label}{sap-labels}
    An example demonstrates well this point.
    In English, both \corpus{the door} in \corpus{the door opens}
    and \corpus{the cat} in \corpus{the cat kills} 
    are given the S label,
    despite evidence from the two labile verbs suggests that 
    \corpus{the door} is in a more patientive position (\corpus{I closed [the door]}), 
    while \corpus{the cat} is in a more agentive position (\corpus{[the cat] killed a bird}),
    because both \corpus{the cat} and \corpus{the door} are in the typical subject position 
    in the finished intransitive clauses.
    For split-S languages, however, there is no uniform S role,
    and Sa (like \corpus{the cat} mentioned above)
    and So (like \corpus{the door})
    are distinguished. 
    So now the new labels Sa and So can be seen as labels for clausal complement positions,
    but they can be seen as coarse-grained syntactic semantic roles as well,
    because the difference between the Sa clausal complement and the So clausal complement 
    arises from the difference between the agent-like argument coming with an unergative verb
    and the patient-like argument coming with an unaccusative verb.
\end{infobox}

\begin{theorybox}{S, A, P labels as A positions}{a-position}
    When S, A, P labels are used syntactically, i.e. when step 2 and step 3 are conflated,
    the S, A, O positions are roughly A-positions. 
    The definition of S in a language without split-S, for example, may be 
    ``the only NP argument position in an intransitive \vP{}
    (coarse-grained argument position, without specification on whether it moves to SpecTP)'',
    and the definition of Sa in a language with split-S may be 
    ``the only NP argument position in an intransitive \vP{} similar to a DoP (coarse-grained argument position),
    which undergoes a A-movement to SpecTP (clausal complement position)'',
    while the definition of So may be 
    ``the only NP argument position in an intransitive \vP{} similar to a UndergoP,
    which does not undergo the movement to SpecTP''.
    An O argument may be defined as ``the lower argument position in a monotransitive \vP{} 
    (coarse-grained argument position),
    which usually stays in that position and can be analyzed as a part of the VP in a surface-oriented account
    (clausal complement position)''.
\end{theorybox}

It's often the case that as labels of clausal dependents, 
S, A, P labels have redundancy.
In both accusative languages and ergative languages, 
we know in monotransitive and intransitive clauses,
there are only two complement types (i.e. \term{marking} or \term{coding} of argument.
Saying S and A are \term{marked in the same way} 
means S and A are the same with respect to clausal position
(and the difference between A and S is a matter in the second step,
i.e. the syntactic semantic role step).
Thus, similarities within S, A, P labels are good parameters of the alignment typology,
which studies how semantic roles are mapped into clausal dependents.

It should be noted that as I have said in \prettyref{sec:valency.overview.steps},
the three steps all have their own effects,
and there are always some corner cases 
in which conflating the three layers obscures what's really going on.
In existential constructions (TODO: ref), i.e. \corpus{there be} clauses,  
the subject is the dummy \corpus{there}.
Now what's the A argument?
In this case we have to tell step 2 from step 3.
In a typological sketch of the language, however,
this doesn't make things too bad,
because we can first limit the usage of these labels in canonical clauses
and then do generalization.

One example in which at least two steps mentioned in \prettyref{sec:valency.overview.steps}
should be separated from each other 
is valency changing.
(Alignment typology actually also needs to separate step 2 from step 3:
In an accusative language, for example,
in step 3, S and A are the same,
while in step 2, they are two distinct labels.
The mapping from step 2 to step 3 shows accusativity.)
Sometimes people talk about surface and deep S, A, and O positions in valency changing.
The meaning of deep S, A, P labels is
the coarse-grained semantic roles.
Here we see coherence between purely semantic argument roles and 
syntactic argument roles.
The meaning of deep S, A, O, etc. is a mixture of step 1 and step 2 mentioned above
(i.e. \emph{that kind of thing} that would become the surface S, A, O in the active counterpart),
and the meaning of surface S, A, O, etc. is a mixture of step 2 and step 3.

\begin{theorybox}{Exact meaning of S, A, O roles in alignment valency changing}{sao-valency-chancing-meaning}
    The exact meaning of ``surface'' roles depends on 
    what type of valency changing strategy is used here (\prettyref{box:valency-changing}):
    In the passive construction of one language, the surface A argument may just be the SpecTP,
    while in another it may be SpecCauseP (and also SpecTP).

    A language in which S and A are marked in the same way (i.e. a nominative-accusative language)
    has only one subject-like position, which is usually SpecTP.
    A language in which S and O are marked in the same way (i.e. an absolutive-ergative language)
    has only one obligatory topic-like position,
    which may be SpecTP (in the case of Dyirbal) 
    or a position lower than SpecTP which can appear even in nonfinite clauses.
    See, for example, \citet{aldridge2008generative} for more details.
\end{theorybox}

TODO: E argument 

\section{Valence alternations}

Although the passive voice is a device 
somehow ``higher'' than the other argument structure alternation devices
(\prettyref{box:valency-changing}),
I treat it together with other valency alternation devices,
because they all seem to have strong dependence on the verb root: %TODO: better wording
Even though the passive voice is generally quite regular,
there are rare cases where the subcategorization frame of a passive verb 
doesn't have an active counterpart,
for example the \corpus{be said to} construction
\citep[\citepage{245}]{dixon2005semantic}.

TODO: \citep[\citepages{249, 1433}]{cgel}

TODO: is \corpus{the dog bites} antipassive?

TODO: What about Dixon's promotion to subject, like \corpus{the CD sells well}?

\section{Prototypical transitive and intransitive verbs}

This section discusses prototypical transitive verbs -- verbs with a clear A argument and a clear P argument --
and prototypical intransitive verbs -- verbs with just an argument,
which, since English is an accusative language (\prettyref{sec:simple-clause.subject.accusative}),
is labeled as S.

\subsection{The \category{affect} verbs}

An \category{affect} verb comes with three \emph{semantic} arguments:
the Manip, the Agent, and the Target.

\citet[\citesec{4.2}]{dixon2005semantic} notes 
sometimes we have the alternated syntactic coding of argument 
exemplified by (\prettyref{ex:valency.affect.2}).
The alternation between (\prettyref{ex:valency.affect.1}) and (\prettyref{ex:valency.affect.2}) is not free,
but motivated by semantics:
(\prettyref{ex:valency.affect.2}) is more marked,
in which the Manip argument -- the stick -- is semantically more patient-like
(for example, he may want to break the stick or to test how firm it is),
so it is syntactically mapped to the patient position. 

\begin{exe}
    \ex\label{ex:valency.affect.1} 
    He hit [the table]_{\text{Target, patient, P}} [with the stick]_{\text{Manip, instrument}}
    \ex\label{ex:valency.affect.2}  He hit the stick to the table.
    \ex The stick hit the table.
\end{exe}

\subsection{The \category{weather} verbs}

Verbs about weather are zero-valency verbs.
The subject of a clause with the main verb being a \category{weather} verb 
is always the dummy \corpus{it}.

\begin{exe}
    \ex It's going to rain!
    \ex *It was rained.
\end{exe}

\section{Prototypical ditransitive verbs}

In this section I talk about verbs about giving and receiving,
that is, verbs with two internal arguments,
one being theme-like (labeled as T) and the other goal-like (labeled as G).



\section{Copular verbs}

\section{Verbs with prepositions and particles}

Verb-preposition constructions and verb-particle constructions
can be classified according to the following parameters:
\begin{enumerate*}
    \item whether it's a transitive preposition or a particle 
    (an intransitive preposition, or something else),
    \item whether the construction can be interpreted in a compositional way or 
    has already gained an established (idiomatic) meaning,
    \item how the choice of preposition/particle is restricted by the verb,  
    \item the mobility of the preposition/particle 
    in, say, \corpuscat{wh}-movements, and 
    \item complement-related properties of the associated \acs{np} coming with the preposition/particle,
    like whether it can be passivized
\end{enumerate*}
\citep[\citepages{272-274}]{cgel}.

\begin{infobox}{Intransitive prepositions}{intrans-prep}
    The term \term{particle} here covers intransitive prepositions;
    the term \term{preposition} is used to cover transitive prepositions.
    Although strictly speaking, 
    this terminology confuses form and function 
    (prepositions are a word class, 
    and can be used intransitively in some cases),
    I choose to do so to keep the notation consistent with 
    the current grammar writing practice.
\end{infobox}

Concerning verbs coming with a single preposition,
trivially, if a verb doesn't specify the preposition following it, 
the preposition is always mobile.
Thus we have a three-fold classification:
\begin{enumerate*}
    \item verbs with non-specified prepositions,
    \item verbs with specified but mobile prepositions 
    (\concept{preposition verbs with mobile prepositions}; \citealp[\citepage{273}]{cgel}), and 
    \item verbs with specified and fixed prepositions 
    (\concept{fossilized preposition verbs}; \citealp[\citepage{277}]{cgel}).
\end{enumerate*}
Note that a non-specified prepositional phrase is still a complement \citep[\citepage{273}]{cgel}.

The parameters of established meaning and complement properties
are largely independent to the classification made above.
Passivization is completely not predictable 
from the classification made above \citep[\citepage{276} {[11]}]{cgel}.
Fossilized verb-preposition constructions are usually idioms,
but some, like \corpus{break with}, 
still have largely inferrable meaning;
the same applies for verbs with specified prepositions
(indeed, the presence of a specified preposition introduces a sense of 
directed volition \citep[\citepage{293}]{dixon2005semantic});
verbs with non-specified prepositions usually are less idiom-like,
but this is because if they are idiomatic enough,
we will recognize them as verbs with specified prepositions.

The classification of verb-preposition constructions,
therefore, is given in \prettyref{tbl:verb-prep-construction}.
The examples used in the table is based on \citet[\citepage{278}, {[17]}]{cgel}.

\begin{table}[H]
    \centering
    \caption{Classification of verb-single-preposition constructions}
    \label{tbl:verb-prep-construction}
    \begin{tabular}{lllll}
    \toprule
    &       &       & \multicolumn{2}{c}{specified preposition} \\ \cmidrule(l){4-5} 
    \multirow{-2}{*}{\begin{tabular}[c]{@{}l@{}}passivization of NP \\ after preposition\end{tabular}} & \multirow{-2}{*}{idiom} & \multirow{-2}{*}{\begin{tabular}[c]{@{}l@{}}non-specified \\ preposition\end{tabular}} & mobile             & fixed                \\ \midrule
                                                                                                       & yes                     & \cellcolor[HTML]{C0C0C0}\corpus{}                                                      & \corpus{call on?}          & \corpus{see to}      \\
    \multirow{-2}{*}{yes}                                                                              & no                      & \corpus{sleep in}                                                                      & \corpus{refer to}  & \corpus{fuss over}            \\
                                                                                                       & yes                     & \cellcolor[HTML]{C0C0C0}\corpus{}                                                      & \corpus{stand for} & \corpus{come across} \\
    \multirow{-2}{*}{no}                                                                               & no                      & \corpus{fly to/from}                                                                   & \corpus{feel for}          & \corpus{come into}            \\ \bottomrule
    \end{tabular}
\end{table}

Beside the classification given by \prettyref{tbl:verb-prep-construction},
another parameter is the origin of preposition verb constructions.
Some of them are similar to verbs licensing oblique cases
(found in languages with rich case morphology, like Latin),
like \corpus{refer to},
the verb parts of which rarely appear alone or with other prepositions.
For others, like \corpus{see to},
the verb part of the construction (usually a simple, monosyllabic one)
does appear alone or with other prepositions.
In the first case,
the ``idiom-or-not'' parameter is actually not so important,
because we can consider the preposition as a part of the verb lexeme,
while in the second case,
the parameter is important,
because \corpus{stand at the door} is of course not idiomatic,
while \corpus{stand for} has an established meaning.

The complement introduced by the preposition of a preposition verb 
is object-like (TODO: ref),
and therefore preposition verbs are transitive
(\citealt[\citepage{291}, \citepage{297}]{dixon2005semantic};
\citealt[\citepage{277}]{cgel}).

\section{Small clause constructions}

\begin{exe}
    \ex I painted the door green.
\end{exe}

\section{Complement-taking verbs}

Since the in-depth characterization of subclasses of complement-taking verbs 
involves too much about the inner structure of the complement clause,
following the common practice in modern grammars,
I postpone this part to \prettyref{sec:clause-combining.complement-clause}.

\chapter{Peripheral arguments}\label{chap:peripheral-arguments}

Peripheral arguments, or simply 

\chapter{Simple clauses}\label{chap:simple-clause}

After several chapters about each part of the clause,
this chapter discusses how the parts are assembled into one.
The details of how a clause is embedded into another are not covered in this chapter
-- they are covered in \prettyref{chap:clause-combining}.

\section{Overview of clause structure}\label{sec:clause-template}

\subsection{The template}

The template of English clause structure is shown in \prettyref{fig:clause-template}.
The figure displays the four rough levels of clause structure.
Each layer in \prettyref{fig:clause-template} as well as justification of them,
if not described in chapters above, are described 
in the rest of this chapter.

The first layer contains the verb-argument (core or peripheral) grammatical relations,
\ac{tam} marking (by inflection, auxiliary construction, or adverbs), and negation.
In structuralist tradition as is described in \citet{cgel},
this layer is the \concept{verb phrase}.
It contains the auxiliary chain and the main verb 
(\prettyref{sec:verb-forms}, \prettyref{sec:auxiliary-chain}),
internal complements (\prettyref{sec:valency.overview}),
and adverbials that prototypically appear in the clause-final position (TODO: ref).
Note that that these clause-final adverbials 
appear \emph{higher} than the internal complements 
in the constituency tree:
The former are after the latter for some other reasons (TODO).
The first layer has several sub-layers:
First the core argument structure,
then peripheral arguments, 
then auxiliary verbs and negation and also \acs{tam} marking by adverbs,
and also the category of voice. 

The second and the third layers shown in \prettyref{fig:clause-template}
are much slimmer than the first layer.
They are shown as separate layers mainly because 
the subject-predicate relation 
and the subject-auxiliary inversion 
traditionally gain more attention.
The second layer highlights the prominent status of the subject (\prettyref{sec:simple-clause.subject}).
A subject plus a verb phrase is a \concept{nucleus clause}.
A declarative clause without information packaging operations
can just be a nucleus clause without further syntactic operations.
The third layer is optional:
It arises when subject-auxiliary inversion happens (\prettyref{sec:sai}),
which is the case in %Enumerating: all cases in which SAI happens 
question formation (\prettyref{sec:simple-clause.interrogative.formation}).

The fourth layer is also optional and may have several preposed constituents,
each of which may be preposed by a different reason,
and interacts freely with the subject-auxiliary inversion.
This is also a fat layer:
There exist several types of preposing operations (\prettyref{sec:simple-clause.derivation.preposing}),
and the layer also contains some high-level adverbials
which are about speech force, etc., %Enumerating: high-level adverbials
like \corpus{frankly} (\prettyref{sec:pos.adverb}).

\begin{figure}[H]
    \centering
    \input{templates/clause.tex}
    \caption{English clause structure (the indentation means linear order and not constituency relations)}
    \label{fig:clause-template}
\end{figure}

\begin{infobox}{About the term \term{verb phrase} and \term{predicate}}{verb-phrase}
    Dixon argues against using the term \term{verb phrase} in the sense of this note;
    his \term{verb phrase} is \prettyref{tbl:auxiliary-chain}.
    The two definitions of \term{verb phrase} are all frequent in modern descriptive grammars.
    When the term \term{verb phrase} is used in the sense in \prettyref{fig:clause-template},
    Dixon's verb phrase is sometimes called the \term{verb complex} \citep{Friesen2017}.

    Another terminology issue is many people -- like Dixon -- use the term \term{predicate}
    for the syntactic function of the verb complex
    (i.e. the realization of functional heads),
    while others use it for the syntactic function of the verb phrase 
    (i.e. a lower part of the TP -- see \prettyref{box:vp-tp-cp}).
    To avoid this endless confusion, 
    I will just avoid the notion of \term{predicate} as much as possible (\prettyref{box:form-function}).
\end{infobox}

\begin{theorybox}{The \vP{}-TP-CP projection}{vp-tp-cp}
    Roughly speaking, in \prettyref{fig:clause-template},
    the verb phrase is the part of TP that is lower than the projection in which the subject is introduced.
    The subject-predicate structure is roughly the complete TP.
    Layer 3 and layer 4 are about CP.
\end{theorybox}

Note that clause linking is not represented in \prettyref{fig:clause-template}.
Linked clauses may appear before or after the main clause.
Supplementation and subject-sharing coordination is also not covered 
(\prettyref{sec:clause-linking.coordination},
\prettyref{sec:clause-linking.supplementation}).
Nor is clausal derivation illustrated in the figure 
(\prettyref{sec:simple-clause.derivation}),
because arguably, some post-internal complement adverbials 
are likely to be the result of heavy constituent postponing (TODO: ref).
Apart from the above constructions,
the scheme illustrated in \prettyref{fig:clause-template} works for all clause types
(\prettyref{ex:simple-clause.structure-1}, 
\prettyref{ex:simple-clause.structure-2},
\prettyref{ex:simple-clause.structure-3}),
including nonfinite clauses,
though for the latter,
the properties of the subject 
and the allowed auxiliaries deviate from the finite case,
and this is also the same for allowed preposing constructions. %Enumerating: restriction on infinite clause derivation
(\prettyref{ex:simple-clause.structure-1}) is a fused relative clause,
in which there is \corpuscat{wh}-fronting 
but no subject-auxiliary inversion (TODO: ref).
In (\prettyref{ex:simple-clause.structure-2}) we see two preposing constructions,
one topicalization (TODO: ref)
and \corpuscat{wh}-movement for question formation (TODO: ref),
and the only verb -- the copula \corpus{is} -- is moved out of the verb phrase
because of subject-auxiliary inversion.
The 

\begin{exe}
    \ex\label{ex:simple-clause.structure-1} {} [%
        [What]_{i,\text{\corpuscat{wh}-preposed: \corpuscat{wh}-pronoun}} %
        [[Max]_{\text{subject:\acs{np}}} %
        [said Liz bought --_{i}]_{\text{verb phrase}}]_{\text{nucleus}}]_{\text{\corpuscat{wh}-preposing}}
    \ex\label{ex:simple-clause.structure-2} {} [%
        [In your opinion]_{\text{topicalized}}
        [[what]_{i,\text{\corpuscat{wh}-preposed}} %
            [is [--_{i} the most dangerous]_{\text{verb phrase}}]_{\text{SAI}}%
        ]_{\text{\corpuscat{wh}-preposing}} %
    ]_{\text{topic-preposing}}
    \ex\label{ex:simple-clause.structure-3} {} [%
        [what]_{i,\text{\corpuscat{wh}-preposed}} [to [do --_i]_{\text{verb phrase}}]_{\text{nucleus}}%
    ]_{\text{\corpuscat{wh}-preposing}}
\end{exe}

\begin{infobox}{Confusing form and function}{form-function}
    If you are familiar with the structuralist method documented in \citet{cgel},
    you may already notice my annotation in \prettyref{fig:clause-template}
    and the above examples confuse \emph{function} (predicate)
    with \emph{form} (verb phrase).
    However, as is said in \prettyref{box:clause-sentence},
    English verb phrases -- roughly \vP{} after case assignment, etc. -- 
    almost never appear outside a clause,
    and it doesn't provide additional information 
    to introduce separate terms for form and function in \prettyref{fig:clause-template}.
    This is also the practice taken in most works adopting the notion of verb phrase,
    like \citet{Friesen2017}.
\end{infobox}

\subsection{Active and passive voices}

One thing that happens in the verb phrase 
and strongly influences the structural building process is the category \emph{voice}.
English doesn't have a rich set of valency changing devices,
and the active-passive distinction is the only regular valency changing mechanism.
There are other alternations of verb valency, 
but they are much more strongly determined by the lexicon 
and therefore are excluded from the discussion on voice (\prettyref{sec:overview.valency-changing}).

\subsection{Moods or types of finite clauses}\label{sec:moods}

English has several clause types with regard to the related grammatically marked speech force.
From the perspective of compatibility with the auxiliary verbs,
the main distinction is the distinction between the imperative mood and non-imperative moods:
The former doesn't allow any nontrivial modality and aspect,
and the tense is always present,
while non-imperative moods interact freely with all \acs{tam} categories.

\begin{infobox}{Mood and modality}{mood}
    \citet{dixon2009basic1} firmly argues against using the term \term{mood} 
    for the syntactic marking of modality,
    while \citet{cgel} uses the term \term{mood} for the syntactic marking of modality
    and uses \term{clause type} to specifically refer to Dixon's \term{mood}.
    To avoid confusion (\term{clause type} is too vague),
    this note follows the definition of Dixon.

    The confusion seems to arise from traditional Latin grammar,
    in which there is no significant difference 
    between a declarative sentence and an interrogative sentence, 
    while there is significant difference
    between the verbal morphology in indicative and subjunctive clauses.
    On the other hand, in imperative clauses 
    there is no indicative-subjunctive distinction.
    Therefore the imperative-non-imperative distinction is fused with 
    the indicative-subjunctive distinction 
    and is named \term{mood}.
    This relies on the specificities of Latin grammar 
    and surely is not a universal category for all languages.
    English also has modal clauses with auxiliaries like \corpus{would} or \corpus{should},
    but that's about modality, not mood.
    There is indeed a subjunctive clause type in English,
    but it has already been restricted to complement clauses,
    and never appear as a full sentence. TODO: ref
\end{infobox}

The difference between non-imperative moods is small.
The formation of interrogative clauses 
only takes two (often skipped) syntactic steps 
(\prettyref{sec:simple-clause.interrogative.formation}),
which can be attributed to a focus construction which also happens in declarative clauses (TODO: ref).
Indeed, some, like \citet[\citepage{25}]{dixon2005semantic}, only recognize two moods.
This note still keeps the declarative-interrogative distinction 
for convenience.

\subsection{Nonfinite clauses and verbless clauses}\label{sec:simple-clause.nonfinite-clause}

Nonfinite clauses are deficient in \acs{tam} marking 
\citep[\citepage{1174}, {[5-7]}]{cgel},
and never appear as full sentences.
This doesn't mean finite clauses are all full sentences:
Some may be embedded clauses.

\begin{table}[H]
    \caption{Classification of clauses based on independence and finiteness}
    \centering
    \begin{tabular}{@{}llllll@{}}
        \toprule
        \multicolumn{2}{c}{independent}            & \multicolumn{4}{c}{embedded embedded}                                                                \\ \cmidrule(lr){1-2} \cmidrule(lr){3-6}
        \multicolumn{4}{c}{finite}                                                                & \multicolumn{2}{c}{nonfinite}                         \\ \cmidrule(lr){1-4} \cmidrule(lr){5-6}
        imperative               & \multicolumn{2}{c}{"normal"} & subjunctive & infinitive           & participle \\ \midrule
        1    &     2            &   3         &                                 &  &                                \\ \bottomrule
    \end{tabular}
\end{table}

The class of participles contain \corpuscat{ed}-participles and \corpuscat{ing}-participles.
The class of infinitive clauses can be further divided into 
\corpuscat{to}-infinitives and bare infinitives \citet[\citechap{14}, \citesec{1.4.3}]{cgel}.
The class of \corpuscat{to}-infinitives have three superficial constituent order:
\corpus{to do sth.}, \corpus{sb. to do sth.}, and \corpus{for sb. to do sth.}
However, the \corpus{sb. to do sth.} sequence doesn't correspond to a separate type of infinitive clause:
The \corpus{sb.} position is always an object position licensed by the verb.
Indeed, we never find the \corpus{sb. to do sth.} sequence
in constructions other than the in-\acs{vp} use of infinitives.
Thus we only have two types of infinitive clauses:
the one without \corpus{for} and with a null subject,
and the one with \corpus{for} and a visible subject.

Nonfinite clauses prototypically appear as complement clauses, 
but they can also be relative clauses and adverbial clauses \citep[\citepage{1264}]{cgel}.

There is a further class of clauses -- the \concept{verbless clause} \citep[\citepage{1266}]{cgel} -- 
that may be placed into the nonfinite column,
but some think it's just a type of sub-clausal phrase.
Its distribution is also very different from other types of clauses.

\begin{infobox}{Sentence v.s. utterance}{sentence-utterance}
    In this note, an \term{utterance} is a unit spoken by a speaker,
    while a \term{sentence} is a ``maximal'' clause that is an utterance.
    An utterance doesn't have to be a sentence:
    It can be an \acs{np}, as a concise reply to a question,
    or even a single word.

    Some people use the term \term{sentence} to cover all utterances.
    \citet[\citepage{45}, \citepage{853}]{cgel} uses the term \term{sentence} 
    almost as a synonym of \term{utterance},
    and all discussions concerning the syntax in their account of English grammar are about clauses.
\end{infobox}

The subjunctive clause is not nonfinite \citep[\citepage{83}]{cgel} TODO: why, and more about it 

Of course, the inner structure of nonfinite clauses are strongly related to their licensing environments,
which we discuss in the next chapter.

\subsection{Clausal derivations}\label{sec:simple-clause.derivation}

%Enumerating: clause derivation
(TODO: heavy NP shift, final adverbial with a pause)

\subsubsection{Preposing}\label{sec:simple-clause.derivation.preposing}

%Enumerating: preposing cases
(\prettyref{sec:simple-clause.information.topicalization})

\section{Minimal declarative clause}

\subsection{Clausal dependents}\label{sec:simple-clause.dependents}

Putting purely grammatical items (like auxiliary verbs) aside,
clausal dependents are traditionally divided into arguments (or ``complements'') and adjuncts (i.e. adverbials).
Both types have many diverse subtypes,
and sometimes, 
a subtype of arguments and a subtype of adjuncts can be quite similar.
Similar to the case in other languages, 
clausal dependents in English can be summarized as \prettyref{tbl:clausal-dependent}.

Prototypical core semantic roles (\prettyref{sec:valency.overview.semantic-roles}), 
like agent, patient, theme, etc.,
are always clausal complements and never adjuncts.
The passive \corpus{by}-phrase is also an argument, not an adjunct 
(\prettyref{sec:valency.overview.by-phrase}).

Prototypical peripheral roles, like location or instrument, can also be arguments,
but they can also be adjuncts.
The concepts of manner, whether the action in question creates frustration 
(e.g. \corpus{I spent the whole day working on that problem [in vain]}), etc.
are sometimes grammaticalized as arguments,
as in \corpus{we were treated [badly]},
without which the clause is not grammatical,
but more frequently they are adjuncts.

The term \concept{peripheral argument}
usually means adjuncts with prototypical peripheral semantic role,
but it may also be about manner or frustrative expressions like \corpus{in a stupid way}:
The latter can still be asked about (\prettyref{ex:simple-clause.dependents.ex-1}), 
just like prototypical peripheral arguments (\prettyref{ex:simple-clause.dependents.ex-2}). 
The cell corresponding to prototypical peripheral arguments
is colored blue in \prettyref{tbl:clausal-dependent};
the cell corresponding to less-prototypical peripheral arguments
is colored light blue in \prettyref{tbl:clausal-dependent}.

The term \concept{oblique argument} 
means syntactic arguments with oblique case marking, i.e. not nominative or accusative.
Their cells are colored light and pale green in \prettyref{tbl:clausal-dependent}.

\begin{infobox}{The term \term{argument} and the argument-adjunct distinction}{argument-terminology}
    Note that here is a terminological confusion:
    The term \term{argument} is used sometimes 
    as opposed to more grammatical clausal components like \acs{tam} adverbs
    (as in \term{peripheral argument}, 
    i.e. any specifier positions that allows large variation with regard to its content),
    and sometimes as opposed to \term{adjunct},
    i.e. an element that doesn't have very strong relation with the verb.
    Here we have two descriptive parameters when we talk about arguments:
    one is the ability of variation
    (core arguments, peripheral arguments, oblique arguments can be filled by diverse constituents,
    while \acs{tam} adverbials only allow a limited number of adverbs),
    and the other other is the closeness to the lexical head, which is the main verb here 
    (core arguments, oblique arguments are closely related to the main verb,
    while \acs{tam} adverbials and peripheral arguments are not).
    The parameter of closeness to the lexical head is the parameter used for argument-adjunct distinction
    in \prettyref{tbl:clausal-dependent}.

    \citet[\citepage{732}]{quirk1985} says we need gradient analysis 
    in cases like \corpus{we were treated [quite badly]}.
    This is correct, but doesn't say much about the essence of English grammar:
    At a given time, for a given speaker,
    we can still tell how close the constituent \corpus{quite badly} is to the verb.
    Here, the requirement of gradience 
    comes from the inherent deficiency of the terms \term{argument} and \term{adjunct}. 
    The emphasis of the authors on this kind of construction 
    seems to arises from confusion between form and function:
    \acs{advp}s ``should'' only occur as adjuncts and not complements,
    and when they actually appear to be complements,
    some make-up mechanisms are needed to maintain the generalization that \acs{advp}s are adjuncts.
\end{infobox}

\acs{tam} adverbials are adverbials that mark the \acs{tam} categories 
in the way that can be also found in \prettyref{chap:verb-inflection}.
They are usually quite limited in variation,
resembling the tense or aspect system in the verbal complex.
Adverbials like \corpus{yesterday} or \corpus{in that very moment} (TODO: ref)
seem to be peripheral arguments, instead of a part of \acs{tam} marking devices,
because their syntactic functions allow too much variation 
and therefore can't be captured by that kind of feature combination 
(``S before R'' or ``S=R'', etc.)
usually seen in \acs{tam} devices. 

\begin{exe}
    \ex\label{ex:simple-clause.dependents.ex-1} - [How] did they treat you? - They treated us [quite badly].
    \ex\label{ex:simple-clause.dependents.ex-2} - [Where] did they detained you? - They detailed us [in a building near the sea].
\end{exe}

\begin{table}[H]
    \caption{English clausal dependents}
    \label{tbl:clausal-dependent}
    \begin{tabular}{ccc}
    \toprule
    \multirow{2}{*}{meaning}      & \multicolumn{2}{c}{syntactic position}                                                       \\ \cmidrule{2-3}
                                  & argument (i.e. complement)                             & adjunct                                             \\ \midrule
    prototypical core roles       & \cellcolor[HTML]{32CB00}\corpus{[I] loves [that apartment]}             & \\ 
    prototypical peripheral role  & \cellcolor[HTML]{34FF34}\corpus{She lives [in that apartment]} & \cellcolor[HTML]{34CDF9}\corpus{The machine is fixed with this new tool}    \\
    manner, frustrative, etc.     & \cellcolor[HTML]{DAE8FC}\cellcolor[HTML]{67FD9A}\corpus{We were treated [quite badly]} & \cellcolor[HTML]{DAE8FC}\corpus{He answered the question in a silly manner} \\
    \acs{tam}-related adverbials &                                        & \cellcolor[HTML]{ECF4FF}\corpus{I [always] feel tired}                      \\
    peripheral adverbials  &                                        & \corpus{[Frankly], I think you are fooled by them} \\ \bottomrule
    \end{tabular}
\end{table}

There are of course subtleties between the classification of meanings in \prettyref{tbl:clausal-dependent}.
The instrument role, for example, 
may appear in the subject position or as a peripheral argument, 
while the manner expression is similar with the peripheral instrument argument 
in their forms (prepositional constructions or ``oblique cases'')
and the ability to be \corpus{wh}-extracted
(\prettyref{ex:simple-clause.dependents.ex-1}, \prettyref{ex:simple-clause.dependents.ex-3}).

\begin{exe}
    \ex\label{ex:simple-clause.dependents.ex-3} - How did you finish this article? 
    - I finished it with LaTeX.
\end{exe}

Prototypical core arguments,
peripheral arguments and oblique arguments representing prototypical peripheral semantic roles 
allow quite diverse choices when it comes to how to fill them.
Manner-like phrases -- be them oblique arguments or peripheral arguments -- 
allow less variations.
\acs{tam} adjuncts are usually highly limited in their contents.
Peripheral adverbials, on the other hand,
allow much more variation (TODO: ref).




Some adverbials are even higher than the speech act-related adverbials 
mentioned in \prettyref{tbl:clausal-dependent},
but they are too high to be considered as clausal dependents:
many of them are clause linking devices (\prettyref{sec:clause-linking.subordination}).
Subordinated adverbial clauses may be about 
cause and result (\corpus{now }), 
concession, 
and condition (\corpus{if \dots then \dots}, with the ``reason'' clause being semantically irrealis).
There are also connective adjuncts like \corpus{moreover} or \corpus{alternatively},
which refer to \emph{discourse} structures, instead of syntactic structures.

\begin{infobox}{Adverbial classification in the literature}{adverbial-classification}
    Different authors have slightly different terminologies concerning adverbials.
    \citet[\citepage{576}]{cgel} put \acs{tam} adverbials (except modality adverbials) 
    and peripheral arguments
    under the class of \acs{vp}-oriented adverbials, 
    while modality adverbials and speech-act-like adverbials are called clause-oriented adverbials.
    \citet[\citepage{386}]{dixon2005semantic} on the other hand 
    put all \acs{tam} adverbials and speech-act-like adverbials 
    into the category of sentential adverbials (he calls them \term{adverbs})
    and the non-prototypical peripheral arguments are packaged into the class of manner adverbials,
    though some of them are not really about manner -- 
    for example it may be about degree \citet[\citepage{576}]{cgel}.
\end{infobox}

\subsection{Clausal continuation}

TODO: \corpus{not even} construction, heavy NP shift, etc.


\subsection{Logic and default information structure}

\subsubsection{Descriptive parameters}

TODO: position of quantifiers for NPs with or without determiner,
and the difference between \corpus{all}, \corpus{every}, \corpus{some}, \corpus{any};
the position and scope of negation;
how the position of NPs (subject or object) influences quantification;
the relation with information structure
(if a subject NP is never given, 
it tends to be read as a representative of its kind and is therefore bound by $\forall$;
but it's never the case for objects)

\section{Topicalization}\label{sec:simple-clause.information.topicalization}

\section{Cleft constructions}

\subsection{\corpus{It}-cleft}

A \corpus{it}-cleft construction 
contains a dummy subject \corpus{it},
a finite form of \corpus{be}, 
a focused constituent,
and a \corpuscat{that}-clause in which there is a gap
(\prettyref{ex:simple-clause.cleft.it.1}, \prettyref{ex:simple-clause.cleft.it.2}).
Note that here \corpus{it} never changes into, say, \corpus{she} or \corpus{they},
and \corpus{is} doesn't show any agreement with the focused constituent.
This is the expected behavior: 
Note that it's pretty fine 
for the syntactic numbers of the \acs{np}s 
before and after \corpus{be} to be different
in non-cleft clauses, 
and \corpus{be} always agrees with the subject.

\begin{exe}
    \ex\label{ex:simple-clause.cleft.it.1} It is [him]_{i, \text{focused}} that he wanted to murder ---_i !
    \ex\label{ex:simple-clause.cleft.it.2} It is [by this new method]_i that we have achieved such success ---_i.
\end{exe}

The range of constituents able to be focused 
can be found in \citet[\citepages{1417-1419}]{cgel}.
We seems to have a generalization: 
If the focused constituent is an adverbial, 
it has to be able to be an answer to a \corpus{how} question -- 
and therefore can appear after \corpus{be}.

The \corpus{it}-cleft construction seems to be a clausal idiom:
The dummy \corpus{it} can be raised
when the \corpus{it}-cleft construction is in an infinitive form 
and embedded into a complement clause construction.
Note that the \corpus{it}-cleft construction can't be a verbless clause: 
This makes the focusing reading inaccessible.

TODO: \corpus{that} or \corpus{who}?? 

Thus, although the \corpus{it}-cleft construction 
is already an established construction with a fixed meaning (i.e. focusing),
it's still analyzable as a bi-clausal construction
following the usual syntactic constraints found elsewhere in English.

\subsection{\corpus{Wh}-cleft}

\section{Expletive subject constructions}

\subsection{\corpus{There be} existential construction}

\begin{exe}
    \ex 
\end{exe}

\subsection{\corpus{It seems that ...}}

\section{Focus constructions}

The English focus construction involves subject-auxiliary inversion 
and preposing of the focused constituent.
Note that the fronted constituent can be a copular complement,
a locative adverbial, TODO: list 
but never an object in a prototypical transitive construction.
This seems to be motivated for functional reasons,
because in the latter case it's impossible to correctly restore the meaning.

\begin{exe}
    \ex {} [On the top of the mountain]_{\text{locative \acs{pp}}} lies [a small church]_{\text{subject}}.
\end{exe}

\begin{infobox}{Focusing is not valency changing}{focus-not-voice}
    This note follows the analysis in \citet[\citepage{244}]{cgel}
    and regard this as a type of information packaging
    but not a voice construction.
    Some grammars, like \citet[\citepage{736}]{quirk1985},
    analyze the fronted constituent as the subject. 
    This is not the position of this note TODO: why?
\end{infobox}

\section{The passive voices}\label{sec:simple-clause.voice}

\subsection{Overall scheme}

\subsection{Passivized argument}

Passivization depends on - though not in a very apparent way -- the properties of the main verb. 
TODO: passivized argument



\section{Interrogative moods}

\subsection{Overview}\label{sec:simple-clause.interrogative.formation}

There are two movements involved in forming a canonical interrogative clause:
the subject-auxiliary inversion,
and fronting of the \corpuscat{wh}-phrase, if any.
Both operations can be omitted in casual speech.

\subsection{Yes-no questions}

\subsection{Open questions}

\subsection{Tag questions}

\begin{exe}
    \ex The car is broken, isn't it?
\end{exe}

\section{The imperative mood}

The imperative mood is only compatible with active clauses.
Passive imperatives are never possible, 
and the intended meaning may be alternatively expressed by 

\section{The \corpuscat{to}-infinitive}

\chapter{Clause combining}\label{chap:clause-combining}

\section{Complement clause constructions}\label{sec:clause-combining.complement-clause}

Complement clauses or \term{content clauses} \citep{cgel} are clauses embedded as arguments of certain verbs.
English adverbial clauses have the same form of complement clauses,
and therefore \citet{cgel} use the term \term{content clause}.
Here I'll just stick to the more common terminology in linguistic description.

\subsection{Types of complement clauses}

According to \citet[\citesec{18.4}]{dixon2010basic2},
there are usually three types of complement clauses:
\begin{enumerate*}
    \item the Fact type, which looks like a full sentence
    and usually express a fact, 
    \item the Activity type, which looks like an \acs{np}
    but still keeps key features of clauses 
    and usually express an ongoing activity 
    without specifying the time (and thus with deficient \acs{tam} marking), and 
    \item the Potential type,
    which describes the potential or plan to do certain things 
    and also has deficient \acs{tam} marking,
    but is formally less similar to \acs{np}s.
\end{enumerate*}
In English, the three types correspond to precisely 
the finite complement clause,
the participle clause,
and the infinitive clause.
Note that the classification is pseudo-semantic:
It is similar to \prettyref{sec:valency.overview.sap},
which names constructions with their prototypical -- but not unique -- semantic function.
Indeed, a Fact clause -- a finite complement clause -- 
is able to express a potential,
like \corpus{that I would spend my summer in Paris},
and an Activity clause can express a fact 
(\corpus{[Being an engineer], he has a sharp mind when solving practical problems}).

\subsubsection{Subjunctive clauses}\label{sec:complement.subjunctive}

\subsection{Infinitive constructions}

Before going into details of each construction,
I list some parameters to classify infinitive complement clause constructions.

\subsubsection{Infinitive appearing in subject}

It's possible for an infinitive clause to appear in the subject position
(\prettyref{ex:complement.infinitive.1}).
However, this use of infinitive clauses 
has nothing particularly interesting:
The complement clause has almost parallel behaviors with an \acs{np} 
(\prettyref{ex:complement.infinitive.1p}).

\begin{exe}
    \ex\label{ex:complement.infinitive.1} 
    [To try your best] also includes to ask for help when it's necessary.
    \ex\label{ex:complement.infinitive.1p} [The skill to ask for help]_{\text{subject:\acs{np}}}
    is a strength.
\end{exe}

TODO: Is this control?
We may analyze this as (semi-)control:
The null subject of \corpus{to travel a lot} 
seeks reference and can only has coreference with the object,
and this doesn't seem like a purely syntactic process
compared with raising.
The coreference here may be better analyzed as a semantic effect:
The only ``active'' \acs{np} in the clause is the object \corpus{him},
and therefore the null subject has to refer to the object.
This creates another problem: 
Whether the classical object control is also from the same mechanism.

\begin{exe}
    \ex To travel a lot annoys him.
\end{exe}
I think it's not, because we also have 
\begin{exe}
    \ex To travel a lot sometimes is annoying for him.
    \ex For her, to travel a lot is never a burden.
\end{exe}
So it seems 

TODO: see \citet[\citepage{1269}]{cgel}

\subsubsection{Object and post-object infinitives}

Infinitive clauses in the \acs{vp},
on the other hand, 
have much richer behaviors.
This section discusses infinitive clause constructions with the constituent order 
shown in \prettyref{fig:complement.infinitive.template},
where the object position and the infinitive complement clause position 
are all internal complements shown in \prettyref{fig:clause-template},
and the object position may be absent.

The subject and the object of the matrix clause may originate from the subject of the infinitive.
If this is the case,
then there are two possibilities regarding the mechanism that connects the matrix subject/object 
and the infinitive subject:
control and raising \citet[\citepages{1194-1197}]{cgel}.
With the control mechanism,
the \acs{np} in question bears two argument roles,
one from the main verb of the matrix clause, and the other from the main verb of the infinitive clause.
With the raising mechanism, however,
the \acs{np} in question receives no argument role from the main verb of the matrix clause.
This results in several structural and semantic differences,
which will be talked about later.

\begin{figure}
    \centering
    \input{templates/infinitive-outside.tex}
    \caption{The template of all infinitive clause constructions}
    \label{fig:complement.infinitive.template}
\end{figure}

\begin{theorybox}{The control/raising distinction from a Minimalist perspective}{minimalist-control-raising}
    Essentially, the difference between control and raising is 
    whether the ``object'' bears more than one $\theta$-role,
    and historically people assume that a DP can only bear one $\theta$-role,
    so control can't be from movement.
    This however is disputed from a Minimalist lens,
    and the ``single $\theta$-role'' condition 
    can be loosen without overgeneration,
    and therefore both control and raising come from movement
    \citet{hornstein1999movement}. 

    The real problem, however, is not whether control \emph{can} be accounted for 
    by a movement theory, 
    but whether it's appropriate to do so:
    If doing so TODO: semantic theory of control fits better crosslinguistically??
\end{theorybox}

Some generalizations further narrow down 
the number of possible infinitive clause constructions.
English has a strong tendency to spell out only one copy of a moved constituent,
so if the subject of the main clause is linked to the subject of the infinitive,
then the latter is not visible,
and the object of the main clause, if any, has to be base-generated;
and if the object of the main clause is linked to the subject of the infinitive,
the latter is also not visible,
and the subject of the main clause has to be base-generated.

The subject can also be a dummy in other complement clause constructions.
When the complement clause is an infinitive, however, 
this seems impossible (\prettyref{ex:complement.infinitive.no-dummy-subject}).

\begin{exe}
    \ex\label{ex:complement.infinitive.no-dummy-subject}  \begin{xlist}
        \ex It seems that he is mad.
        \ex *It seems for he to be mad.
    \end{xlist}
\end{exe}

Subject raising (i.e. raising the subject of the infinitive to the subject of the matrix clause) 
is not compatible with the object position.
This seems to have a semantic motivation:
If a verb doesn't have an agentive role -- 
which is always true in the case of subject raising,
by the definition mentioned above -- 
then it also doesn't have a patientive role,
and therefore the object position is not licensed.
Subject control, on the other hand, allows the object position.

Thus, possible infinitive clause constructions with 
the infinitive in the \acs{vp} are summarized as follows:

\begin{table}[H]
    \caption{Infinitive constructions with the infinitive being in \acs{vp}}
    \label{tbl:infinitive-object}
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    subject                                 & object                & example \\ \midrule
    subject raising                         & no object             & (\prettyref{ex:complement.infinitive.vp1})  \\ \midrule
    \multirow{2}{*}{subject control}        & no object             & (\prettyref{ex:complement.infinitive.vp2})  \\
                                            & object base generated & (\prettyref{ex:complement.infinitive.vp3}) \\ \midrule
    \multirow{4}{*}{subject base generated} & no object             & (\prettyref{ex:complement.infinitive.vp4}) \\
                                            & object base generated & (\prettyref{ex:complement.infinitive.vp7}) \\
                                            & object control        & (\prettyref{ex:complement.infinitive.vp5}) \\
                                            & object raising        & (\prettyref{ex:complement.infinitive.vp6}) \\
                                             \bottomrule
    \end{tabular}
\end{table}

\begin{exe}
    \ex\label{ex:complement.infinitive.vp1} 
    {} [The student]_{i,\text{subject}} seems [---_{i, \text{raised}} to be cheerful]_{\text{infinitive}}.
    \ex\label{ex:complement.infinitive.vp2}  
    {} [I]_{i,\text{subject}} want [---_{i,\text{controlled}} to join your group]_{\text{infinitive}}.
    \ex\label{ex:complement.infinitive.vp3}  
    {} [I]_{i, \text{subject}} promise [her]_{\text{base-generated object}} 
    [---_{i, \text{controlled}} to go away]_{\text{infinitive}}.
    \ex\label{ex:complement.infinitive.vp4}  
    {} I want [for her to complete this task tomorrow]_{\text{sealed infinitive}}.
    \ex\label{ex:complement.infinitive.vp7}  
    I promise [you]_{\text{base-generated object}} [for John to come here]_{\text{sealed infinitive}}.
    \ex\label{ex:complement.infinitive.vp5}  
    I want [him]_{i, \text{object}} 
    [---_{i, \text{controlled}} to complete this task tomorrow]_{\text{infinitive}}.
    \ex\label{ex:complement.infinitive.vp6}  
    I ask [you]_{i, \text{object}} [---_{i, \text{raised}} to do this tomorrow].
\end{exe}

The above classification has direct consequence in the form of the infinitive clause.
(\prettyref{ex:complement.infinitive.vp4},
\prettyref{ex:complement.infinitive.vp7})
have no essential difference with (\prettyref{ex:complement.infinitive.1}).
(\prettyref{ex:complement.infinitive.vp7}) is less frequent 
but is still attested \citep[\citepage{243}]{dixon2005semantic}.

The next step is to analyze the \emph{form} of these infinitive clauses
appearing in raising/control/no-raising-or-control environments.
Whenever raising or control appears, \corpus{for} is absent;
and if an infinitive clause isn't meant to be involved in raising or control,
then \corpus{for} is usually present,
because otherwise the construction 
is interpreted as a control or raising construction 
(\prettyref{ex:complement.infinitive.preference-control-reading}).
Thus, we conclude that \begin{enumerate*}
    \item The word \corpus{for} in an infinitive clause seals the clause 
    and turns it into an \acs{np}-like construction 
    with invisible inner structure in the eys of the syntactic environment, and 
    \item In non-control-or-raising infinitive constructions listed 
    in \prettyref{tbl:infinitive-object},
    the infinitive clauses are the \acs{np}-like infinitives just mentioned  
    and are put in object-like positions.
    (compare (\prettyref{ex:complement.infinitive.promise-np-object}) and 
    (\prettyref{ex:complement.infinitive.vp7}))
\end{enumerate*}

\begin{exe}
    \ex\label{ex:complement.infinitive.preference-control-reading} I want [to join your group]. \\
    \translate{*I want someone else to join your group.}
    \ex\label{ex:complement.infinitive.promise-np-object} The great powers promised the Jews [an independent nation].
\end{exe}

TODO: bare infinitives, let sb. to, make sb. to, see sb. do \citet[\citepage{1236},\citepage{1254}]{cgel}

\subsubsection{Semantic classification of infinitives}

Semantically, an infinitive clause either expresses a potential situation,
or a subjective judgement \citep[\citepage{245}]{dixon2005semantic}.
A judgement infinitive clause 
is always in a subject-raising construction or an object-raising construction,
probably for semantic reasons:
A verb taking a judgement infinitive clause 
takes a cognitor semantic argument,
TODO: but why can't there be a \corpus{for} infinitive clause? 
\corpus{*I find for this food to be bad}

\subsubsection{Interpretation of the null subject}

The \corpus{to do sth.} type of infinitive has null subject.
What the null subject refers to is sometimes decided by structural factors,
as in the cases of control and raising,
and sometimes by semantic and pragmatic feasibility.

TODO: semantic subject interpretation



\subsubsection{Subject-raising}

\begin{exe}
    \ex The boy seems unhappy.
\end{exe}

\subsubsection{Object raising}

\begin{exe}
    \ex I wanted them to start.
\end{exe}

\subsubsection{Control}

\begin{exe}
    \ex I ask them to be helpful.
\end{exe}

Although \citet[\citepage{15}]{dixon2005semantic}, \citet[\citepage{388}]{dixon2010basic2} argue that 
it's not necessary to introduce the concept of object raising in English, TODO

\section{Relative clauses}\label{sec:relative-clause}

The relative clause construction is formed by 

\subsection{Types of relative clauses}

It should be noted that the \corpuscat{wh}-movement in relative clauses 
is not structurally the same as the \corpuscat{wh}-movement in interrogative constructions.
Consider the pair in (\prettyref{ex:clause-combine.relative-question}):
It clearly demonstrates that the relative \corpuscat{wh}-phrase 
is structurally higher than the topic,
while the opposite is true for interrogative constructions.
This may have a semantic motivation \citet[\citepage{330}]{radford2009analysing}:
In question formation, the \corpuscat{wh}-movement is just a marking strategy of the \emph{focus},
which appears below the topic,
while in the formation of relative clauses,
\corpuscat{wh}-movement happens \emph{last},
marks the whole clause as a relative clause, 
and ``seals'' the whole relative clause,
separating its content and the matrix clause.

\begin{exe}
    \ex\label{ex:clause-combine.relative-question} \begin{xlist}
        \ex {} [In you opinion]_{\text{topic}}, 
        [what]_{\text{focus:\corpuscat{wh}}} [is]_{\text{fronted auxiliary}} our most urgent task right now?
        \ex {} [[What], [in his opinion]_{\text{topic}}, is our most urgent task right now]_{\text{relative clause}} still remains unknown for the listeners.
    \end{xlist}
\end{exe}

\subsection{Purpose relative clause}

A rare type of 

\begin{exe}
    \ex I need [a house [to live]_{\text{purpose}}]_{\text{object: \acs{np}}}
    \ex I need [a house [to live in]_{\text{purpose}}]_{\text{object: \acs{np}}}
\end{exe}

\section{Clause linking: subordination}\label{sec:clause-linking.subordination}



\section{Clause linking: coordination}\label{sec:clause-linking.coordination}

Parameters concerning variation of coordination 
include number of coordinates, 
number of coordinators,
and whether we have correlative items like \corpus{both} in the coordination construction.

TODO: \citet[\citepage{1276}]{cgel}

This section talks about FANBOY
TODO: subject extraction

\section{Supplementation}\label{sec:clause-linking.supplementation}

\chapter{Comparative construction}

Comparative constructions appear to fill a ``degree'' position
of adverbs, adjectives, and sometimes, nouns and verbs.
TODO: compare with \corpus{how old} constructions  

\chapter{Prosody, punctuation, and spelling conventions}

\begin{infobox}{The notion of \term{thought group}}{thought-group}
    It should be noted that so-called \term{speech groups}
    and \term{thought groups}
    are neither morphosyntactic or semantic concepts.
    When the subject is light (for example, when it's a personal pronoun),
    the subject and the verbal complex may be grouped into one ``thought group'',
    but that doesn't mean the subject and the verb constitute a constituency:
    it merely arises from prosodical considerations.
    In real world utterances, 
    we may also see subject-only sentences with the object omitted,
    but this may be about production of utterance:
    I already have some templates of clause structures in our mind
    (though with inner hierarchical structures, as in Tree-Adjoining Grammar),
    and after we fill the subject position of one of the templates,
    somehow -- possibly because I forget what to say -- 
    I just stop filling the template and pour the half-finished sentence 
    to the one I'm talking with
    (\prettyref{sec:psycho-real}).
    But still, though groups have something to do with stress allocation,
    which indeed is influenced syntactically \citep[\citepage{7}]{kahnemuyipour2009syntax}. 
\end{infobox}

\chapter{Notable variations}

\section{Early Modern English}

Dialects, etc.



\bibliographystyle{plainnat}
\bibliography{cambridge}

\end{document}