本文试图给出最简方案中一个相对比较能够凝聚共识的分析框架。

# 生成语言学的目的

语法研究大致可以分成四类：

1. 已被证实的
2. 可被证实的
3. 人类可以处理的
4. （在某个非常大的框架内，如type 0 grammar）可被描述的

第一种是已经被明确记录、分析、写下来的语法：英语语法，汉语语法；第二种是我们知道存在但也许尚未调查清楚的，如某个人的特殊遣词造句方式，历史语法；第四种是“脑洞大开”型的，比如说我们可以要求某种语言的词的第质数个音节发生一些变化，或者句子整句颠倒过来表示否定等等。
生成语言学希望能够通过前两种语法获知第三种语法，这就是语法研究的认知取向。

应该指出，大部分人类可以处理的语法实际上都不见得在实际的语言中被证实了。这是很自然的：人类语言大约有6000种，但是所有可能的语法构造排列组合得到的数目恐怕远远多于这个数目。
或者说，生成语言学的理论部分的核心在于“可能的”语法，而不是“比较可能的”语法，后者和心理学、社会学，乃至“某个具有某种奇怪特征的语族正好存活下来了”的意外都有关系，相对复杂。

# utterance production

1. 和心智过程直接相关的概念体现为features，它们被Merge运算组装在一起。有些学派，如DM，会认为这些feature来自词库的一部分（比如说DM中的list A），还有一些学派认为这些feature直接来自心智；本文中我们说这些feature直接来自心智；
2. 每发生一次Merge，就会尝试自下而上地实行spellout，后面的spellout覆盖前面的spellout的结果；spellout从词库中取出lexical entry，将lexical entry的树和要spellout的树做对比，如果能够匹配则将要spellout的树替换为lexical entry中的phonetic form。
3. spellout结束后的树被移送到PF中，进行词划界、音系操作等工作

phonetic form严格来说可能是phonological form，它含有的是音位，或者甚至可能还有一些超越音位的信息，比如说一个后缀的PF就可能是-ed，-表示它应该黏附到它之前的某个成分上，即有以下规则：

A-B -> AB

我们甚至可以认为语序的确定也是在这一步完成的。例如，一种verb final语言的动词的phonological form可能是"-V"，即带有一个表示head final的标记；或者甚至这个phonological form可以同时指定specifier和complement的相对位置，然后我们有音系规则：

[<sub></sub> A [ X<sub>[head first, specifier, first]</sub> B ] ] -> A X B

这样head directionality parameter就是一个language specific的规则。

# 操作

## 基本句法操作

Merge可以分成两种：External Merge和Internal Merge（又称Move），后者是从已经组装好的成分中复制一个子树然后用于Merge，也就是Move。
Move包括只涉及一个树的简单Move，即将一个树的某个子树移动到其边缘；也有sideward movement，这个是把一个树的子树移动到另一个树的边缘（然后如果再将两个树Merge起来，那就得到了head movement）。
还有ATB movement，就是两个一样的子树被一起移动到树的边缘，只留下一个。
这实际上可以通过一次sideward movement（形成两个一样的子树）加上一次简单Move（将一个子树移动到边缘）来构造。

Copy theory of movement是不能放弃的，因为语言习得中确实有"What do you like what"这种lower copy没有被删除掉的例子。

其实sideward movement并不需要被频繁地用到，因为大部分时候spellout可以cover那些在lexicalized的理论中需要的head movement。

Agree运算让feature“扩散”。

原则上，所有的Agree都可以使用Merge时的选择特征来代替，即如果Merge进入树的成分的某个特征和它应该通过Agree被value的值不同，那么句法推到崩溃。（或者说对应的推导具有很低的概率，等等）

Spellout运算遵循以下步骤：将要被spellout的树和词库中的树比对，构成要spelllout的树的超集，但与此同时比要spellout的树多出来的成分最少的树对应的语音形式就是spellout的结果。
也即：

1. 在所有能够被spellout的子树当中，选择最大的子树；
2. 在所有能够spellout该子树的条目中，选择能够完全包含该子树的条目；
3. 在上一步选取的条目中，选择那些含有特征最少的条目。

完全有这样的可能：一个树的子树先被spellout了一次，然后它本身又被spellout了，那么既然后面的结果覆盖前面的结果，我们得出结论：词库中能够匹配要被实现的树的最大的树最终胜出。

如果匹配不到任何lexical entry，那么忽略要spellout的树中已经被spellout的成分（trace也忽略），再次尝试匹配。实际上“已经被spellout的成分”这个概念是有点模糊不清的：它是指字面意义上已经被匹配过、实现过的树，还是已经“定型”，被transfer到PF的树？

以上所有操作都是cyclic的：Merge总是发生在正在被处理的句法树的最外层，Merge完之后就尝试spellout。
总之，同一个树中可能有一些部分正在被Merge建构，有一些部分已经被spellout了。

# 可以被废弃的，但仍然有用的概念

## feature bundle

**feature bundle**是多重head组成的一个复杂树的一种简化写法，具体来说是把[<sub>αP</sub> [<sub>βP</sub> ... ] ]中的α，β等看成一个head。由于本文给出的系统并不区分adjoined head和projection，这种“粗粒化”手段一定是可行的。
我们还将在下面不断看到这种操作。

## head assigning features

我们经常做这样的分析：T带有一个主格特征，它和主语发生Agree之后主语带上了主格，等等。
考虑到feature bundle不存在，似乎不应该下这样的断言。
不过，从以上传统分析切换到one feature one head的分析并不困难。在认为名词性短语中有一个（也许是unvalued的）CaseP投射之后，至少有两种方案：

- 认为TP之上还有一个NomP投射，它携带了主格特征，它和名词性短语中的unvalued Case head发生Agree；
- 认为和T发生Merge的成分一定带有主格

第一种方案可能造成疑难：这样语音实现将会产生两个主格标记。一个简洁的解决方案：NomP内部有Nom, 名词性短语和TP；TP可以整体被语音实现，那么等到要实现NomP时就只需要实现[<sub>NomP</sub> 主语 Nom ]即可，正好是我们想要的结构。
当然，Agree机制还是需要的，因为主语内部的形容词可能也要跟着变格。

第二种方案可能造成疑难：这个selectional feature是怎么来的？也许需要诉诸C-I系统。

实际上，将feature-assigning head分析成一系列小head可以解释很多在feature bundle的描写粒度下非常难以解释的现象。
比如说，一个head（记作H）赋予其complement一种feature（记作F1），而赋予其specifier另一种feature（记作F2），使用传统理论似乎很难解释，因为需要给feature排序。
但是，如果将这个head劈裂为F2-H-F1的层级，那么就立刻豁然开朗了：

1. complement和F1发生Merge，它获得特征F1；
2. head进入推导；
3. F2进入推导；F2的complement是[ H [ F1 Comp ] ]，其中没有任何未求值特征（如果有，也已经被F1求值了）；
4. specifier和F2被Merge；F2和specifier发生Agree，specifier获得特征F2

我们自然地获得了我们想要的特征排序，它是由两个特征在句法树中的排序衍生而来的。同样地我们也可以让某个head赋予其较低的specifier一种feature而赋予其较高的specifier另一种feature。

## selection

类似于“名词选择动词”这种selection现在可以被拆成两部分。一部分直接来自概念-意向系统，一部分来自spellout。
前者的例子不用多说。
后者的例子：有些动词的宾语一定要有某种格，那么如果我们认为具有某种格的动词由一个functional head带出，并且动词只有和这个functional head放在一起时才能够正确地被spellout，那么我们就解释了为什么该动词的宾语一定要具有某种格，或者说为什么这个动词选择具有某种格的名词。

当然，如果我们真的要认为抽象feature带有selector也不是不可以，但是这样就需要一个包含各种抽象feature的抽象词库，句法是从词库投射而来的。
但是实际上不用这个词库也可以得到一样的解释效果。
无论如何，这个真的是notation的问题了。（所以从这个角度，nanosyntax和DM的语法结构其实是统一的，只不过使用的记号不同罢了）

实际上，概念-意向系统的限制也可以理解成spellout的限制：无法正确地语义实现一个句法树，那么它肯定不合法。

还有一种方法可以规避在词库中显式地引入selectional feature：假定句法树存在universal spine，比如说句子结构一定是ForceP-FocusP-TopicP-FinP-TP-AspP-vP-...，名词性短语一定是DP-NumP-ClP-NP，那么所有需要的selectional feature全部都被保存在spine中了。
的确，很多语言缺乏某些投射的显式形式，但是一级不触发移位、不选择specifier、不改变c-command关系的投射有和没有也没什么区别。
这样做的好处不言而喻，实际上这就是句法制图理论的基础；这样做的坏处是，似乎我们还是要假定人脑自带一个非常复杂的“模板树”，且句法树自这个“范本”投射而来，实际上等价于增加了一个包含有selectional feature的“抽象词词库”，也就是DM中的List A。

## category

像“名词”、“动词”之类的category的作用通常是为selection提供目标（比如说动词应该选择名词，等等）。
但实际上我们也还是可以使用category head和实义词根组合来达到这样的效果，比如说“走”就是verbalizer加上“走”的抽象概念。

然后，有些词总是名词，有些词可以是名词又是动词，还有些词只是动词就可以归结到概念-意向系统上面，比如说verbalizer+“人”没办法语义解释。

不过，需要注意的是，feature还是应该有某种“分类”，例如[case: nominative]，[φ: 1sg]等等，否则Agree时会出现“人称特征被赋予了格”这种荒唐现象。
那么，名词性、动词性等或许可以写成[category: noun], [category: verb]这样。

## 单一probe-goal

一些理论框架中的Agree只有单probe单goal，但是如果采用本文的说法，那么一个head中的feature可以扩散到整个phase中，因此本文提出的Agree本质是多goal的。
然而，由于Agree操作紧接着Merge发生，这种cyclic的执行方式意味着一次Agree能够求值的特征是很少的，因为更低处的特征全部已经被更早的Agree求值了。
这就是Agree在很多时候可以认为是单probe单goal的原因。

## 实义词根和功能语类一样吗？

实义词根通常允许各种活用，而功能语类不允许。不过我们真的把实义词根当成一系列功能语类的组合（比如说"fall"就是“向下运动”，然后可以使用诸如“向下”、“运动”之类的功能语类来组装出它），然后认为概念-意向系统允许将实义词根和category head组装起来，那就解释了各种活用。

当然，单独分出来一个实义词根肯定可以大大简化分析。

## post syntactic operations

主要是affix lowering和head movement，是不是把这两个东西当成post syntactic operations完全取决于你认为句法可以容忍多少语义无解的东西。
由于我们使用one feature one head的模式，head可以通过Agree之类的方法轻而易举地被复制。
以affix lowering为例，原本分析为：

 [<sub>α</sub> α [ ... β ... ] ] -> [<sub>α</sub> <del>α</del> [ ... α β ... ] ]

的过程现在可以分析为（uF表示unvalued feature）

[<sub>α</sub> α [ ... [uF] β ... ] ] -> [<sub>α</sub> <del>α</del> [ ... α β ... ] ]

这样可能会产生一个疑难，就是为什么单单spellout和β在一起的α，而不spellout highest copy of α。
当然，可以使用chain reduction之类的概念解释（在本文的框架中实际上就是认为音系规则删除了一些冗余内容），还有一种解释是认为α和某些更高的head可以一起被spellout，然后这种情况下它没有语音形式。
实际上，这也许也解释了为什么chain reduction在不同的语言中常常展现出完全不同的行为，因为能够影响它的因素实在太多了。

readjustment和context-relevant spellout的概念可以使用适当安排lexical entry来解决。例如对readjustment (doed -> did)，可以认为did是[do + past tense]整体语音实现的结果，那么由于biggest wins，最后正确的形式就是did。
readjustment是spellout过程中自然而然发生的。
context-relevant spellout需要的无非是引入更多的functional head，通过Agree之类的方法捕捉上下文中影响spellout的信息。

但需要注意的是，以上方法都需要假设很多仅仅用于确定形态的functional head，实际上就是AGR insertion的翻版，因此本质上仍然多多少少有点purely morphological的意思。
这就完全是记号的问题了。

还有一个是spellout driven movement，我们其实完全可以把这个看成“词的话题化”或者“词的EPP”。当然这样的坏处就是需要增加大量功能语类，并且不同的语言中这些功能语类是不是都存在就很可疑。不过反正句法制图也有类似的问题对吧……

引入post syntactic operation的还有一个目的是，似乎的确有本身可以看成一个constituent的complex head，而简单地依靠spellout和顺序调整没法弄出这样的complex head。

## 上下文相关的spellout

没有必要显式地引入上下文相关的spellout。有必要的上下文相关性可以通过两种方式解决：

1. 引入一个不可见的functional head来传递上下文相关信息。例如，很多语言名词变格的词尾和名词词干有关，那么我们只需要要求名词性短语的结构为[<sub>CaseP</sub> ... [<sub>DecP</sub> [<sub>NP</sub> ... N Declension ... ] Declension ] Case ]
   即可。NP选择了适当的Declension head（具体过程有一些麻烦之处，可以认为Declension head和NP中的变格法信息发生了Agree，但这样会导致两个Declension head，但是这不要紧，因为可以认为Declension head和N一起spellout时不显形，而和Case head一起spellout时显性；也可以认为NP的selectional feature选择了适当的Declension，但这样需要人为设置一个selectional feature；还有一种方法是，认为外层的DecP会触发NP内部的变格法信息移位到其specifier位置，因为只有这样才能被正确spellout），然后自下而上做语音实现，形容词数量词classifier什么的一个个被spellout，最后只剩下Declension和Case，这两个被一起spellout为一个名词词尾。
2. 实际上还是引入不可见的functional head来传递上下文信息，但是有关的操作涉及语义。比如说，我们可以将反身代词分析为AnaP+普通代词，然后Ana的指称也许可以在Syntax proper中获得（或者LF，无论如何有关的操作涉及语义），那么如果在一个phase中获得不了指称（Reference feature无法发生feature checking），推导就失败了（比如说没法被语音实现，或者没法被语义实现，等等）。

## 关于chain和chain reduction

前面讲到，spellout时忽略trace，但这个看起来有点奇怪，因为这相当于假定trace也被spellout了。此外，一个chain中哪个是trace哪个是具有语音实现的copy这件事对spellout而言应该是完全不可见的。
使用传统的方法，我们要假定发生移位的对象几次移位产生的copy构成chain，然后spellout时chain中最高的一个copy被spellout。
但是这样就引入了非常上下文有关的机制。

换一个角度，我们可以认为所有的copy实际上都被spellout了（从而忽略trace是对的，因为trace对应的copy确实被spellout了），只是在句法-音系接口那里为了简洁，不那么prominent的copy被删除了。
这样我们就把在不同语言中非常不同的chain被spellout的机制（比如说汉语中就有“好不好”这种两个copy都被spellout的情况）转移到了本来就在不同语言中有很大差异的音系接口那里。

看起来，这样做实际上是把tricky的问题转移到了PF中，但是这个转移倒是有可能是必要的，PF中从来不缺元音和谐这种并不那么局域的东西。
（关键点其实在于分析句法中超越CFG的部分在哪儿，Agree显然是这类现象的主要来源，但是Agree没法解释为什么有些元素看起来是被“删除”了——我们要么显式地引入一个Delete运算，要么在Spellout那里要做文章，否则是不行的；原则上，Agree和Delete应该是平等的，前者导致特征的扩散，后者导致特征的消失，但是Agree有明确的动机（未求值特征需要被求值），而很难想象什么会触发Delete运算。那么，将Delete留到PF中也许确实是更好的选择）
真的会产生麻烦的是partial spellout，也就是有一些trace被语音实现为比较“弱”的成分（比如说“邻居那户人家，他们做的饭很好吃”中的“他们”）。
不过实在不行，也可以认为partial spellout实际上并不存在，“他们”和“邻居那户人家”一开始是一个constituent，后来才分开。
这就又是一个纯粹的记号问题了，我们在这里再一次通过多引入functional head的方法避免了context-sensitive spellout。

## 向心结构，以及adjunct和argument的区分

语言中常出现所谓的向心结构，即一个语义上比较重要的中心语周围围绕着一系列与它有关的成分。
这个中心语和X-bar scheme中的head还是有不同的，例如TP-vP-VP投射中V只是最低一级投射的head，但是由于T,v,V被spellout后位置都大约在V上面，它的确可以看成中心语。
类似的还有DP——DP的head是D但是中心语是N。
在中心语周围围绕着的成分中，通常认为必须的成分是argument而可选的成分是adjunct，但是如果我们认为很多成分都是作为一个functional head的specifier进入句法树的，那么就不需要argument和adjunct的区分：为何argument是必须的而adjunct可选，或是何时特定的adjunct不能出现可以归结到一系列selection, feature checking以及functional head的缺少或者出现对spellout的影响上。
不过，考虑到大部分时候多一个functional head并不会特别影响中心语spellout，而缺少特定的functional head确实会影响中心语spellout，（我们可以设定必须出现的argument对应的functional head在词库中的树中一定出现，那么对应的argument不出现中心语就不能被spellout），区分argument和adjunct在描写上还是有价值的。

# 对一些疑难问题的澄清

## 忽略trace导致的语序问题

考虑以下句法树，其中...表示已经被spellout的成分：

[ A [ t [ B ... ] ] ]

假定词库中有lexical tree [ A [ B ] ]，考虑到t2和t1均为trace，该syntax tree可以被正确spellout。

然而如果我们认为trace实际上也被spellout了，只是在PF中被删除了，那么就会产生一个大问题：t1和[A B]的语序是怎么样的？
毫无疑问，如果t不是trace而是一个有语音形式的成分，那么它很可能阻断[A B]的spellout

需要注意以上结构会在下面的derivation中出现：

1. 结构[ A [ C [ B D ] ] ]形成
2. cyclic spell out：D被spell out，形成[ A [ C [ B ... ] ] ]
3. C由于某些原因移出，得到[ A [ t [ B ... ] ] ]

乍一看，可能的解决方案包括：

- 认为某些movement实际上是不留下trace的，这等价于要求句法中有一个Delete运算
- 认为存在spellout-driven movement

但这两个解决方案都会引入额外的句法操作。

其实这里的问题还有一个。例如，设某个成分A移动到了某个head H的specifier位置，并且和H一起被spellout了，那么它的trace的语音形式是什么？
特别的，如果没有H，A就不能被spellout，那么它的trace不能被spellout这件事为什么不影响句子的合法性？（例如主语移位后获得主格，那么主语留下的trace获得格了吗？如果没有那为什么句子是合法的？）

一种可能的思路是，在词库条目中引入抽象模式，例如[ A [ _ [ B ] ] ]一概spellout为AB。这样就免去了上面提到的“如果没有H，A就不能被spellout，那么它的trace不能被spellout这件事为什么不影响句子的合法性”的问题。
如果要保留C，那么C必须在此之前发生了移位。

需要注意的是这种思路要求derivation by phase，否则C还没有移出去，就已经在语音形式中被忽略了。

还有一种可能的思路是，既然我们想要一个明确的语序，那么就规定spellout的结果被放置在原来的A上面好了。
这样我们就有以下推导：

1. 句法树：[ A [ C [ B D ] ] ]
2. C移出，留下一个copy：[ A [ C [ B D ] ] ]
3. D的spellout发生：[ A [ C [ B ... ] ] ]
4. 留在AP中的C的copy被spellout
5. 此时的AP可以和词库模式[ A [ B ] ]匹配，得到完全被spellout的树[ AB [ C ... ] ]
6. 然后也许C在AP中的copy什么时候被删除了

这种思路没法解释移位前的copy实际上没法spellout这个疑难，因为它要求移位前的copy要spellout，这样[ A [ B ] ]才能匹配上句法树。
最后的结果就相当于发生了B-to-A的head movement。这个head movement是非常局域的，或者说和head movement constraint一致。
实际上，很大一部分affix lowering可能也是来自同样的机制——例如英语中的T-to-V lowering，考虑到specifier-vP总是会移动到T以上，实际上分析成V-to-T movement也不是不可以。

以上两种思路都可能是正确的，实际上很有可能它们可以分别被用于解释不同的现象。

## constituent-hood and spellout

我们假定语序是句法树被spellout之后在PF中给出的，但是这样就产生了一个问题：PF必须知道被spellout以后得到的lexical item序列的大致hierarchy。
例如，设[ T [ Asp [ v [ V DP ] ] ] ] 被spellout为/is -ing V DP/，PF必须知道应该将-ing附加到V后面。
然而，如果我们允许PF获得整个层级结构，为什么PF不能将-ing附着到DP后面？
换句话说我们必须保证PF是足够局域的，但这样一来，似乎只能够允许[A B] -> AB型的规则，那么就无法解释为什么能够将Asp后缀-ing附着到V后面，既然Asp和V并没有构成一个constituent。

remnant movement在这个时候就体现出了一定的好处。当然，这么破坏性的操作还是少用为好。
DM的策略是使用post syntactic operations，但正如我们所见这会导致一个疑难：形态学信息全部在list B中，但是发生post syntactic operations时还没有发生Vocabulary Insertion。

实在不行就local dislocation算了，先是以[A B] -> AB规则正确排列所有lexical item，然后执行诸如 -ing V -> V-ing之类的规则。

## 直接成分分析法（ICA）

我们希望spellout之后的成分结构和朴素地使用ICA分析出来的结构大致相同。要怎么做到这一点？
主要的麻烦在于，我们将spellout的locus定在被spellout的树的最高点，那么spellout之后的c-command关系就有可能乱掉。
比如说complementizer附着到动词上是非常普遍的现象，它的生成方式也是非常正常的：所有的名词性成分都spellout之后，C-T-v-V投射被整体spellout成一个（可能有许多后缀，比如说日语中那样的）predicate。
但是这样一来，得到的结构就是[ [ subject object ] predicate ]。

同样，这也是非常错综复杂的一个问题。比如说所谓的C-T-v-V投射被整体spellout也有可能是C affix lowering到了predicate上面，又或者干脆C就是被spellout成了一个clitic，然后被黏附到了predicate上面，等等。

但无论如何有一件事是肯定的，那就是ICA显然不是“最终的答案”，比如说显式的complementizer和lowering到主动词上的SVO语言的complementizer根本就是同一种东西，但是ICA会把前者当成一个单独的层级而把后者当成普通的词缀。

## phase

Phase Theory, Angel J.G.

比较麻烦的是phase的概念。

a rule of thumb: uninterpretale features被check的地方就是一个phase head。
如果我们假设，为了避免混乱，被spellout过的成分不再能够发生其它句法操作，那么实际上我们就获得了某种版本的phase：一旦一个成分被spellout并且没有更大的lexical entry可以spellout它，那么它就不再能够发生任何句法操作。

总之，现在我们有两种理论：

- 存在phase，只有当phase head进入推导时，才发生自下而上的spellout；spellout在匹配lexical entry时忽略所有已经被transfer的成分。
- 没有显式的phase概念，被spellout过的成分不再能够发生其它句法操作，那么最大的lexical insertion就构成一个phase；这样实际上到处都是phase，不止C或者v

后一种理论可能产生这样的疑难：既然到处都是phase，那么C或者v有什么特殊的？phase head起到两种作用：一种是避免phase内部再发生Merge，或者phase内部的feature被赋值，而一旦假设spellout过的成分不再发生别的句法操作，这就是显然的；第二是避免phase domain内部的特征扩散到外部去，但是这可以通过让Agree尽可能local来解决。
的确，通过specifier“逃离”phase的情况是确实存在的，但是要逃离的phase并不是phase head触发的。

需要注意的是为了保证外界能够“知道”一个已经spellout了的成分是什么，已经spellout的成分中的特征还是可以扩散出去的，例如已经spellout了的DP也可以导致第三人称单数词尾。

phase的另一个关键点在于限制上下文有关的spellout。看起来，一个代词是被实现为普通代词还是反身代词，主要还是取决于它和先行词是不是在同一个phase内部。
当然本文使用的spellout算法没有上下文有关的spellout，但是的确有一些理论会使用上下文有关的spellout。

phase的还有一个用处是保证一些成分在被spellout在原位前有足够的时间移位出去（比如说spec-vP），也即，我们假定phase head进入句法推导时才触发spellout，而不是每当一个head进入推导就触发一次spellout。
不过其实这个用处也不是很大。

有一种方法，可以从“每Merge一个feature就尝试spellout”的框架导出phase的概念：我们可以认为phase head不能单独spellout，即词库中spellout phase head的条目是[ H _ ]，那么只有H的complement被成功spellout了之后H才能被spellout，并且由于和H有关的lexical entry只有这一条，HP一旦被spellout了就永远不会再被更动，从而可以被transfer给PF。

有一些现象，如某些动词（suggest等）的论元一定要是具有特殊mood的从句（如一定要是虚拟语态），似乎也说明已经被spellout的成分还是可以参与到selection中，即它们内部的特征还是可见的（虽然不再发生Agree）。

## Borer-Chomsky Conjecture

不同语言的差异仅仅限制在词库中。这里的问题是，句法中的抽象特征是不是词库的一部分？或者说，不同语言的句法树能不能是不同的？

## Sideward movement

head movement和ATB movement都是sideward movement的产物。head movement还涉及head是否可以移动的问题，不过实际上这完全就是记号问题。
sideward movement常因为the Extension Condition被拒绝，但是如果我们转而使用比较弱的Feature Cyclicity——一个feature的所有selection操作（Merge, Move,等等）必须一次性完成，然后这个feature对应的最大投射就被构建完毕——那么head movement和ATB movement就都是可以的。

## head能否被移动？

实际上head能不能被移动纯粹就是记号的问题。举个例子，以下结构：

[<sub>HP</sub> Spec H Comp ]

完全可以改写为

[<sub>XP</sub> Spec [ H X ] Comp ]

即某个不可见的X选择了H（此时H可以被分析为一个极大投射），然后选择了Comp和Spec，这样句子结构没有任何实质性的变化，而H就可以移动了。
实际上，head split就是在干类似的事情。

实际上，基于类似的理由，也没有什么理由不让中间投射spellout。

## 句法中有哪些非局域的东西？

音系学调整实际上都是非常局域的。

Agree是比较不局域的（但是由于它局限在一个phase中，实际上有可能仍然是足够局域的）

Move非常不局域，例如，疑问句形成中，任意深的宾语从句中的名词性成分都可以移动到句首。

然而，实际上会出现的movement的类型非常有限，这就意味着实际上只需要Merge一个操作就可以cover大部分句法现象。
换句话说，全部普遍语法可以概括为“抽象概念通过Merge组装形成句法树，边组装边发生spell out，spellout出来的串发生局域的音系操作，最后得到一个串即语音产出”，而其余一切的限制或者来自syntax和其它认知机制的接口或一些物理上的限制（所谓the third factor），或者来自performance性的因素。
这样的结论和生成语法通常给人的印象——rich innate universal grammar——非常不一致，但同时也和激进的usage-based理论不完全一致。
语言不再是纯粹的nature的或者nurture的，而是nurture via nature的。

## 和Move相关的delete

和Move相关的delete的主要问题是，它非常非局域，非常难以分析。而且mandatory deletion和可选的省略是非常不同的。

# 对常见现象的解释

## 形态变体

传统上用readjustment rules解释为什么会有do+ed -> did这一类情况，但是实际上完全可以用biggest wins定理解释它：did整体实现了do+ed而已。

## coreference

可能代词和名词一开始是同一个constituent，后来名词移走，代词留下。但是这样依赖要解释anaphor就必须要求上下文有关的spellout。

在处理anaphor时，有一种可能是，anaphor有unvalued的指称属性，这个feature必须和某个DP发生Agree才行。这样一开始代词和名词就不是同一个constituent，否则一开始就已经发生Agree了。

## relativization

[<sub>XP</sub> 被提前的名词 [ X [ 从句 ] ] ]

然后也许被提前的是一个DP，也许是NP（从而需要将XP封装进一个DP中）

## 中缀、闪米特语式的模板形态学、重复

均通过抽象词缀+语音调整来实现，和通常类型学中语言标注采取的方式完全一样。（比如说模板形态学就是/CiCaCe + ktb/ -> /kitabe/，专门引入一些这样的规则；重复就是/RED + a/ -> /aa/，如此等等；这些操作都是非常局域的）

# 最简方案句法树和ICA

将最简方案的树转化为ICA的树是有必要的（例如，著名的Penn Treebank的标注原则就受到了 Goverment and Binding的很强影响；见Using linguistic principles to recover empty categories, Richard Campbell; Accurate Unbounded Dependency Recovery using Generalized Categorial Grammars, Luan NGUY EN et al. 等文章）。
不过由于最简方案中有好多彼此冲突的能够决定树结构的因素，这件事不那么容易做。

首先，derivation tree本身决定了一个树结构：将没有语音实现的节点等都删去即可，如

[<sub>TP</sub> SUB T [<sub>vP</sub> v [<sub>VP</sub> V OBJ ] ] ]

可以直接简化为

[ SUB [ V OBJ ] ]

但是如果只是这么做，就会出现在传统语法中无法接受，在lexicalist的生成语法中也无法接受的事情，比如说日语中动词词尾会分散成很多个，其中一些出现在比主语还要高的位置上……因此，形态学操作对ICA树也有必不可少的贡献。一般来说一个词都可以分成一个“重”的词干加上一堆前后缀，在这种情况下我们认为“重”的词干对“轻”的前后缀的吸引力非常强，从而将词干和前后缀分析进一个单元中这条规则的优先级在derivation tree结构的优先级之上。

# 总结

## 分析框架

我们认为各种自然语言句子可以被下面的（概率）自动机生成：

- 可调参数：
  - **抽象词素**
  - **拼写规则**，形如 [ α [ _ β ... _ ] ] -> 语音成分 的规则，其中_表示已经被语音实现了的部分
  - 给定工作空间、其它的认知因素，一个词素被选中为head的可能性；
  - 给定工作空间、正在构建的句法树、其它认知因素，一个词素或是工作空间中已有的句法树被合并入正在构建的句法树中的可能性
- 自动机状态包括：
  - 一个集合（称为**工作空间**），其中有一些句法树；
  - 正在被构建的句法树；
  - 目前正在进行的推导阶段，它可能是：
    - 扩充工作空间；
    - 构建句法树；
    - 语音实现。
- 自动机允许的动作：自动机持续地做下面的循环：扩充工作空间-构建句法树-语音实现（称为**Successive cyclicity**），这三个步骤的流程为：
  - 扩充工作空间：将一个词素加入工作空间，并且指定这个词素为正在构建的句法树（可能被这么做的词素称为**head**）。
  - 构建句法树：将抽象词素或是工作空间内已有的任何树合并到正在构建的句法树上（我们说被合并入正在构建的句法树的成分被**选择**了）。当没有更多内容能够被合并到正在构建的句法树上时，这个句法树称为**最大投射**。
  - 语音实现：对正在构建的句法树作用拼写规则 TODO 在这里仍然没有任何一致意见，因为如果要语音实现 [ α [ _ β [ ... ] ] ] 这样的树，αβ应该放在_前面还是后面没有明确结果。这两者的区别就是head movement和affix lowering。分析这种树是重要的，因为动词在前，否定词在后的结构是非常常见的，而这看起来似乎是V和T被语音实现成了同一个词。但是应当注意实际上这对我们的句法的生成能力没有任何影响，因为空的head配合特征扩散可以实现任何局域的形态操作——如果需要让AB两个语素的位置交换，我们只需要假设A语素上方有一个head能够和B发生Agree即可。
- 输出：任何已经全部被语音实现的句法树

应注意span spellout——也就是将内部已经含有语音实现好了的子树的树语音实现，或者说将[ α [ β [ ... ] ] ]中的α和β语音实现成同一个词实际上还是施加了一定的语序约束，比如说[ α [ β [ γ [ ... ] ] ] ]要么变成[α  β  γ] ... 要么变成... [γ β α]。

输出后的内容可能仍然要经历句法-音系接口的加工（如删除）

可以演生出的性质：

- 工作空间中的所有树，除了正在构建的句法树以外，全部是最大投射
- 会出现Copy操作，设正在构建的句法树有子树β，如果β是最大投射，那么它一定会出现在工作空间中（请注意我们还没有假定任何工作空间中的树被移除的操作），因此在未来的某个时刻可能被合并入β中。配合适当的句法-音系接口的删除机制，这给各种各样的phrasal movement提供了可能
- 可以出现特征扩散，即head的特征扩散到了被选择的成分中，因为我们可以指定：被选择的成分必须具有head的特征，否则不会被选择
- 可以出现“head movement”，它可以来自两个机制：一种是语音实现时的local dislocation；一种是被移动的head根本就不是真正的head
- 已经完全被语音实现了的树的移位通常更加“畅通无阻”

这些可调参数显然是太多了，可能造成强上下文相关性。通常会将它们的形式设定在特定的范围内。
下面的约束基本没有争议：

- 对“给定工作空间、其它的认知因素，一个词素被选中为head的可能性”：限定仅有一小部分词素能够成为head