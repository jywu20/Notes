# 概念定义

head：句法推导中最基本的成分，直接从词库取出而没有经过别的操作。head大体上可以当成词，但也可以是词根、词缀。“词”的概念是PF定义的。

PF：即phonetic form，语言的外显形式，即被说出来或者写下来的形式

LF：即logical form，语言的语义形式，即基本上和逻辑演算中的表达式类似的形式

specifier，complement

# 基本句法操作

基本框架：几个操作：Merge，Agree，Spellout。
它们配合可以产生Copy，Move，很多时候可以仅仅使用Merge和Move。

## Merge

指导Merge的是句法元素含有的**选择特征**，如动词选择名词等，从而形成二叉树结构。
Merge分为Head Merge和Phrasal Merge两种，它们实际上也没有特别本质的区别。Head Merge可以改变一个句法成分的选择特征，TODO

Move也分成Head Move和Phrasal Move，前者是head to head，后者是argument to argument。

Head Merge在一些理论，如Distributed Morphology中，被废弃了，取而代之的是句法操作完成后的音系学操作。
这里的核心争议在于有没有必要将Head Merge区分出来作为一种单独的操作。

## Agree

有一些人认为Merge发生时Agree随之发生了，且Agree不能远程发生，即Agree只能发生在一个最大投射中，或者甚至只能发生在正在被Merge的两个成分之间。
Agree的具体机制仍有争议，Pesetsky, D. 2013. Russian Case Morphology and the Syntactic Categories. MIT Press.认为Agree过程中发生了Feature assignment，即：
若句法成分$\alpha$主动和一个最大投射$\beta$发生了Agree，那么$\alpha$的特征被全部复制到了$\beta$的**所有**head上（不包括已经被Spellout的部分）。
这就避免了多重Agree。

采用这样的观点可以解释很多观察到的Agree的性质。例如，若head$\alpha$和比它低的head$\beta$有Agree关系，那么必然$\alpha$c-command$\beta$，且$\beta$应该和$\alpha$离得尽可能近。
从feature assignment的角度看，这是因为当$\alpha$和$\beta$Agree时，唯一的可能是$\alpha$和某个包含$\beta$的成分发生了Merge，此时$\alpha$c-command$\gamma$中的每一个成分，自然也c-command$\beta$（如果$\alpha$是中间投射，那么就是$\alpha$的head m-command $\beta$）；
$\alpha$和$\beta$不能相距太远，否则它们可能被phase boundary隔开，就不能发生Agree了。

表面上，feature assignment只允许一个head和另一个成分发生Agree，例如只能够有动词-宾语一致或者动词-主语一致，但通过添加多个功能语类很容易绕过这个限制（如把动词劈裂成动词主干、和主语Agree的一个head以及和宾语Agree的一个head，首先宾语和第三个head发生Merge，从而发生Agree，然后动词主干进入推导，最后第二个head也进入推导，然后主语进入推导，和第二个head发生Agree）
这个就真的只是记号问题了

TODO：概率建模

## Spellout

Spellout操作是指将句法成分完全语音实现，从而让这一部分不再参与未来的句法操作（比如移位），能够触发Spellout的句子成分称为phase。

# 复合句法操作

Merge：工作空间中已有最大投射$\beta$和非最大投射$\alpha$，$\alpha$可以选择$\beta$，则会发生以下步骤：

1. $\mathrm{Merge}(\alpha, \beta)$（或者相反的顺序）将$\alpha$和$\beta$组装成一个成分$[_{\alpha} \; \alpha \; \beta]$（下标$\alpha$表示head是哪一边的，顺序可以颠倒）；
2. 发生Agree，具体来说这包括：
   1. 从$\alpha$到$\beta$的feature assignment，即对每一个$\alpha$中已经定义了而$\beta$中尚未定义的特征$\mathrm{f}$，$\beta$中每一个head的$\mathrm{f}$值都被设定为和$\alpha$相同（对$\beta$内已经发生Spellout的phase不这么做）；
   2. 从$\beta$到$\alpha$的feature assignment，这里可能有一些争议，就是$\alpha$如果是一个中间投射，那么要不要把$\alpha$中的每一个head的未定义特征都赋值，不过大多数情况下$\alpha$都只是单个head（TODO：复合head怎么办？？）
3. 如果$\beta$会触发Spellout，那么把$\beta$除了边缘（即最外层specifier）以外的内容全部Spellout。

phrasal Move：工作空间中已有工作空间中已有最大投射$\beta$和非最大投射$\alpha$，$\alpha$需要首先选择$\beta$，再选择一个成分$\gamma$，$\gamma$是$\beta$的子树，且为最大投射，则会发生以下步骤：

1.

类似地也可以出现phrasal Copy。

需要注意的是语音上直觉性的“成分”未必真的是句法上的成分，因为语音实现是分phase进行的，例如句法上，我们有

[<sub>CP<sub>1</sub></sub> I think [<sub>CP<sub>2</sub></sub> that he is mad ] ]

但是实际上真的语音实现时CP2首先作为一个phase被实现，然后CP1中除了CP2以外的部分被实现，从而在PF中似乎有

[I think] [that he is mad]

这两种划分层次的方法哪一种是正确的？当然，都是正确的。第一种方法是正确的，因为这同时和成分测试以及语义分析一致；第二种方法是正确的，因为可以观察到这样的句子：

I think, hmm, that he is mad

婴儿在语言习得中可能无意将CP1中除了CP2以外的部分识别为一个句法成分，从而导致“I think”演化为句首发语词。

# PF组件

语音实现又是一个非常复杂的领域。这里保存着许多音系操作，除此以外还有一些句法相关的操作。

如果一个成分特意没有被Spellout，那么它就被“删除”了，所以不需要特意加一个Delete操作。

Chain reduction：决定同一个phase中被复制（通过feature assignment）的特征（它们组成一个chain，其中每一个或者位于最低位置，或者c-command另一个）哪些被spellout哪些不被spellout。
通常只spellout最高的一个，但是也不总是这样，比如如果组成一个chain的是带有affix性质的东西（比如英语中的第三人称单数后缀或者过去时后缀），那么这就会造成所谓“affix lowering”——若最高的一个affix不能附着在任何东西上，那么就spellout次高的，从而看起来就像affix从最高的位置移动到了次高的位置。

需要注意的是，通过Agree+chain spellout的方法实现affix lowering在one feature one head的假设下需要一个略显不自然的假设：我们需要认为v-V内部或者上一级有一个T投射，这个T投射和更高的、和主语有关的那个T投射发生Agree，而这个T首先是语义无解的，其次有可能是依赖于具体语言的，那就和句法制图的理论相矛盾了。
无论如何，我们只有三条路：

- language specific well-formedness conditions, 比如说上述Neg以下，v以上的T投射之类，或者也许这个T是Merge在V上面的，whatever；
- post-syntactic operations，比如说affix lowering
- 复杂的remnant movement

原则上remnant movement可以cover全部情况，但是非常不自然；一和二主要还是记号的不同，关键还在于语义无解这件事到底有多糟糕。如果我们认为有些affix lowering和head movement不影响语义，那么实际上还是引入了post syntactic operations
不过，语义无解可能也没有那么糟糕，有些特征，比如说变格法是哪一种，就是语义无解的。
我们不能够指望人类语言真的有那么完美。

*Doing Away with Post-Syntactic Operations: No Need for Lowering or Local Dislocation in a Minimal Morphosyntax. Benjamin Bruening (University of Delaware)*一文认为实际上并不需要任何PF特有的操作，也即，不需要显式的affix lowering之类的运算。
可以采用一套句法、PF通用的操作——也就是Merge和Agree——配上language specific的参数，就能够解释所有形态现象。（当然，韵律等操作仅限于音系，但是它们和形态也没什么关系）
这样一套方法中为了保证Agree运算能够发生，必须假定不存在phase，但是这很多时候不尽然是正确的。

以下内容来自
Verbal Morphology: Not Head Movement, Not Mirror Theory, Just External Merge. Benjamin Bruening (University of Delaware)
一文。

举例：

kept = [<sub>V</sub> [<sub>V</sub> KEEP ] [<sub>T</sub> [past] ] ]

也即，在一个词进入句子之前，一系列词缀被Merge在它上面。主要的形态操作不是通过head to head movement完成的，而是通过普通的external merge完成的。

顺便提一句：这可能也是所谓affix lowering的来源，即动词词缀和一系列更高的functional head发生Agree，就好像这些functional head移动到了动词上面一样

# 词类

单纯的N实际上可以看成一个属性词，D则是将一个抽象的名词概念转化为一个有指称的概念的功能语类。

# 常用唯象模型

本文采取最简方案的观点，以Merge和Agree为基本操作，并且使用affix lowering和head movement的记号。
这并不代表我们赞成“实际上确实有这两个操作”——例如，在分布式形态学中，这些实际上只是单纯的形态学操作而已，在Nanosyntax中，这可能更多的是一系列phrasal movement导致的语序重排——我们只是使用这两个操作作为唯象的描述。
我们也不去讨论是否真的有货真价实的adjunct，而只在必要的时候讨论“可选论元”、“修饰成分”的分布，换而言之，我们将adjunct也当成一个唯象的概念，即“核心短语以外的某些功能语类的specifier，或者真正的adjunct”。

某种意义上，上一段所说的理论就好像粒子物理中的标准模型——它只是将一些观察到的机制简单的混合在一起，而不试图解释为什么会有这些机制。
然而，它使用的formalism（在物理中是相对论性量子场论，在这里是最简方案）却很可能是更进一步的解释的基础。

# 疑难问题

## 什么是能产的成分？

毫无疑问，句法和音系操作一定是能产的，但是是否存在其它generative的语言构件？请注意音系操作通常都比较“简单”，可能仅限于正则语言。

### 词汇完整性假设

很多语言都存在格、性、数等形态变换。如果我们将词汇看成句法操作的主体，那么

### 有独立的形态学操作吗？

是否真的有一个完全独立于句法的“morphology”？或者说，是否有post syntactic operations?
在这件事上，不同的流派有着不一样的看法。Distributed Morphology认为存在一系列post syntactic operations，而Nanosyntax则可能会使用诸如spellout-driven movement之类的方法，将所谓的post syntactic operations简化为语音实现时的调整，从而消除这些操作。

这两种进路都会遇到一些比较麻烦的问题。就Distributed morphology而言，发生post syntactic operation时，尚未发生Vocabulary Insertion，也即，句法树中的元素都还是抽象的概念，但是抽象的概念不大可能携带形态学特征。
也就是说，post syntactic operation的发生要求句法推导“预览”Vocabulary中存储的形态学特征，这是非常不自然的。

而Nanosyntax的spellout-driven movement之类的方法又会遇到另一种困难：首先，它还是引入了一种“和其它句法移位都不同的移位”，实际上还是引入了额外的、只适用于形态的操作；其次，spellout-driven movement发生后，着陆点似乎没有良定义的label，也许可以认为这是某种adjunct，但是adjunct的概念本身就很可疑。
一些学者会认为，spellout-driven movement发生后的成分没有label，但这种完全靠强行引入假设的进路显然不值得提倡，也和最简方案力求简洁、可解释的宗旨不符合。

## 基本的句法学操作有哪些？

### Adjunction

是否真的有纯粹可选的adjunct？或者，说得更加清晰一些，是否有独立于普通的Merge的句法操作，能够形成adjunct？
这样的操作通常称为Adjoin，或者，用乔姆斯基的说法，Pair Merge。

Adjoin是非常好用的概念，可以轻易地用于解释句子中的可选成分。不过，应该指出，它也有一系列困难。
首先，在Merge以外引入另一个structure building operation是非常可疑的，且这样一个操作的地位也非常奇特：乔姆斯基声称普通的Merge是Set Merge，定义为

Merge(α, β): {α, β} → {α, {α, β}},

但是实际上{α, {α, β}}本身就是pair的一种可能定义，所以实际上并不能将Set Merge和Pair Merge真的区分开来。

其次，adjunct的语义地位也存在一些问题。以事件结构为例，通常地点、位置等信息可能被认为是封装在adjunct中的，但是它们是不同的论元，似乎直觉上应该有不同的functional head引导有关的时间、地点短语，而不是简单的adjoin。
或许更加关键的是，语义系统怎么知道某个成分是adjunct？它为什么不认为这是多出来的论元，而直接让推导crash？
如果我们认为adjunct可以被打上特殊的标记，那么为什么不把adjunct分析成functional head的specifier来实现这一点？那这样还需要adjoin操作吗？

最后，很多历史上认为是adjunct的东西——话题、焦点等——最后都被发现实际上是单独的functional head的specifier，这不能不让人怀疑adjunct这个概念究竟在多大程度上起到了“解释”语法现象的目的：似乎我们只是简单地将我们无法解释的、看起来像是可选的成分说成adjunct，而从来没有分析它们实际上是不是真的是同一类现象。

### Head movement

Chomsky 01 不认为head movement真的是纯粹的句法操作，因为：

1. it never affects interpretation
2. the trigger is questionable
3. head movements are not cyclic - for example they violate the Extension Condition
4. moved heads raise problem about c-commanding relations
5. when successive head movements occur, we get a more and more complicated head (called "**rolling up**", just like a snow ball rolling up everything it encounters and getting bigger and bigger), which is simply not successive-cyclic at all: we get [<sub>W</sub> W [<sub>X</sub> X Y] ] instead of the successive one [ X [ W Y] ] or something like that.

（真巧，这里面的每一条我都想到过……）

其实还有一个比较麻烦的点。我们知道很多所谓的head实际上是可以split的，但是在phrasal movement下无论某个XP内部怎么split，都不会影响整体的分析；但是head movement实际上非常依赖head的定义。
换句话说head movement不scalable，那么它看起来就会很ad hoc。

替代方案包括：

1. 认为head movement实际上是PF operations，好处在于非常简洁明了，坏处在于需要假定非常丰富的post syntactic operations
2. remnant movement，即将 … H …[ Z (H) Y] … 分析成 … XP … Z‥Y‥ [ (Z) H (Y)] … （操作过后[ (Z) H (Y) ]称为remnant，因为其中大部分的东西都被移走了，只留下一个“残余”，这个残余的结构和head movement导致的滚雪球滚出来的complex head是一样的），好处在于不需要任何额外理论工具，坏处在于没法解释是什么导致了这么伤筋动骨的移位
3. f

这三种替代方案都不是“全局”替代方案，但也许这是理所当然的，因为的确没有什么能够保证“head movement”这个造成了如此多麻烦的东西真的是一个单一的操作。

真正的全局替代方案实际上是sideward movement。不过这个movement过于强大以至于需要限制限制

## 词库是怎么样的一个东西？

### 词项粒度

如果词项非常细粒度，那么feature-driven movement很容易失败，因为没有正确的c-command关系。

## 语序问题

每个XP中，specifier, head, complement的顺序是不是固定的？
管约论中有一个head位置参数，可以是head first, head final等等；但是光靠这个参数没法解释为什么VSO语序这么多。
再者，这个参数也实在过于唯象了；且很多情况下head first和head final是可以共存的，正如汉语展示的那样。
最后，引入head directional参数实际上只是唯象地描写了语言。

有些理论，比如Antisymmetry，会认为所有句法树都是Specifier-Head-Complement的，语序的不同只是移位的结果。
但是Antisymmetry的基本假设LCA现在看来恐怕已经破产了，那么也许真的可以引入head directionality macroparameter。
但这样又有新问题：head directionality显然不是语义有解的，那么如果我们认为句法树只是操纵抽象概念，似乎不应该有head directionality。

## 参数

“原则与参数”中的“参数”到底是什么？一方面，有microparameter，这些可以直接归结到词库的不同；另一方面，有macroparameter，比如说语序、是否允许多式复综、VP shell是不是形成明确的向心结构（又或者所有论元都是adjunct），等等。
macroparamter难以归结到词库的不同上面。
macroparameter本质上是language specific rules。

需要指出的是，虽然“遇到语言不同就引入一个参数”的确非常方便，但这样也许很难称为真正的“解释”。这一方面是由于其唯象本质，一方面是由于传统的principle and parameter语法从未获得预期的效果。我们本来希望，只需要一张简单的参数取值表就可以完整地描述一种语言的语法，但实际上，我们得到的是过多的参数，每一个参数都经不起实证的考验——不同的pro-drop语言展现出不同的行为，等等。

此外，引入“syntax proper中可变的参数”是一个非常不minimalist的行为。如果乔姆斯基是正确的，那么狭义上的句法能力——也就是将抽象特征构建为句法树的能力——单纯来自几个基因突变，难以想象这里面有多少可以调节的东西。

总之，最好能够寻找一种方式，用microparamter解释macroparamter。后者是词库变化+普遍的认知能力的限制（比如说movement最好向左以便parsing）共同决定的，因此粗一分析似乎有一组不多的parameter可以完全解释各种语言现象，但是仔细一看其实并非如此。

通常，有这么几种办法做到这一点：

- the grounded approach, 即认为language specific rules存在，但存在于the third factor中，比如说parsing efficiency。由于可以用不同的方式达到parsing efficiency，这些rules可以有也可以没有，这就引入了参数。（举个例子：FOFC principle在汉语中可能不适用（汉语中的“的”多半是一个complementizer，它却是head final的））由于这种approach认为language specific rules还是认知局限性的一部分，它仍然是一个UG approach。这种方法比较麻烦的是没法解释为什么这些rule确确实实可以有也可以没有，因为完全可以认为parser也是固化在基因里面的。
- the emergentist approach, 认为parameter的本质是语言学习过程和third factor的互动，比如说婴儿倾向于保守地设置language specific features，那么自然会倾向于全部head initial或者全部head final；
- the reductionist approach，认为parameter根本就和competence无关，完完全全是performance的产物。
