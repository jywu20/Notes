\documentclass{article}

\usepackage{geometry}
\usepackage{titling}
\usepackage{titlesec}
\usepackage{paralist}
\usepackage{float}
\usepackage{footnote}
\usepackage{marginnote}
%\usepackage{enumerate}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{gb4e}
\noautomath
\usepackage{bbm}
\usepackage{soul}
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage[ruled, vlined, linesnumbered, noend]{algorithm2e}
\usepackage{xr-hyper}
\usepackage[colorlinks]{hyperref} % linkcolor=black, anchorcolor=black, citecolor=black, filecolor=black
\usepackage[most]{tcolorbox}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[figuresright]{rotating}
\usepackage{acro}
\usepackage[round]{natbib} 
\usepackage{nameref,zref-xr}
\zxrsetup{toltxlabel}
\zexternaldocument*[cgel-]{../English/cambridge}[cambridge.pdf]
\zexternaldocument*[chinese-]{../Chinese/main}[main.pdf]
\zexternaldocument*[latin-]{../Latin/latin-notes}[latin-notes.pdf]
\zexternaldocument*[alignment-]{../alignment/alignment}[alignment.pdf]
\zexternaldocument*[exercise1-]{../Exercise/2021-3}[2021-3.pdf]
\usepackage{prettyref}

\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}

\DeclareMathOperator{\timeorder}{\mathcal{T}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\legpoly}{P}
\DeclareMathOperator{\primevalue}{P}
\DeclareMathOperator{\sgn}{sgn}
\newcommand*{\ii}{\mathrm{i}}
\newcommand*{\ee}{\mathrm{e}}
\newcommand*{\const}{\mathrm{const}}
\newcommand*{\suchthat}{\quad \text{s.t.} \quad}
\newcommand*{\argmin}{\arg\min}
\newcommand*{\argmax}{\arg\max}
\newcommand*{\normalorder}[1]{: #1 :}
\newcommand*{\pair}[1]{\langle #1 \rangle}
\newcommand*{\fd}[1]{\mathcal{D} #1}

\newcommand*{\citesec}[1]{\S~{#1}}
\newcommand*{\citechap}[1]{chap.~{#1}}
\newcommand*{\citefig}[1]{Fig.~{#1}}
\newcommand*{\citetable}[1]{Table~{#1}}
\newcommand*{\citefootnote}[1]{footnote~{#1}}

\newrefformat{sec}{\citesec{\ref{#1}}}
\newrefformat{fig}{\citefig{\ref{#1}}}
\newrefformat{tbl}{\citetable{\ref{#1}}}
\newrefformat{chap}{\citechap{\ref{#1}}}
\newrefformat{infobox}{Box~\ref{#1}}
\newrefformat{fn}{\citefootnote{\ref{#1}}}

\usetikzlibrary{arrows,shapes,positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\tikzstyle arrowstyle=[scale=1]
\tikzstyle directed=[postaction={decorate,decoration={markings,
    mark=at position .5 with {\arrow[arrowstyle]{stealth}}}}]
\tikzstyle ray=[directed, thick]
\tikzstyle dot=[anchor=base,fill,circle,inner sep=1pt]


\tcbuselibrary{skins, breakable, theorems}

\newtcbtheorem[number within=section]{infobox}{Box}%
  {colback=blue!5,colframe=blue!65,fonttitle=\bfseries, breakable}{infobox}

\newcommand*{\concept}[1]{\textbf{#1}}
\newcommand*{\term}[1]{\emph{#1}}
\newcommand*{\corpus}[1]{\emph{#1}}

\newcommand*{\vP}{\textit{v}P}

\DeclareAcronym{blt}{short = BLT, long = Basic Linguistic Theory}
\DeclareAcronym{cgel}{short = CGEL, long = The Cambridge Grammar of the English Language}
\DeclareAcronym{dm}{short = DM, long = Distributed Morphology}
\DeclareAcronym{tag}{long = Tree-adjoining grammar, short = TAG}
\DeclareAcronym{sfp}{long = sentence final particle, short = SFP}
\DeclareAcronym{vp}{long = verb phrase, short = VP}
\DeclareAcronym{np}{long = noun phrase, short = NP}
\DeclareAcronym{adjp}{long = adjective phrase, short = AdjP}
\DeclareAcronym{advp}{long = adverb phrase, short = AdvP}
\DeclareAcronym{pp}{long = preposition phrase, short = PP}
\DeclareAcronym{cls}{long = classifier, short = CLS}
\DeclareAcronym{dist}{long = distal, short = DIST}
\DeclareAcronym{prox}{long = proximate, short = PROX}
\DeclareAcronym{dem}{long = demonstrative, short = DEM}
\DeclareAcronym{dur}{long = durative, short = DUR}
\DeclareAcronym{neg}{long = negative, short = NEG}
\DeclareAcronym{tam}{long = {Tense, Aspect, Mood}, short = TAM}
\DeclareAcronym{tame}{long = {Tense, Aspect, Mood, Evidentiality}, short = TAME}
\DeclareAcronym{pie}{long = Proto-Indo-European, short = PIE}

% Disable unsupported commands in bookmark titles 
\pdfstringdefDisableCommands{%
  \def\\{}%
  \def\texttt#1{<#1>}%
  \def\mathbb#1{#1}%
}
\pdfstringdefDisableCommands{\def\eqref#1{(\ref{#1})}}

\makeatletter
\pdfstringdefDisableCommands{\let\HyPsd@CatcodeWarning\@gobble}
\makeatother

\newcommand{\cgel}{\href{../English/cambridge.pdf}{my notes about CGEL}}
\newcommand{\chinese}{\href{../Chinese/main.pdf}{my notes about Chinese syntax}}
\newcommand{\latin}{\href{../Latin/latin-notes.pdf}{my notes about Latin}}
\newcommand{\alignment}{\href{../alignment/alignment.pdf}{my notes about alignment}}
\newcommand{\exerciseone}{\href{../Exercise/2021-3.pdf}{this exercise}}

\newcommand{\ala}{Ã  la}

\title{Glossing of descriptive terms, and how to read a grammar}
\author{Jinyuan Wu}

\begin{document}

\maketitle

\section{Theoretical orientation}\label{sec:theory}

The contemporary generative syntax is usually in a lexical-decomposition manner:
that is, sub-word and even sub-morpheme features are the basic units of morphosyntactic operations.
The features are fed into Merge to construct a binary tree with possible multi-domains
(or a binary tree with chains recording copying or Internal Merge),
and then the tree is linearized and post-syntactic operations are applied 
so features are assembled together to form words.
This approach is not appropriate for language documentation,
the latter requiring a more surface-oriented approach.

There have already been several relatively stable descriptive frameworks.
Modern descriptive grammars of underdocumented languages 
are usually carried out within the framework of \ac{blt},
which is theorized in \citet{dixon2009basic1,dixon2010basic2,dixon2012basic3},
and, according to Dixon, deviates striking from the bond-to-fail generative approach.
The \ac{blt} approach assumes no fine-grained constituency hierarchy,
represents dependency relations not by constituency structure,
and views constituent order as mostly driven by pragmatic reasons.
In a word, \ac{blt} is the lay version of functional syntax \ala{} Simon Dik.

On the other hand, already well-known languages are often described in the framework proposed in 
\ac{cgel} \citep{cgel}.
This framework is also taken in \citet{abeille2021grande,huang2016reference},
and its varieties are used in \citet{demonte1999gramatica1,munoz2000gramatica2,bosque1999gramatica3}.
The \ac{cgel} approach is more informed by generative syntax:
it maintains a largely binary-branching analysis,
and dependency relations are still highly bounded to the surface-oriented constituency tree,
though certain dependency relations that involve movements that are hard to find by looking at the surface form 
require special treatment:
and thus the subject in a clause is recognized as a complement of the verb,
but since it is outside the \ac{vp} and the A-movement to SpecTP is not recognizable
in a surface-oriented,
a new syntactic function label \term{external complement} 
-- essentially a way to represent a dependency relation --
is invented to cover the relation between the subject and the verb.
In a word, the \ac{cgel} approach
is the surface-oriented version of the mutual consensus of Minimalism (and GB) and HPSG.

Though the \ac{blt} approach, and the contemporary generative approach, or the Minimalist one,
differ in several important aspects,
the two frameworks roughly describe the same grammatical complexity class:
I will show this in the rest of this note. 
For abstract discussion, see \citechap{\ref{chinese-chap:theory}} in \chinese. 
The take-home message is
\ac{cgel} may be viewed as the surface-oriented dual theory of the constituency structure of Minimalism,
while \ac{blt} may be viewed as the surface-oriented dual theory of the dependency-based formalism of Minimalism.
The relation between the three is visualized in \prettyref{fig:three-formalism}.

In the literature, the constituency-based approach is frequently called the \emph{structuralist} one,
while the dependency-based approach is frequent called the \emph{functionalist} one.
The latter does not necessarily look like more theoretical `functionalist' approaches,
like the Systematic Functional Grammar.
We see both extremes are not suitable for surface-oriented analysis:
the surface-oriented constituent tree is not enough
and additional function labels like \term{subject} and \term{internal complement}
are required,
while the surface-oriented dependency tree 
cannot reveal what commonly attributed to constituency relations,
like extraction properties.
The \ac{cgel} approach is closer to the so-called structuralist approach,\footnote{
    Actually, there is no wide gap between the old-fashioned structuralist approach 
    and the modern \ac{cgel} approach:
    if we look closer to structuralist grammars in the age of Bloomfield,
    e.g. \citet{chao1965grammar},
    we will still find primary function labels like \term{subject} and \term{predicate}.
    The main differences include function labels are sometimes mixed with category labels i.e. form labels,
    for example in terms like \term{verb-object construction},
    and argumentation in support of function labels (see \prettyref{sec:why-argumentation-function-label})
    is often in lieu.
    But using category labels in place of function labels sometimes is acceptable 
    (\prettyref{sec:form-based-function-name}),
    and argumentation may be omitted in the grammar (\prettyref{sec:argumentation-amount}),
    so the differences are merely about writing styles rather than theoretical divergence.
}
and the \ac{blt} approach is closer to the so-called functionalist approach.
We know there is no substantial divergence between the two.
Indeed, people often say 
``modern typology is based on functionalist syntax''
and ``descriptive grammars used in typology are strongly influenced by structuralism \ala{} Bloomfield''
at the same time,
and as we see, both claims are correct.

Note that it is possible for a grammar about well-known languages to be carried out in term of \ac{blt}.
Examples include \cite{batchelor2010reference,batchelor2011reference}.
This is possibly because these languages fit in the framework of traditional grammar well,
and since \ac{blt} may be regarded as ``traditional grammar informed by theories'',
that certain grammars of well-documented languages are \ac{blt}-like is expected.

\begin{infobox}{\ac{blt} in the generative community}{blt-generative-people}
    Indeed, contrary to the prevalent idea in the so-called functional-typological community,
    there \emph{are} generative linguists participating in language documentation and description,
    though in the generative community, 
    the \ac{blt} approach is usually said to be simply \emph{descriptive},
    in contrast with \emph{theoretical} works, i.e. generative works.
    Here is a list of some linguists participating in 
    both descriptive and theoretical enterprises (as they call them)
    and their descriptive works:
    \begin{itemize}
        \item David Adger: \citet{adger1997vso,adger2006dialect,harbour2012information}.
        \item Chris Collins: \citet{collins2014plural,miller2007sounds}, 
        as well as videos with subtitles that can be found with a Google search.
        \item Daniel Harbour: \citet{watkins2010linguistic}, and his collaboration with David Adger.
        \item Roberta D'Alessandro: \citet{andriani2022documenting,frasson2021subject}.
    \end{itemize}
    There is no qualitative boundary between their ``descriptive'' and ``theoretical'' works:
    the descriptive part reveal grammatical categories, dependency relations,
    and constraints on constituent order demonstrating functional domains,
    and all these things are put together in the theoretical i.e. generative part.
    Their workflow differs from with functional-typologists only in 
    how they deal with the output of the \ac{blt} part:
    the generative approach shows the construction in question is possible 
    in the sense that it can be derived with processes observed before,
    while the typological approach measures how probable it is 
    by comparing with other languages.
    These two approaches are in fact complementary and not contradictory.
\end{infobox}

\begin{figure}
    \centering
    \input{line-box/three-formalisms.tex}
    \caption{The generative formalism and two surface-oriented formalisms used in language description.
    The hierarchy information of the Minimalist formalism lost when deriving the surface-oriented formalisms 
    is remended by grammatical functions 
    like \term{indirect complement} and \term{function fusion} in the \ac{cgel} formalism,
    and by grammatical dependency relations like ``slot 1 is the syntactic topic''
    and ``the dependency relation between the lexical head and the F1 slot is coded by the F1 marker'' 
    in the \ac{blt} formalism.}
    \label{fig:three-formalism}
\end{figure}

Beside the discrepancy between the \ac{blt} and the \ac{cgel} approaches,
there are still further divergences within the \ac{blt} approach.
So here I list some dimensions of divergence:
\begin{itemize}
    \item Is the theory purely lexicalist, 
    or are there syntactic templates?%
    \footnote{
        Sometimes the term \term{lexicalist} means the syntax works on words 
        and not sub-word units.
        This is not the meaning intended here. 
        The meaning intended here by \term{lexicalist} is 
        ``all grammatical rules can be reduced to how to use certain lexicon entries (lexical or functional)'',
        which may be words or morphemes or features.
        In other words, a lexicalist theory has no or few ``global'' phrase structure rules,
        as opposed to early generative grammars.
        This usage of the term \term{lexicalist} is attested in \citet{matchin2020cortical}. 
    }\label{fn:lexicalist-1}
    Though in a quick glance, it seems the lexicalist approach agrees with the Minimalist syntax 
    while the templatic approach agrees with the constructionism,
    things are not that simple:
    remember, a Minimalist syntax runs on features which are not directly visible,
    and words and morphemes are just quirky reflections of them.
    The corresponding surface-oriented version of a Minimalist syntax with lots of features 
    that are used to guide the syntactic derivation (e.g. the EPP feature), then,
    inevitably contains syntactic templates that are hard to place under any lexicon entry.
    The Cinque hierarchy of clause structure, for example, contains tons of invisible functional heads,
    and once we ``integrate out'' these functional heads,
    the resulting grammar has a clause template.
    The linguist has to consider whether to introduce 
    a chapter named ``the structure of noun phrases''
    or a chapter named ``the clausal structure''.

    \item How is morphology dealt?
    This parameter has strong association with the previous parameter, 
    since there is no clear distinction between a morpheme and a word.
    In morphology the lexicalist extreme is the Item-and-Arrangement approach,
    while the templatic extreme is the Word-and-Paradigm approach.
    The Item-and-Process approach is somehow in the middle, 
    maybe in a position closer to the former and further from the latter. 
    What brings in more complexity in morphology is 
    there are post-syntactic operations:
    even when the features do spellout into morphemes,
    the Distributed Morphology-style post-syntactic operations 
    blur the correspondence between features and morphemes,
    and hence the idea that words are built up by morphemes 
    does not lead to any constraints on the form of the word,
    raising doubts about whether in a surface-oriented analysis,
    morphemes are of any theoretical significance at all \citep{anderson2017words}.
    The linguist needs to pick up a specific way to show how words are built up.

    \item How are grammatical relations (in other words, dependency relations) introduced? 
    Together with morphemes that bear them, or words, or constituents, or with separate chapters and sections?
    This parameter has certain correlation with the top-down/bottom-up parameter,
    because in a top-down analysis,
    the grammatical functions of constituents in a larger construction 
    are obviously introduced before what fill the constituent slots are discussed.
    On the other hand, 
    a bottom-up grammar tends to introduce grammatical relations when discussing the smallest unit that bear them,
    for example talking about the case marking of various complements in the noun morphology chapter.

    \item What is the relation between a phrase and words contained in it?
    What is the head? What are the complements? What are the modifiers?
    In Minimalist syntax, all functional categories serve as heads,
    but lexical categories are never heads.
    This may appear strange but has underlying consistency 
    (see \citesec{\ref{chinese-sec:headedness}} in \chinese).
    This approach, however, is not acceptable for a surface-oriented grammar,
    and here another concept -- what determines the ``overall'' property of a constituent -- 
    is accepted as the standard to decide what is the head. 
    Thus a \term{n}P and a DP are all headed by the central noun in the surface-oriented analysis,
    because both of them are built surrounding the core noun stem,
    and since the core noun stem is phonetically realized as the central noun -- a lexical word --
    the latter is recognized as the head.
    Disagreements then arise when whether a word is functional or lexical is not that certain.
    Should the preposition be considered as a head? 
    The preposition in a peripheral argument may be seen as the marker of a syntactic case system 
    (so in the generative analysis, we have PP and CaseP),
    and under this analysis, the preposition is not a head.
    But in many languages like English, 
    the preposition category has certain predicative properties,
    making it appear like a lexical category, 
    and then it seems a \ac{np} with a preposition is no longer a \ac{np} -- 
    it is a \ac{pp} headed by the preposition.
    
    \item Are there fine-grained constituency structures, or are there just \acl{np}s and clauses?
    Some grammars, like the \ac{cgel}, 
    posits an anatomy of \ac{np}s with the following functional domains:
    head noun -- nominal -- minimal \ac{np} with a determiner -- external modifiers.
    Others just list possible \ac{np} dependents or clausal dependents,
    without discussing which is closer to the head. 
    If the latter approach is taken,
    the linguist has to introduce effects due to the relative position of constituents in another way,
    like ``the O argument in ergative languages is more topic-like''.
    The main reason to take the latter approach -- which is the approach advocated in \ac{blt} --
    is only \ac{np}s and clauses have complete semantic significance.
    See \ac{blt} \citesec{1.11}, (33) and (34):
    Dixon does not like the binary-branching (Minimalist) approach (33),
    because it does not illustrate the fact that the function words are different from lexical ones. 
    But this is more a problem of terminology:
    the term \term{phrase} in \ac{blt} corresponds to a maximal domain like DP or CP in generative syntax,
    while a generative \term{phrase} -- like \term{v}P or AdvMannerP -- 
    corresponds to a grammatical construction in \ac{blt}.

    \item Whether to adopt a clear distinction between syntax and morphology.%
    \footnote{
        This parameter involves the term \term{lexicalist} in another sense (compare \prettyref{fn:lexicalist-1}).
        If there is a clear distinction between syntax and morphology,
        i.e. there is a stable notion of \term{word},
        then the theory is \term{lexicalist}.
    }
    From a Distributed Morphology perspective,
    the only distinction between what is traditionally regarded as syntax 
    and what is traditionally regarded as morphology 
    is that the latter involves more post-syntactic operations.
    Once these operations are undone,
    \ac{cgel} and \ac{blt} analysis for syntax is applicable to the morphemes
    (or grammatical categories in the Word-and-Paradigm approach):
    the lexical stem of a word may be regarded as with no definite category,
    and hence lexical category labels are in essence function labels (\prettyref{fig:noun-function}).
    
    \item How is constituent order (often called \term{word order}) introduced?
    Is there a separate chapter devoted to constituent order?
    Constituent order can be understood as a manifestation of constituent hierarchy,
    while in more functionalist approaches, 
    it is understood as a method parallel to morphological marking that 
    marks the constituent positions in a larger construction.
    Note that the second claim does not go against the first one:
    certain features, e.g. EPP, 
    are indeed reflected by the surface constituent order in generative syntax.
    Languages may also have macroparameters directing how to linearize generative syntactic trees,
    which does not involve features (which are syntactic objects) 
    and are rules on the interface between PF and the syntax proper.
    Indeed, there are linguists claiming that constituent order is merely morphology 
    and should not be taken too seriously when discussing the syntax proper.%
    \footnote{
        In \ac{blt}, Dixon says constituency order is a way 
        to mark constituents' function label and is of secondary interest.
        He contrasts this with the approach taken by ``formalists'',
        who allegedly want to use an English-informed framework to catch all things 
        of a largely unknown language.
        The point here is Dixon's approach \emph{is} in fact 
        the approach taken by formalists in the real world. 
    }
    Certain mechanisms that do not involve features (e.g. Antisymmetry)
    cannot be translated transparently back into the second approach, though,
    but they can be framed in the second approach as 
    ``the human language faculty just rejects certain constituent orders anyway''.%
    \footnote{
        One controversy here is the generative feature-driven constituent order often involves movement,
        while functionalists accept constituent order variations ``as they are''.
        This controversy is false, because for many generative linguists, 
        movements can be unmarked, and what movement means is simply 
        dual syntactic function of a constituent 
        or the imperfect relation between constituent order and dependency relations
        (e.g. cross-serial dependencies).
    }

    \item Top-down (i.e. structuralist partition-based), 
    or bottom-up (i.e. based on the usage of smaller units)? 
    In PSGs there is a clear correspondence between the two, 
    but for actual language documentation things are often complicated:
    a top-down grammar is awkward to write 
    because the author has to enumerate all possible configurations in a construction 
    to fully characterize it
    (``a clause is either coordination of clauses or a subject-predicate construction''
    -- oh no, supplementation and pre-nucleus constructions are forgotten),
    while a bottom-up grammar is awkward to read 
    because the reader has to infer all possible configurations in a construction 
    (``the verb is the prototypical content of the predicate slot''
    -- any other possibilities? Nobody knows).
    This parameter is in principle orthogonal to the parameter about how constituent order is introduced,
    but a bottom-up grammar without a chapter (or several chapters) devoted to constituent order 
    will be extremely hard to read:
    the reader may find a sentence like ``the object follows the verb'' in the chapter about verbs.
    Alright, can an adverb intervenes between the verb and the object? No answer.

    \item Whether a set of canonical constructions is established.
    Viewing non-canonical constructions as transformed from canonical ones (or by adjunction, etc.) 
    is a powerful descriptive tool,
    but it is often the case that certain constructions 
    that are uncontroversially deemed non-canonical do not have a canonical counterpart.
    This is one of the reason transformational rules are finally abandoned in generative syntax.
    Transformational rules (and adjunction, etc.) are still handy when doing description, though:
    no one wants to read a grammar that treats positive clauses and negative clause in the same way.

    \item If two constructions are of the same type,
    but one is much simpler than the other,
    whether to place the simpler version together with the less simple version,
    or to place the simpler construction with other relatively simple constructions.
    Examples include whether the serial verb construction should be discussed 
    together with the simple verb-complement construction 
    -- the alternative arrangement is to place the verb-complement construction 
    together with alignment and argument indexation in a chapter named, say, ``simple clauses'' -- 
    and whether the relative clause construction 
    should be introduced in the chapter about \ac{np} dependents,
    or in the chapter about clause types,
    or in a separate chapter.
    This chapter is related to the parameter about canonical constructions:
    \ac{np}s without relative clauses may be viewed as canonical \ac{np}s,
    and non-canonical \ac{np}s containing relative clauses 
    can be obtained by substituting attributive modifiers with relative clauses.

    \item How corpus examples are given -- fully bracketed and labeled, or represented as is?
    In the first case, 
    an example is a demonstration of the grammatical \term{rules} generalized in the grammar,
    while in the second case,
    an example is just there as a piece of observation.
    In practice, no reference grammar is truly generative 
    in the sense of listing all permitted forms and excluding ungrammatical forms.
    Thus, examples are never presented purely as examples of grammatical rules.
    But whether they are ``deeply'' or ``shallowly'' annotated still observes lots of variations.
    This parameter has relation with the top-down or bottom-up parameter,
    but the relation is not absolute:
    in general, the more bottom-up a grammar is, the more observation-based it is, 
    i.e. the examples are provided as is without much tree diagrams or bracketing expressions.
    But it is of course possible to have a top-down grammar 
    which does not make much generalization about grammatical rules 
    that generate grammatical utterances 
    and exclude ungrammatical ones.
    Indeed, this is exact the case for the structuralist Immediate Constituent Analysis:
    partition of corpus data is made,
    but there is no generalization about what is permitted and what is not.
    The correlation between the bottom-up narrative order and the observation-based approach 
    is likely due to it is the easiest way 
    to document something about a language without mistakes.
    
    \item Another parameter about how to give examples: as a bracketed constituent in a full utterance,
    or taken out of the context?
    Structuralist works, like \citet{chao1965grammar}, tend to employ the latter approach,
    while modern grammars are the opposite.
    Despite being concise and easy to formalize,
    the latter approach 
\end{itemize}

\begin{figure}
    \centering
    \input{line-box/noun-function.tex}
    \caption{The lexical category \term{noun} as a function label:
    in a generative grammar, a nP (nominalizer phrase) is placed in a functional projection FP,
    and a noun stem is placed as the complement of the nominalizer.
    After coarse-graining the generative syntax tree 
    and using function labels to replace functional heads,
    the F functional head in the FP projection is replaced by the F label on the right side.
    Then, by the same logic, 
    the nominalizer should be coarse-grained into a ``Noun-stem'' function label,
    and the nP projection is coarse-grained into the ``Noun'' category label.
    In practice, the orange box on the right side
    is contracted into one single word, i.e. the noun,
    and thus we can see the category label of a word also has a hidden function label inside.}
    \label{fig:noun-function}
\end{figure}

Both \ac{blt} and \ac{cgel} 
have strong tendencies in the values of some (though not all) parameters listed above.
The parameters that are largely fixed by the overall descriptive framework 
include whether fine-grained constituency hierarchies appear,
how is constituent order introduced,
and the definition of \term{head}.
It is of course possible to mix the \ac{blt} and the \ac{cgel} approaches:
\citet{Friesen2017}, for example, despite being a largely \ac{blt}-like grammar,
uses the term \term{verb phrase} in the way of \ac{cgel},
while the parts about \ac{np}s are typically \ac{blt}-like.
On the other hand, \citet{munoz2000gramatica2}, 
despite it employment of \ac{cgel}-like terms,
does not emphasizes on tree diagrams and 
constituency structure, nor its possible constraints on the constituent order,
and is much more \ac{blt}-like than the \ac{cgel} itself or the great French grammar \citep{abeille2021grande}.
Another example of mixing of the \ac{cgel} approach and the \ac{blt} approach
can be found in \ac{cgel} itself:
ditransitive clauses can be analyzed in Minimalism,
but the analysis inevitably involves lots of movements
to make the dependency relations correct,
so \ac{cgel} just gives up binary branching in exchange of a much clearer surface-oriented analysis,
where the syntactic properties of the direct and indirect objects 
(two grammatical functions not found in monotransitive clauses)
are manually stipulated.
This is just how \ac{blt} works when the constituency relations are complicated.

Choosing between the approaches in \ac{cgel} and \ac{blt} 
and the rest of the parameters are to be decided by the grammarian,
and some best practices are introduced in \prettyref{sec:best-practice}.
In principle, the above parameters are free to choose.
In practice, they have to be fine-tuned or otherwise the grammar will be hard to read.

\section{(Not so) best practices of grammar writing}\label{sec:best-practice}

\subsection{What influences the organization of the grammar}\label{sec:grammar-factors}

Parameters in \prettyref{sec:theory} have to be fine-tuned according to the following factors:
\begin{itemize}
    \item The properties of the language. 
    If a linguist unfortunately decides to write a Chinese grammar 
    in a bottom-up manner
    in which a grammatical relation is introduced in the chapter about the lexical category about its head,
    a reader will soon be stuck in questions like 
    what are the possible linear order between object(s), directional complement, and aspectual markers.
    On the other hand, it is okay -- and even desirable to write a Latin grammar in this way,
    because Latin is much more free-order than Chinese 
    and grammatical relations are mostly marked by morphology.
    \item Whether the language is already well-known. 
    In \prettyref{sec:theory} we have already seen that
    comprehensive grammars of well-known European languages are usually \ac{cgel}-like,
    while newly documented languages are usually captured by \ac{blt}-like grammars.
    This is again expected, because in-depth partition of constituents 
    is never the priority when describing a newly encountered language.
\end{itemize}

% TODO: a table about famous grammars

It should be noticed that what is in the final version of the grammar 
has no absolute relation to what is done to reveal the grammar.
A chapter in a grammar about verb morphology 
may list all attested \ac{tame} categories marked on the verb,
and then show morphemes corresponding to these categories,
while the workflow to investigate the paradigm 
is likely to be carried out in reverse order:
grammarians often first record all attested forms of a verb,
and then try to find the morphemes,
and finally link them to \ac{tame} categories.
The morphemes attested, actually, 
are the strongest evidences for or against certain analyses of 
what \ac{tame} categories are coded.
This explains why many authors love the bottom-up approach.
But again, they inevitably need some top-down partition:
at least they have to be able to identify \ac{np}s and clauses!
These scaffolds are removed once the building of the grammar is finished.
They may still leave traces in the finished work:
This is the topic I am going to discuss in \prettyref{sec:argumentation}.

\subsection{Organization of chapters}\label{sec:chapter-organization}

\subsubsection{The introduction chapters}\label{sec:introduction-chapter}

In modern grammars, the first chapter of a grammar is usually about 
its genetic affiliation, its population, 
geographic and cultural information,
typological significance, and similar topics.
Grammars focusing on raw fieldwork data 
may also list available texts and corpora.

It is common -- but not necessary, counterexamples including \citet{Grimm2021} 
-- to have a grammar sketch chapter then.
This brings some (though not all, for reasons below) benefits of the top-down approach
to a grammar that is not carried out strictly in the top-down manner,
and thus makes it easier both for readers to understand the language 
and for the author to describe what he or she knows.
In many grammars, though, the grammar sketch chapter is just 
the zipped version of the following chapters organized in a bottom-up manner
instead of something like \prettyref{sec:clause-top-down} and \prettyref{sec:np-top-down},
and readers in a hurry 
-- possibly readers who want to know what syntactic categories are marked in the clause,
or readers reading a grammar to give a construction a generative analysis  --
are unlikely to find what they want in the chapter without reading it from the beginning to the end.
They should not expect what they need can be found in a single section.

Take \citet{jacques2021grammar} as an example.
The morphosyntactic part of \citechap{2} is thoroughly bottom-up,
with attested lexical categories being introduced first,
then nominal morphology,
then verbal morphology,
then argument indexation and flagging,
and finally constituent order and subordination.
Readers need to dive deep into \citesec{2.4.3.2} to see what \ac{tame} categories are marked in the clause
-- since they are marked on the verb complex 
and the author writes the grammar in a bottom-up way,
introducing grammatical categories in the sections about smallest constructions 
that manifest them,
a comprehensive list of \ac{tame} categories can only be found 
in a small corner in the section about verbal morphology.

There is one particular benefit of having a grammar sketch chapter.
A grammar needs argumentation to support a function label.
When the author says ``the subject is available for more extractions than internal complements'',
the readers are expected to know where these movements happen,
which, unfortunately,
are usually introduced after the concept \term{subject} appears,
in the chapter about information structure.
Having a grammar sketch means non-canonical constructions 
can be used to support a particular analysis of a canonical construction.

The following chapter(s), if any, is usually about phonetics and phonology,
and possibly about the preferred writing system.
This chapter may be omitted for languages already well known, like English.
There is no phonology chapter in \ac{cgel}, for example.
This note is not about phonology, so I will just skip this part.
It should be noted that readers interested in a largely unknown language 
would better know something about the phonology,
even if their primary interest is about morphosyntax,
because phonological rules can blur otherwise clear constructions.

What happens next observes more variations.
In the following I discuss frequent strategies to arrange chapters about morphosyntax.
These strategies are not mutually contradictory:
good grammars mix them to meet the need in \prettyref{sec:grammar-factors}.

\subsubsection{Chapter organization: item and arrangement}\label{sec:item-and-arrangement-grammar}

One way to carry out a grammar 

The chapters about arrangement of items 
may be bottom-up or top-down.
Structuralist grammars \ala{} Bloomfield tend to choose the latter order.

\subsubsection{Chapter organization: \ac{np}s and clauses}\label{sec:np-clause-chapter}

Some grammars can be divided into two parts:
one is about \ac{np}s,
the other clauses.
Since \ac{blt} tolerates using names of lexical categories in place of the naming of their prototypical functions,
sometimes we say these grammars are divided into 
a part about nouns and a part about verbs.

\subsubsection{Chapter organization: from canonical constructions to non-canonical ones}

\subsection{Terminology}

\subsubsection{Form-based grammatical relation terms}\label{sec:form-based-function-name}

Some people tend to use the lexical or phrasal category 
that prototypically fills a grammatical function slot 
as the name of that grammatical function.
Here is a list of relevant terms:
\begin{itemize}
    \item \term{Adverbial}, which is actually peripheral argument (\prettyref{infobox:clausal-dependent}).
    \item \term{Serial verb construction}, which is actually serial predicator construction.
    \item \term{Verb complex}, which is actually predicate (in the \ac{blt} sense) 
    or the predicate minus complements (in the \ac{cgel} sense).
\end{itemize}

\ac{blt}-oriented grammars tend to use more form-based terms about function,
possibly because these grammars are usually results of language documentation projects,
in which linguists do not have much time to decide which is the best analysis of a phenomenon,
and a large corpus with at least some annotation 
-- despite possible quirks -- 
is better than a few grammaticality judgement tests.

Confusing terms about form and function in practice does \emph{not} cause much problems
-- see \citesec{\ref{latin-sec:form-function}} in \latin.

\subsection{Argumentation}\label{sec:argumentation}

\subsubsection{The amount and position of linguistic argumentation}\label{sec:argumentation-amount}

This section is about how to make linguistic analysis and argumentation,
and how it is shown in a grammar.
A grammar without argumentation will be confusing:
readers will ask ``why does the author say there is clear distinction between nouns and verbs'',
and the answer can only be found by comparing the distribution of nouns and verbs by themselves.
To a certain extent, a grammar without enough argumentation is not truly finished.
It is just an \emph{legend} about the ``shape'' of a language,
and all the reader need to do is to accept the story as it is and never ask why.

A grammar with too much argumentation will be messy.
Consider a grammar in which there are discussions both 
on how to do a top-down partition of a clause 
and on how to assemble verbs and \ac{np}s into a clause. % TODO: ç»ä¸ä¸ªè¿ç§æ¹æ³ååºæ¥çè¯­æ³çreference
It is often the case that the reader has to switch between the two parts frequently 
because a grammar point is introduced in one 
but a highly relevant grammar point can only be found in the other.

Even when the amount of argumentation is appropriate,
where to place them is still quite an art.
Argumentation for distinguishing ditransitive verbs and monotransitive verb with an extended argument,
for example, may be carried out in a chapter mainly about canonical clauses,
but it inevitably involves something about non-canonical constructions 
(passivization, extraction, etc.)
which are still largely unknown for readers reading the grammar from the beginning to the end.
Adding a grammar sketch chapter may ease the problem (\prettyref{sec:introduction-chapter}).

Sometimes argumentation is is mixed with description.
It is possible to talk about what argument can be passivized 
in the chapter about clausal dependents in canonical clauses,
and then shun the topic in the actual chapter about passivization.
This makes the grammar concise but also harder to read,
because readers interested in passivization 
will then have to switching between the two chapters.

\subsubsection{Constituency partition}

In \ac{blt}, the constituency relations are relatively simple,
because there are only two basic types of constituents: 
\ac{np}s and clauses,
while in the \ac{cgel} approach,
the constituency relations are much more complicated
(see \prettyref{infobox:term-predicate}). 

\subsubsection{Identifying function labels and dependency relations}\label{sec:why-argumentation-function-label}

The importance of function labels and dependency relations 
is exemplified well in \prettyref{sec:complement-type-necessary},
and there is no need to repeat here.


\subsubsection{Distinguishing lexical and phrasal categories}

Lexical and phrasal categories can be classified by their internal makeup as well as 
their external distribution.
Similarly to argumentation about function labels,
if a category label is established,
then certain implicational rules about the category exist in the grammar.
The claim that 
``Latin verbs conjugate, not decline, and they head clauses''
can be equivalently formulated without mentioning \term{verb} as 
``if the inflectional endings of a word attested fit in the so-called conjugation table,
not the declension table,
then it is likely that the word prototypically appears in the predicator position of clauses''.


\section{Top-down partition of the clause structure}\label{sec:clause-top-down}

Even for a largely bottom-up grammar,
top-down analysis is sometimes necessary,
which is discussed at the end of \prettyref{sec:grammar-factors}.
In this section, I discuss how to have .

\subsection{A sketch of the constituency tree}\label{sec:ica-clause}

This section gives a purely form-based analysis of clause structure.
Just like when discussing morphology,
we often first show possible morphological devices 
and then discuss what grammatical categories are marked by these devices,
in this section, I first discuss how to give a constituent analysis of a clause,
and then in other sections about how to interpret the constituency tree obtained.

\subsubsection{A clause is built up by one or more nuclei with certain syntactic processes}\label{sec:nucleus-to-clause}

The top-level partition of a clause is given as the follows:
\begin{exe}
    \ex\label{ex:clause-def-1} A \concept{clause} is
    \begin{itemize}
        \item the coordination of two clauses (\prettyref{sec:clause-coord}),
        which may involve ellipsis in and/or movement out of the conjuncts, or
        \item a clause with supplementation (\prettyref{sec:clause-supp}), or
        \item a clause without the two.
    \end{itemize}
    \ex\label{ex:clause-def-2} A clause without coordination or supplementation is 
    \begin{itemize}
        \item a clause with pre- or post-nucleus constructions
        (the residue of the nucleus clause undergoing relevant syntactic processes 
        is named the \concept{nucleus}), 
        like the English subject-auxiliary verb inversion or \term{wh}-movement, or 
        \item a nucleus clause (see \eqref{ex:nucleus-def}).
    \end{itemize}
\end{exe}
Note that the distinction between 
coordination and adjunct clause construction (a type of subordination)
may be not so clear for some languages, 
for example Latin (see \latin, \citesec{\ref{latin-sec:subordination-abs}}).
Also, there is no strict application order 
between coordination, supplementation, and pre- and post-nucleus constructions:
in the English question
\corpus{on that particular day -- I mean the day when the unfortunate incident happened -- 
did you pass that site or hear anything usual in that direction},
first a coordination construction is used, 
followed by a subject-auxiliary verb inversion (a pre-nucleus construction)
and then supplementation 
and finally another pre-nucleus construction (topicalization of the time adjunct).
Another remark here is the syntactic processes from nucleus clauses to more complicated ones 
may only work for certain inputs:
in English, for example, the supplementation \corpus{not even \dots} 
is only possible for a clause in negative voice.
A final remark is that finding the boundary of the nucleus 
requires testing the transformational properties of each clausal dependents.
The constituency tree obtained by immediate constituent analysis 
is without labels,
and it is impossible to decide, say, whether a constituent is a topic (a prenucleus construction)
or a subject (a dependent within the nucleus).
This fact leads some Chinese grammarians to abandon the distinction between topic and subject. % TODO: ref
Here is not the best space to have in-depth discussion for the definition of the nucleus.
A working definition is given in \prettyref{sec:nucleus-dependents},
but it involves terms like \term{complement} and \term{adjunct},
which cannot be defined by the label-free constituency tree obtained by clause partition.

\subsubsection{Clausal dependents in the nucleus}\label{sec:nucleus-dependents}

Now it is time to define the nucleus clause:
\begin{exe}
    \ex\label{ex:nucleus-def} A \concept{nucleus clause} is 
    \begin{itemize}
        \item a minimal nucleus clause, or 
        \item a nucleus clause with adjunction.
    \end{itemize}
    \ex\label{ex:minimal-nucleus-def} A \concept{minimal nucleus clause} is a complex of 
    \begin{itemize}
        \item the \concept{predicator}, 
        prototypically a verb but with possible alternatives,
        possibly marked for grammatical categories involved in the clause structure, and 
        \item one or more visible or invisible \concept{complements}, and 
        \item possible function words marking clausal grammatical categories
    \end{itemize}
    or it is a serial verb construction (\prettyref{sec:serial-verb-construction}).
\end{exe} 
Here \concept{adjunction} means adding \concept{adjuncts} into the tree structure, 
in the manner in \ac{tag}.
This is the surface-oriented counterpart of optional projections in Cinque hierarchies.
Adjuncts are contrasted with complements,
the latter being somehow closer to the predicator, 
but not necessarily obligatory.
There are several tests to find whether something is a complement or an adjunct
(see \ac{cgel} \citesec{4.1.2}, for example),
but the distinction is usually quite blurred and language-specific 
(\citesec{\ref{chinese-sec:sub-cat}} in \chinese).
The complement-adjunct distinction is usually hard to test simply by pure constituent analysis,
because an adjunct is not necessarily higher than all complements.
The distinction is not what can be studied here -- 
it has to be delayed to \prettyref{sec:complement-type-necessary}.

The term \term{adjunct} used in this note means clausal modifier.
\term{Adjunct}, in generative syntax, 
means optional non-head components of any projection,
though nowadays, especially in the Syntactic Cartography program, 
it is often assume that there is no adjoin operation beside the usual Merge,
and so-called adjuncts are specifiers of certain optional functional heads,
and hence the term \term{adjunct} loses its structural significance.
Many descriptive grammars, like \citep{quirk2010comprehensive}, 
use the term \term{adverbial} for the term \term{adjunct}.
A third name used for adjuncts are \term{peripheral argument} in \ac{blt}.

The term \term{complement} may sometimes be used to denote specifically \term{complement clauses}. % TODO: ref
In \ac{blt}, the term \term{complement} is usually replaced by \term{core arguments}.
\ac{cgel} insists on a strict form-function distinction 
and hence the term \term{argument} is reserved for semantics.
\ac{blt}, on the other hand, emphasizes on the semantic basis of syntax, 
and so the term \term{argument} is used.
But here comes a subtle difference between \ac{blt}'s standard of clausal dependents and \ac{cgel}'s:
certain constituents, like the direction complement in Mandarin Chinese 
(see \citesec{\ref{chinese-sec:direction-complement}} in \chinese),
are definitely complements under the standard of \ac{cgel},
but are definitely not arguments, 
and hence they are not recognized as clausal complements in \ac{blt}
-- they are thus recognized as a part of the \ac{blt} predicate (see \prettyref{infobox:term-predicate}).

\subsubsection{Pre- and post-nucleus constructions not well defined for free-order languages}\label{sec:free-order-blt}

It should be noted that for languages with a relatively free constituent order,
it is almost impossible to find a neutral order, 
and hence pre-nucleus and post-nucleus constructions 
cannot be well-defined,
let along the fact that some linguists posit so-called in-VP scrambling
and the pronominal argument construction for radical non-configurational languages
where argument NPs are actually adjuncts,
which are by no means pre- or post-nucleus constructions 
but nonetheless induces changes in the constituent order.
In this case, \eqref{ex:clause-def-2} and \eqref{ex:nucleus-def} should be merged together,
and notions like pre- and post-nucleus constructions are to be replaced by 
discussions on the relation between constituent order and semantic and pragmatic information.

\subsubsection{Syntactic topic}

\subsubsection{Classification of clausal dependents}\label{sec:complement-type-necessary}

In the above discussion I intentionally avoid mentioning subject and object
or more generally, any complement and adjunct types,
because as is discussed in the end of \prettyref{sec:nucleus-to-clause}
and in \prettyref{sec:nucleus-dependents},
by staring at the surface form,
it is impossible to define these terms.
The constituent analysis of the surface syntax 
gives us a constituency tree without labels.
In this section, I discuss how to add function labels to the nodes of the tree.
The above discussion -- why the surface-oriented constituency tree is not enough -- 
has a strong flavor of \ac{cgel}.
For \ac{blt}, the importance of function labels is much clearer:
the complexity of the constituency tree is highly limited,
so most of the information has to be conveyed in terms of 
dependency relations, i.e. function labels.

Trivially, the label of a node can be assigned as the category of the node.
Thus we have 
{[$_{\text{S}}$ [\corpus{I}]$_{\text{Pron}}$ [$_{\text{VP}}$ [\corpus{like}]$_{\text{V}}$ [\corpus{fruits}]$_{\text{NP}}$]]}.
But of course \corpus{I} and \corpus{fruits} occupy different syntactic positions:
from folk grammar we know the first is the subject while the second is the object.
Can this distinction be seen from their structural positions?
It is true that in generative syntax,
complement positions can be distinguished purely in structural terms 
(SpecTP, Spec\vP, etc.),
but in the surface-oriented analysis the relevant functional heads are all invisible,
and inevitably there are occasions 
when structural terms are occasionally insufficient to decide the role of a clausal dependent.
A grammarian may want to define the \term{subject} as 
``the most external clausal dependent in immediate constituent analysis'',
and this leads to the ridiculous conclusion that 
in \corpus{quietly, he entered the room}, 
the adverb \corpus{quietly} is the subject.

This example is a vivid example of the importance of \emph{functional} labels in the constituency tree.%
\footnote{
    Here \term{functional} means syntactic function and not pragmatic function.
}
Another illustration can be found in \citefig{\ref{cgel-fig:coarse-grained}} in \cgel:
the information contained in the functional projections in the left tree 
is displayed in the functional labels like \term{predicator}, \term{agent}, \term{patient}, etc.
in the right one.
In the above example of the definition of the subject,
``the most external clausal dependent in the nucleus'' seems to work well.
But \emph{what} is the nucleus?
This question is raised at the end of \prettyref{sec:ica-clause} 
but has never been answered definitely.
One may want to define it in semantic terms:
``a nucleus clause contains all constituents that are necessary to complete the meaning of the verb''.
But isn't \corpus{quietly he entered the room} such a clause?

The conclusion is that in order to find 
complement positions, adjunct positions, the definition of \term{nucleus} 
-- in a word, functional labels -- in a language, 
syntactic tests based on transformational behaviors 
(or to be precise, baed on comparison between regularly related constructions) is needed.
The grammarian should expect lots of cross-linguistic variation of available functional labels,
because they are reflections of the underlying feature structure,
which allows plenty of variations.
In a purported language without any EPP feature, SpecTP may not be not of much significance,
and hence the label \term{subject} 
-- the combination of the syntactic agent i.e. the topmost argument in the argument structure, 
and the obligatory ``topic'' i.e. the topmost argument after TP is finished --
is of little use.
An example of how to find complement types is \citefig{\ref{cgel-fig:english-object}} in \cgel.
By six syntactic standards 
-- constituent order, passivization, preposing, postposing, gap controlling, and predicative adjunct --
five object-like complement types are identified,
and four of them are recognized as objects with one being kicked out of the object family.

\subsubsection{Alignment}\label{sec:alignment}

Recognizing complement types is mostly about syntax.
Semantics is also involved, of course, 
because otherwise it is impossible to decide whether one clause is transformed from another.
But this is not what people already with knowledge on traditional grammar expect.
What do semantic roles of complements and adjuncts 
do in complement type recognizing?
They are important factors in determining complement and adjunct types,
but they are by no means the decisive ones.
Passivization is a well-known counterexample of the uniform matching between semantic roles and complement types.
A locative role may be realized as a complement or an adjunct.
The defective -- yet still largely regular -- mapping between semantic roles and complement or adjunct types 
is therefore worth separate treatment.
This is what known as \concept{alignment}.

There are usually much fewer complement types than semantic roles.
The detailed semantic classification of verbs -- and their complements -- is quite messy. 
\citetable{3.1} in \ac{blt} lists the semantic classification of the most frequent verbs in English.
There are 16 semantic roles mentioned, 
and if the linguist just lists his/her testing results of the syntactic behavior of each of them,
the reader will be driven mad!
A well-organized description of the alignment of a language therefore is based on 
the mapping relation between complement and adjunct roles and coarse-grained semantic roles.
A priori no one knows how to coarse-grain semantic roles 
so that the resulting ``macro-roles'' make sense both syntactically and semantically.
After periods of investigation, several macro-roles have already been identified.
The most important three are S, A, and O\footnote{
    Many denote it as P, to be consistent with the A argument (agentive/patientive). 
    In this note I use O to be consistent with Dixon.
}.
S is the only argument in the intransitive clause.
A and O are the more agentive argument and the more patientive argument in the transitive clause, 
respectively.
Other argument labels include E 
(whatever that occurs together in addition to a SV or AVO construction
-- see \citesec{\ref{cgel-sec:blt-e-argument}} in \cgel),
G (the goal-like argument in a ditransitive construction with a meaning of ``transferring''
-- see \citesec{\ref{cgel-sec:direct-indirect}} in \cgel),
and T (the theme-like argument).

If somehow S and A are realized by the same complement type 
-- which is commonly named the \term{subject} --
then the language is \concept{nominative-accusative} or simply \concept{accusative}.
If, however, S and O are realized by the same complement type,
then the language is \concept{ergative-absolutive} or simply \concept{ergative}.
As is shown by \citefig{\ref{cgel-fig:english-object}} in \cgel,
to say two complement types are essentially the one 
has a vague meaning:
the monotransitive object and the T argument in the English V-G-T construction 
(\term{sth.} in \corpus{give sb. sth.})
are both analyzed by \ac{cgel} as implements of the direct object,
but they differ in passivization.
The same is for identification between S and A or O.
A language can be accusative under certain standards while ergative under others.
For details, see \citesec{\ref{alignment-sec:sao-marking}} in \alignment.

There is some drifting in the meaning of these argument labels.
Essentially being functional labels just like \term{subject} and \term{nucleus},
these labels are syntactic concepts in some contexts,
including ``passivization means turning the O argument into S and suppress the A argument into E''
and ``the A argument always binds%
\footnote{
    The term in \ac{blt} \citechap{13}, Appendix 1 is \term{control},
    but \term{control} has its specific meaning in a class of verbs 
    that take an object and an infinitive complement clauses.
}
the O argument, which means O can be filled by a reflexive pronoun bound by A,
while reflexive pronouns do not occur in the A position''.
The notion of S argument is also an inherently syntactic one,
because S arguments in so-called unaccusative verbs are closer to O, not A.
When the S, A, O, etc. concepts are syntactic,
we may say ``the agent argument is marked as A'',
or ``the goal argument is marked as E'',
and complement or adjunct labels are just coarse-grained S, A, O, etc. labels
(e.g. the \term{subject} label is the clustering of A and S), 
because the S, A, O etc. labels denotes complement types with semantic specification.

On the other hand, there are contexts in which the S, A, O, etc. notations 
are defined on an almost solely semantic footing:
the English G argument shows rather split behaviors in the V-G-T and V-T-pG constructions,
as is shown in \citefig{\ref{cgel-fig:english-object}} in \cgel.
Now we do not say ``the agent argument is marked as A'',
but ``the G argument is marked as the indirect object in the V-G-T construction''.
Note that in this case there is no simple relation between complement types and the argument labels:
for example, in \citefig{\ref{cgel-fig:ditransitive-gt}} in \cgel,
The O argument and some instances of the T argument are marked as the monotransitive object,
while the rest of the instances of the T argument are marked as the ditransitive direct object,
so there is no surjection relation from argument labels to complement types,
but nor is there surjection relation from complement types to argument labels.

The requirements of uniform syntactic behaviors, 
of uniform semantic behaviors
and of conciseness
often cannot be satisfied together,
giving rise to the above phenomenon.

The above discussion on clausal dependents can be summarized as the follows:
\begin{infobox}{Nucluse clause and clausal dependents}{clausal-dependent}
    Clauses can be constructed from nucleus clauses via pre- and post-nucleus constructions 
    and/or coordination and supplementation.
    The nucleus clause contains clausal dependents, a lexical verb, and auxiliaries.
    In the \ac{cgel} approach, the clausal dependents include complements and adjuncts.
    In the \ac{blt} approach, the clausal dependents include core arguments and peripheral arguments.

    This note keeps all the four terms: \term{complement}, \term{adjunct}, 
    \term{core argument}, \term{peripheral argument}.
    Though roughly complements correspond to core arguments,
    and adjuncts correspond to peripheral arguments,
    certain complements -- like the non-argument complements in Chinese -- 
    are certainly not arguments, and may be included as parts of the \ac{blt} predicate 
    (see \prettyref{infobox:term-predicate}).
    Adjuncts are also referred to as \term{adverbials} in some grammars.

    The complement-adjunct distinction and subclassification of the two types of clause dependents 
    rely on syntactic analysis and argumentation 
    based on extraction properties like preposing,
    valency changing properties like passivization,
    and marking of constituent order and morphology.
    Without syntactic argumentation, 
    it is impossible to distinguish adjunct, complement, and topic (a pre-nucleus construction) 
    or to find subtypes within clausal dependents,
    for immediate constituent analysis is unable to provide relevant information.
    
    There is typically uniform but nontrivial mapping from semantic roles to complement and adjunct types.
    Coarse-grained semantic roles based on similar syntactic and semantic properties 
    include S, A, O, G, T, etc.,
    and the alignment of a language decides 
    the relation between these argument labels
    and complement and adjunct types.
    The exact meaning of the argument labels varies.
    Sometimes these argument labels are just clausal complements subclassified 
    according to the semantics,
    and sometimes they are mostly semantic.
\end{infobox}

\subsection{The inner structure of the verb-complement construction}

\subsubsection{The subject-predicate analysis of the verb-complement construction for syntactically accusative languages}

\eqref{ex:minimal-nucleus-def} is a flat-tree analysis, 
but there are several evidences suggesting 
a fine-grained hierarchy is useful even for surface-oriented analysis.
For accusative languages, 
the S and A arguments are and hence are identified as the \term{subject}, 
and we have the following facts:
\begin{itemize}
    \item The subject is much easier to be extracted out of the nucleus,
    which can be explained by the theory that 
    it is somehow higher and movement operations are localized.
    \item The quantifiers of the subject and internal complements, 
    explicit or implicit, 
    demonstrate a stable scope hierarchy:
    the scope of the subject quantifier is always larger.
    When talking about a charity organization,
    one may say \corpus{every woman helps three boys}.
    Here, the subject is bounded by $\forall$ and the object is bounded by `there exists three \dots',
    and $\forall$ $>$ \corpus{three} and *\corpus{three} $>$ $\forall$:
    the meaning of the sentence aforementioned is 
    `for each woman, there are three boys that she helps,
    but I do not know who they are,
    and possibly the boys Sarah helps are not the boys Lily helps'.
    After a seemingly trivial passivization, 
    we get \corpus{three boys are helped by every woman},
    which means 
    `there are three boys -- I don't know who, but anyway there are three -- 
    who are helped by every woman in our organization',
    and we have \corpus{three} $>$ $\forall$ and *$\forall$ $>$ \corpus{three}.
    If we assume the semantics is related to the syntactic structure at least partially,
    then this is a piece of evidence that the subject is higher in the syntactic tree,
    no matter what its semantic role is. 
    \item If the subject is indefinite, then it is by default bounded by $\forall$, TODO: really???
    
    Some notes about \ac{blt} \citechap{13}, Appendix 1: 
    TODO: S argument and A argument are by default bounded by $\forall$,
    while O is bounded by $\exists$ -- is this cross-linguistically correct?
    This also explains why verb-object incorporation is frequent:
    \corpus{a cat kills some animals} = \corpus{a cat kills}.
    It seems the only argument -- be it peripheral or core -- 
    that is by default bounded by $\forall$ is S in intransitive clauses and A in transitive clauses
    (which may be seen as a double check ).
    What's the counterpart in syntactic ergative languages?
    \item Verb-argument incorporation, nominalization, etc. 
    (for example compare \corpus{solve problem} and \corpus{problem solving}) 
    usually happens between the verb and the internal complement(s),
    not between the verb and the subject.%
    \footnote{
        Grammaticalization of a span is also in principle possible,
        so incorporation between the verb and the subject 
        may still rarely occur.
        But note that operation on span is usually seen for functional hierarchies,
        in which what are spellout as a single word 
        are highly lightweight functional heads, 
        not more substantial lexical categories.
    }
    \item If there is something looking like reflexive pronouns, 
    then it usually follows the Government and Binding scheme,
    and using this as a test,
    the subject is always predicted to occupy a higher position.
\end{itemize}
The list can go on and on, and hence it is useful to divide the nucleus clause into 
the subject and the predicate:
\begin{exe}
    \ex\label{ex:subject-predicate} A nucleus clause is made up by an \concept{external complement}, often named the \concept{subject},
    and a predicate.
    \ex\label{ex:predicate-as-vp} A \concept{predicate} is either a predicate without adjunction, which may be 
    \begin{itemize}
        \item a predicator-complement construction, or 
        \item a serial verb construction, 
    \end{itemize} 
    or a predicate after adjunction,
    or a predicate after syntactic processes marking clausal grammatical categories like 
    negation, modality, etc.
    \ex\label{ex:predicator-complement} A predicator-complement construction consists of 
    a predicator (which is the head of the predicate and the clause) 
    and its \concept{internal complements}.
\end{exe}

The above rules replace \eqref{ex:nucleus-def} and \eqref{ex:minimal-nucleus-def}.
These are the rules used in \ac{cgel}, and actually also the Chinese school grammar
(see \citesec{\ref{chinese-sec:clause-constituent-order-overview}} in \chinese).
\ac{cgel} does not acknowledge the role of verb complex,
which is in principle correct, 
because English is already highly analytic and rigid-order,
and most information about dependency relations can be reconstructed 
from the surface-oriented constituency analysis.
Therefore, the term \term{predicate} is used as in traditional grammar:
it means the nucleus minus the subject, 
and its status as a constituent summarizes the above listed facts.

\subsubsection{The flat-tree analysis of the verb-complement construction}

It should be noted the above concept of \term{predicate} does not always correspond to 
an uncontroversially constituent in the surface structure:
in a VSO language, for example, the predicate is discontinuous.
This urges some to accept a flat-tree approach to describe the nucleus predicate.

To see another motivation of the flat-tree approach in surface-oriented description, consider the following facts.
There are some controversies arising from the ``what is the head'' parameter in \prettyref{sec:theory}.
Some verbs are auxiliary verbs.
In the clause \corpus{I should do this},
what is the predicator?
Here we are in the same delimma as the one concerning ``preposition phrase''.
An analysis in which the predicator is \corpus{should} will face the criticism 
that function words are never heads in a surface-oriented analysis,
or otherwise, in order to be self-consistent,
its bound morpheme counterparts should also be regarded as heads,
which falls back to the generative functional head analysis.

The above two motivations urge us to take 
the analysis in which the main verb \corpus{do} is the predicator.
This approach usually occurs with the flat-tree approach,
or otherwise \corpus{should} is analyzed as a clausal dependent similar to the determiner in a \ac{np},
which is acceptable in the structuralist analysis of Chinese non-argument complements 
(see \citechap{\ref{chinese-chap:non-argument-complement}} in \chinese)
but is not prevalent outside the Chinese grammar community.
The nucleus minus arguments (core and peripheral) is named \term{verb phrase} in \ac{blt},
while in \ac{cgel} the term \term{verb phrase} means the verb plus its internal complements,
which is the form of the predicate.
The \ac{blt} \term{verb phrase} is the hierarchy \emph{span} 
(as in \term{span spellout}, or the head slot in the \ac{blt} part in \prettyref{fig:three-formalism}) 
of the \ac{cgel} VP shell.
To avoid conflict, 
the term \term{verb complex} may be used to denote the verb phrase in the \ac{blt} sense
\citep{hockett1948potawatomi,Friesen2017,Wilbur2014}.
Now since there is no need to do fine grained partition of the nucleus,
the term \term{predicate} can be assigned to something else 
and the commonly accepted practice is to use it to denote the verb complex.
In this way, \eqref{ex:subject-predicate}, \eqref{ex:predicate-as-vp}, and \eqref{ex:predicator-complement}
are replaced by the following:
\begin{exe}
    \ex A nucleus clause is made by a predicate
    (with a different meaning with the \term{predicate} in \eqref{ex:predicate-as-vp}) 
    and core and peripheral arguments.
    Rearrangement of constituent order may be necessary.
    \ex A \concept{predicate} may be a simple one or a serial verb construction 
    (\prettyref{sec:serial-verb-construction}).
    \ex A simple predicate consists of a head (prototypically a lexical verb) and  
    possible grammatical category markers (including auxiliary verbs). 
\end{exe}

This approach is not without doubt: the analysis that the main verb \corpus{do} is the main verb 
also faces a problem of non-consistency:
the boundary between auxiliary verbs and lexical catenative verbs % TODO: ref
is somehow vague in some languages, 
and in this case, in somewhere in the grammaticalization process the head status 
suddenly flip from verb to another.
Also, the problem of discontinuous constituent (the verb complex)
still exists, which can also be seen from \prettyref{fig:three-formalism}.
But this is the practice accepted in \ac{blt} and most of grammars sticks to this paradigm,
so I introduce it here.

\subsubsection{Switching between the two}

\begin{figure}
    \centering
    \input{line-box/simple-clause-cgel-blt.tex}
    \caption{Comparison between a \ac{blt} analysis and a \ac{cgel} analysis}
    \label{fig:simple-clause-compare}
\end{figure}

Finally I discuss how to translate between the two approaches.
There are only two key points:
in \ac{blt}, most heavy lifting jobs are done by dependency relations within a large, non-branchable constituent, 
not constituency relations,
and what is a constituent depends heavily on semantics.
Consider \prettyref{fig:simple-clause-compare},
which illustrates the divergences between \ac{cgel} and \ac{blt} 
over a simple predicator-complement construction.
Here is a comparison between the two analyses:
\begin{itemize}
    \item The argument positions in both approaches are labeled by explicit functional labels.
    The necessity has been argued in \prettyref{sec:complement-type-necessary}:
    in Minimalism, the argument positions can be decided purely in terms of the structure:
    the subject is SpecTP, and object is SpecTransP, etc.
    But in the surface-oriented formalisms 
    information contained in the constituent structure
    is not enough to tell us the role of arguments,
    and hence arguments are explicitly labeled via notions like 
    ``subject:'', ``object:'', ``subject slot'' and ``object slot''.
    \item The binding relation between the subject and the object 
    is realized in \ac{blt} as ``the subject tends to somehow control the object cross-linguistically''.
    This reflects the dependency relation-based nature of \ac{blt}:
    the fact that the subject is somehow ``higher'' than the object 
    is not reflected in the constituent structure, 
    but rather by a dependency relation placed in the clause template.
    \item The fact that \corpus{have completed} is a span in the TP projection 
    is reflected in the \ac{cgel} analysis also by constituency structure,
    but \corpus{have completed} is recognized as a constituent in the \ac{blt} approach.
    This reflects the semantic-informed constituent standard in \ac{blt}:
    as can be found in the \ac{cgel} part of \prettyref{fig:simple-clause-compare},
    in the clause structure we have a \ac{vp} \corpus{have completed the task},
    but it is neither a clause nor a \ac{np},
    so it is not a constituent in \ac{blt},
    but once the \ac{np} \corpus{the task} is stripped away,
    the purely verbal skeleton \corpus{have completed} -- which is a span and colored as blue --
    is of semantic significance: 
    it describes the event going on, 
    and the internal gap for the object as well as the external complement (i.e. subject) gap 
    are interpreted as valency (here the dependency-based nature of \ac{blt} is also reflected).
    So \corpus{have completed}, a span in \ac{cgel}, gets recognized a constituent in \ac{blt} 
    and it fills the predicate slot.
    This is illustrated in \prettyref{fig:simple-clause-compare}.
\end{itemize}

\begin{figure}
    \centering
    \input{line-box/predicate-blt.tex}
    \caption{The structure of a simplest \ac{blt} predicate}
    \label{fig:blt-predicate-simple}
\end{figure}

Similarly, the generative constituency relation-based illustration 
of serial verb construction in e.g. \citet{chen2016mandarin}
is replaced the dependency relation-based syntactic process to insert several verbs into a single predicate 
and alternate the dependency relation between the verbs and the arguments in \ac{blt}.
\prettyref{fig:serial-verb-construction-1} is an illustration of 
the correspondence between the analysis in \citet{chen2016mandarin} and a \ac{blt} analysis.
The phenomenon discussed in the diagram is the direction complement construction
or direction compounding construction 
(see \citesec{\ref{chinese-sec:direction-complement}} in \chinese),
in which a word indicating spacial movement (picked from a closed category) 
-- which is the direction complement or direction compound -- 
is merged together with a TransP,
and the object -- in this case \corpus{t\={a}ng} `soup' -- in the TransP
also becomes a complement of the direction complement,
and by head movement, the direction complement is attached to the main verb 
-- \corpus{s\`{o}ng} `send' here -- 
and hence a compounding verb \corpus{s\`{o}ng la\'{i}} is formed,
which precedes the object.
Now we try to translate the above derivational process to a \ac{blt} account:
\begin{itemize}
    \item The fact that \corpus{t\={a}ng} is both 
    the complement of the main verb \corpus{s\`{o}ng}
    and the direction complement \corpus{la\'{i}} 
    (by appearing in two specifier positions)
    is reflected by the two dependency relations 
    on the right side.
    \item The fact that \corpus{s\`{o}ng la\'{i}} is the span spellout of the verbal projections minus the object 
    is reflected by putting the two words into the predicate slot.
    The constituent order information is reflected in a flat-tree way.
\end{itemize}
Here I intentionally skip the \ac{cgel} approach 
because the complexity of serial verb construction
is already comparable with the functional projection 
that gives rise to the \corpus{have been being done} hierarchy
\citep{ramchand2014deriving},
and the surface-oriented \ac{cgel} analysis will not be substantially different 
from the \ac{blt} analysis shown in \prettyref{fig:serial-verb-construction-1}.

\begin{figure}
    \centering
    \input{line-box/serial-verb-example-1.tex}
    \caption{An example of serial verb construction: 
    \corpus{send come soup} is the literal translation of the Chinese \corpus{s\`{o}ng la\'{i} t\={a}ng},
    which means `send soup here (= send soup and make it come here)'.
    Based on (74) in \citet{chen2016mandarin},
    which adjustment to make it compatible with Distributed Morphology.}
    \label{fig:serial-verb-construction-1}
\end{figure}

There are adjustable parameters in both the \ac{cgel} approach and the \ac{blt} approach.
The aforementioned ``what is the head'' question 
and ``whether discontinuous constituents are recognized as constituents''
are obviously parameters.
For \ac{blt}, since auxiliary verbs are not considered as heads in clauses containing them,
the question what are lexical verbs arises,
since in many languages, 
there are catenative verbs that seem to already undergone some degree of grammaticalization,
but are not typically auxiliary verbs nonetheless.
This question decides what is the head in the \ac{blt} analysis.
Similarly, certain adverbs are actually lexical markers of \ac{tame} categories,
and hence whether they should be considered as a part of the \ac{blt} predicate like auxiliary verbs
is a question without a universal answer.
The \ac{cgel} approach is unable to analyze VSO languages 
with the subject-predicate division without movements,
but similarly, the \ac{blt} approach suffers the problem of discontinuous predicate
in cases like V2 languages.

The fine structure in a nucleus which is a verb-complement construction can therefore be summarized as follows:
\begin{infobox}{The fine structure of the nucleus and the terminology about \term{predicate}}{term-predicate}
    There are fine structures within the nucleus,
    but they are caught with radically different approaches in \ac{blt} and \ac{cgel}.
    The comparison between the two is given in \prettyref{fig:simple-clause-compare}.

    In \ac{cgel}, if \term{subject} can be defined for a nucleus clause,  
    the nucleus clause is divided into the subject and the \term{predicate},
    and the predicate can be then be further divided 
    by successively stripping off the most external dependent.
    In a predicator-complement construction,
    after all adjuncts and complements are separated, 
    the remaining of the predicate is the \term{predicator},
    the head of the predicate, the nucleus clause, and the whole clause,
    which is prototypically filled by a verb.
    The phrasal category of the predicate is typically called the \term{verb phrase}.
    It is also possible to have a serial verb construction,
    where there is more than one predicator-like syntactic item.
    The \ac{cgel} constituent analysis is the immediate constituent analysis 
    plus dependent types annotated by argumentation mentioned in \prettyref{infobox:clausal-dependent}.
    The constituency tree is the coarse-grained result 
    of the constituency relations in the corresponding generative syntax,
    which plays a role in deciding binding government and binding between arguments, 
    which verb to move in subject-auxiliary inversion, etc.

    In flat-tree approach grammars, i.e. \ac{blt}, 
    the only uncontroversial constituent types are \ac{np}s and clauses,
    and all constituents within a larger constituent are placed on the same plane.
    What are not arguments in a nucleus clause 
    are all placed into the \term{predicate},
    which corresponds to a span in the verb phrase in \ac{cgel}. 
    The predicate in \ac{blt} is also said to be a \term{verb phrase},
    or \term{verb complex} to avoid confusion with the \ac{cgel} meaning of the term.
    What is conveyed by constituency relations in the \ac{cgel} approach
    is alternatively articulated by dependency relations.

    Certain constituents acceptable as complements in \ac{cgel}, 
    like the direction complement in Chinese, 
    tend to be placed in the predicate position in \ac{blt} (see \prettyref{infobox:clausal-dependent}),
    because these non-argument complements are somehow comparable with auxiliary verbs.

    It can be seen that for surface-oriented sketching of previously unknown languages,
    the \ac{blt} approach is more flexible,
    since there is no need to do surface-oriented binary-branching in-depth constituent analysis,
    there is no subject-predicate division which is dubious in ergative languages, % TODO: whether this is true
    and surface constituent order is not taken to be directly reflecting the dependency structure.
    However, since the predicate is the surface correspondence of the verbal skeleton span,
    it can be expected that the predicate may be more frequently realized discontinuously
    compared with arguments which themselves are also constituents in generative syntax,
    and some may want to reduce the content of the predicate to ensure continuousness,
    while others may not.
    When there are auxiliary verbs,
    the \ac{cgel} approach naturally recognizes 
    the most external auxiliary verb as the head of the whole clause,
    the then the second most external auxiliary verb is deemed
    the head of the VP dependent of the top auxiliary verb, etc., 
    while in \ac{blt}, the general tendency is to deem 
    the head of the predicate as the main verb, and not the most external auxiliary verb.
    Both \ac{cgel} and \ac{blt} have the problem of noncontinuous constituents,
    and whether to split them is an adjustable parameter.
    These parameters are left to the grammarian to decide.
\end{infobox}


\subsection{Serial verb construction}\label{sec:serial-verb-construction}

When in the \ac{blt} predicate there are more than one verb that acts as 
I have already introduced an example of serial verb construction 
in the discussion about \prettyref{fig:serial-verb-construction-1}
how serial verb constructions are described in terms of 
both the generative approach and the \ac{blt} approach,
and that since the derivation of serial verb constructions 
is already of the same complexity level of how auxiliary verbs are constructed according to \ac{tame} features,
the \ac{cgel} approach to serial verb constructions is largely similar to the \ac{blt} one,
and the verbs appearing in a serial verb construction 
may be regarded as morphological components of a complex predicator.

Here I review the typology of serial verb constructions. % TODO

\subsection{Grammatical systems and categories in the clause}

\subsubsection{Arguments: flagging, indexation, alignment}

\subsubsection{\ac{tame} categories}

\ac{tame} categories, or \term{non-spatial settings} (the name used by Dixon),
are prototypical TP categories.

\subsubsection{Finiteness}

In generative syntax, finiteness is in a low position in the CP domain.
It determines  

\subsubsection{Information packaging}

Information packaging, i.e. syntactic marking of the information structure,
involves several strategies.
The simplest ones are topicalization and 

\subsubsection{Clause types}

\subsection{Workflow}

Though most modern grammars are bottom-up (just like their traditional antecedents),
top-down constituency and dependency analysis of clauses is still important
and is likely to be the first step in understanding the language.
A toy example can be found in \citesec{\ref{exercise1-sec:clause-partition}} in \exerciseone.

\section{Top-down partition of the \acl{np}}\label{sec:np-top-down}

\section{Lexical categories}

\subsection{The noun category}

Despite some morphological and syntactic varieties, 
all languages have nouns. 
A noun is typically a head of a phrase filling an argument slot (see \prettyref{infobox:clausal-dependent})
-- this distribution feature is the \emph{prototype} role of nouns, 
and also an important criteria to recognize a noun class.

\subsubsection{Possible distribution}



\subsubsection{Semantic classification}

\subsection{The verb category}

\subsubsection{What is recorded in the dictionary entry of a verb}

Here is a list of what needs to be described in the dictionary entry of a verb
if the dictionary is expected to provide full information instructing 
how to build a sentence from words:
\begin{itemize}
    \item Grammatical categories marked on the verb and 
\end{itemize}

\subsubsection{Semantic classification}

\subsection{Distinguishing nouns and verbs}

\subsection{The adjective category (or categories)}

\section{Morphology}

\subsection{The notion of \term{word} and the coverage of morphology}\label{sec:what-is-word}

\subsubsection{Words as black boxes in syntax}

Morphology, roughly speaking, 
is the study of the inner structure of words.
But what are words, anyway?
It should first be noted that the definition of phonological words 
does not necessarily agree with the definition of grammatical words.
\ac{blt} spends a whole chapter (\citechap{10}) to discuss 
criteria to decide the two.
And what is a grammatical word is also not without controversy.
Morphosyntactic phenomena used to decide 
whether a syntactic unit is or is not a grammatical word 
can be summarized as certain versions of the Lexicalist Integrity Hypothesis,
i.e. when it comes to the syntax,
the speaker does not really feel the inner makeup of the unit.%
\footnote{
    A stronger claim is the speaker does not feel the inner makeup of words at all.
    It is true that native speakers' intuitive partition of words 
    is often problematic when examined closer.
    The representation of Japanese verbal conjugation in the Kana system
    -- in which stem alternation is invoked --
    is accepted by most native speakers,
    but a closer look reveals that concatenative morphology 
    is enough to account for the observed conjugation paradigm,
    though the stem may end up with a consonant and  
    thus native Japanese speakers do not find the concatenative analysis.
    But ignorance of minimal analyzable units happens equally in syntax: 
    native speakers often forget to mention important function words 
    when they are invited to introduce a construction of their language.
    When a native Chinese speaker is invited to talk about the disposal construction,
    the optional function word \corpus{geÇ} in clauses like 
    \corpus{t\={a} b\v{a} w\v{o} geÇ ch\={u}ma\`{i} le} %ä»ææç»åºåäº
    is often left untouched. % TODO: ref
}
Today, we know the hypothesis is not really necessary.
Extraction constraints exist on all levels of morphosyntax,
which can be explained without mentioning \term{word}.
The distinction between word and phrase is likely to be 
a secondary concept,
derived from more fundamental laws of morphosyntax
\citep{bruening2018lexicalist}.
And the hypothesis is also not one hundred percent correct.
What is uncontroversially syntax, like coordination, 
can definitely see how a word is formed,
as in \corpus{pre- and post-revolutionary France}.

\subsubsection{Words as minimal utterance}

Another way to distinguish words is not based on morphosyntactic tests done by linguists,
but the native speakers' intuition in discourses:
a word may be defined a smallest unit that appears in metalinguistic discourses,
or maybe it is defined as a smallest unit of ordinary utterance.
Here the definition of \term{word} relies more on the condition of being somehow minimal,
rather than on being a unit that is felt by the speaker in actual discourses,
because many -- actually most -- morphosyntactic constituencies that are clearly there 
(which can be tested using standard constituency tests)
are never cited in metalinguistic discourse,
and they are of all sizes.
What are universally realized by the speaker in intuitive language use 
seem to be limited to \ac{np}s and clauses in syntax,
the two being the only constituency types recognized in \ac{blt}
or in other words, two maximal functional domains in generative syntax,
namely the DP domain and the CP domain (see \prettyref{sec:theory}).
In this perspective, the relation between morphemes and words 
is similar to the relation between clausal dependents and heads and clauses.
Consider the theory on categorizers in Distributed Morphology, for example.
A categorizer phrase,
presumably a phase, 
adds category labels to the stem,
without definite categories, which resides in the lowest position of the whole functional projection,
in the same way CP and TP grammatical relations are added to a \vP.
What singles words out is they are the \emph{smallest} units that can be cited.

This view, unfortunately, also suffers from several issues.
The most important problem is speakers sometimes do cite affixes.
Consider the following dialogue:
\corpus{-- You mean `pre-revolutionary', or `post-revolutionary'? 
-- `Pre-'.}
The second problem is ``appearing independently in discourse''
is not self-consistent.
In English, single-verb utterances are rare,
but verbs can be cited metalinguistically.
The third problem is the status of function words as words is challenged in this view:
the article \corpus{the}, 
for example, never appears on its own as an utterance,
but since it appears as a dependent in the \ac{np},
it has to be a word, not a morpheme.
Dixon seems to be content with this,
since in \ac{blt} \citesec{1.11} he says there is no need to treat 
``function words'' in the same way as lexical ones:
the former are grammatical markers that can be enumerated in the grammar
and it is even appreciated if they are not listed in dictionary.

\subsubsection{Words as units with conventionalized meanings}\label{sec:word-meaning}

The inner structure of words are subject to fossilization.
This gives rise to the so-called criterion of wordhood 
that a word has a single conventionalized meaning,
which cannot be seen by looking at morphemes inside it.
Thus, the structure of syntactic units directly implies its meaning,
while the structure of words,
though analyzable,
is of primarily historical and etymological interest.

But fossilization exists, of course, in syntax,
examples including idiomatic verb-preposition constructions 
and verb-particle constructions,
and periphrastic conjugations as well.
The distinction between fossilization of word structure and fossilization of syntax 
is better regarded as quantitative, rather than qualitative.
Fossilization means storing a whole structure in the lexicon,
which of course works better for smaller constructions i.e. so-called morphological trees,
rather than large syntactic ones.

As is often said, morphological rules are usually less productive than syntactic ones,
and among morphological rules,
derivation is less productive than inflection in general.
The reason of the first observation is already said above:
smaller structures are easier to routinize 
and hence relevant rules are easier to be eroded.
This also explains why derivation is usually less productive than inflection:
since inflection interacts with the syntactic context of a word,
it can be expected that functional projections involved in inflection 
are somehow more external,
and thus the stem together with derivational heads 
constitute a smaller constituent than 
the stem together with derivation heads and inflectional heads,
so the former is easier to fossilize.
This does not mean there is no fossilization in inflection.
Fossilization in inflection is the same as collapsing of the functional hierarchy involved,
which increases the fusion index of the language.
So fossilization of inflection makes the inflection rules more obscure 
-- but there are inflectional rules, after all,
because the spellout of the inflectional functional projection span 
still needs to be concatenated to the stem.
On the other hand, 
fossilized derivation results in new words,
and the corresponding rules are just gone.

\subsubsection{What morphology is about}

Several conclusions can be drawn from the above discussion.
First, what does the heavy lifting in any definition of wordhood 
is always minimality:
most of the criteria raised apply to what is uncontroversially recognized as syntax as well,
and it is minimality that tells words from phrases.
Second, different criteria usually give conflicting definition of wordhood.
The true meaning of the term \term{word}
will definitely contain some idiosyncrasies 
of the language in question as well as the personal preference of the author of the grammar
(or the cultural tradition, especially the orthography).
The term \term{word} can still be useful as a language-specific descriptive concept,
but the grammar writer has to be explicit about what he or she means by the term.

Considering the chaos in defining \term{word},
expectedly, what is involved in morphology is highly heterogeneous,
much more heterogeneous than the case in syntax.
The following mechanisms involved are the same as ones in syntax:
\begin{itemize}
    \item Constituency tree within the word: 
    functional projections (and thus function labels or grammatical relations in surface-oriented terms) 
    that may appear in categorizer phrases.
    For example, we accept \term{faithful} as a word,
    then the function label of \term{-ful} never appears outside the adjectival categorizer phrase:
    in English phrases it is never possible to simply add a word 
    and term a noun into an adjective meaning ``full of \dots''.
    Function labels within the word may also be the same with 
    the labels in syntax.
    In Chinese, the predicator-object relation is both found in the clause structure and in verb morphology. % TODO: ref
    \item Span spellout without much nontrivial post-syntactic operations: 
    a span of functional projections are spelt out into morphemes
    in a transparent manner.
    Japanese conjugation is a good example of this:
    the conjugation endings may be seen as auxiliary verbs,
    which is reflected in the terminology in the School Grammar tradition.
    This is also seen in syntax:
    the \ac{blt} definition of \term{predicate} (\prettyref{fig:blt-predicate-simple}) is a typical example 
    of how a span is analyzed as a constituent 
    in a surface-oriented theory.
\end{itemize}
As is said above, 
the syntactic (in the sense of Distributed Morphology) part 
of morphology (in the sense of surface-oriented analysis)
has nothing different with the syntax (in the sense of surface-oriented analysis)
in basic structure building mechanisms.
But beside these, languages also have highly localized processes.
The following mechanisms are highly localized and therefore are usually only observed 
in what we call morphology:
\begin{itemize}
    \item Nontrivial spellout: post-syntactic operations like fusion,%
    \footnote{
        Sometimes they are called morphological operations,
        though the latter term is kind of misleading,
        since post-syntactic operations work on features and not morphemes.
        The term \term{morphological operation} suggests 
        a surface-oriented analysis,
        which is dual to Distributed Morphology
        but is not identical to it superficially.
    }
    and spellout based on underspecification.
    Portmanteau is a good example.
    \item Phonological realization may combine two grammatical words into one 
    or split a grammatical word into several phonological words.
    It is even possible for a morpheme of a grammatical word to be 
    attracted by and attached to another grammatical word
    in phonological realization (\ac{blt} \citesec{10.6}). 
    These subtleties are usually not introduced in detail in the name of ``phonology''
    and should be accounted for in chapters about morphology.
\end{itemize}
Of course, nontrivial spellout and phonological rules also appear in syntax (in the surface-oriented meaning):
English auxiliary hierarchy, like \corpus{have been being done},
involves nontrivial span spellout,
while the auxiliary inversion involves head movement,
which may be analyzed as an example of post-syntactic operation.
Prosody drives lots of syntactic phenomena in many languages,
and may even break a word into its parts. % TODO: ref:ä½äºä¸å æ

All processes mentioned above are subject to fossilization.
Fossilization is another source of so-called Lexical Integrity phenomena 
(one source being phasehood of categorizer phrases):
once a word with complex internal structure is fossilized,
its internal structure is of no synchronic significance,
and thus ``morphological rules'' -- to be exact, fossilized diachronic morphological rules --
are irrelevant to ``syntactic rules''.

\subsection{Three models of morphology}

For people unfamiliar with the recent development of morphological theories,
the Item-and-Arrangement model may be the default model.
Its 

\section{Coordination}

\subsection{Clausal coordination}\label{sec:clause-coord}

\subsection{Coordination in \ac{np}s}

\section{Supplementation}\label{sec:clause-supp}

\bibliographystyle{plainnat}
\bibliography{typology,famous-grammars,controversy}

\end{document}