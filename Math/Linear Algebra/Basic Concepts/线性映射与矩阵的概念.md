# 线性映射与矩阵的概念

$\mathcal{L} (V, W)$指的是从$V$到$W$的所有线性映射。设$T \in \mathcal{L}(V, W)$。

定义线性零空间
$$
\mathrm{null} T = \{ \boldsymbol{v} \in V | T \boldsymbol{v} = \boldsymbol{0} \}
$$
它是$V$的子空间。

单射：$\forall \boldsymbol{u}, \boldsymbol{v} \in V, T \boldsymbol{u} = T \boldsymbol{v} \Rightarrow \boldsymbol{u} = \boldsymbol{v}$

值域
$$
\mathrm{range} T = \{T\boldsymbol{v}| \boldsymbol{v} \in V \}
$$

满射指的是值域就是$W$的映射。显然，一个映射是不是满射依赖于我们选择哪个$W$为目标域。接下来都假定$W$为目标域。

$$
\dim V = \dim \mathrm{null} \; T + \dim \mathrm{range} \; T
$$

若$\dim V > \dim W$，则$T$必定不是单射。若$\dim V < \dim W$，则$T$必定不是满射。

## 线性同构
两个向量空间是线性同构的，当且仅当，两者之间有一个可逆线性映射。

线性同构的向量空间中，线性相关和无关、维数、基、线性表示等只和线性性有关的性质都是对应的。

两个有限维向量空间同构，当且仅当，它们的维数相等。有含有不止零向量的交集而线性同构的向量空间相等。

## 逆

一个线性映射是可逆的，当且仅当，它同时是单射也是满射（也即，它是双射）。

若干个映射的复合是可逆的，当且仅当，它们全部都是可逆的。

## 算子
属于$\mathcal{L}(V) = \mathcal{L}(V, V)$的映射称为算子。

如果一个映射是算子，那么下面的几个命题等价：
- 它可逆
- 它是单射
- 它是满射

设$\boldsymbol{e}_1, \ldots, \boldsymbol{e}_n \in V$。$V$的任意两组基可以使用一个可逆的算子相互转化；且一个可逆的算子作用在一组基上可以得到另一组基。事实上，$T$可逆，当且仅当在$\boldsymbol{e}_1, \ldots, \boldsymbol{e}_n$是一组基时，$T\boldsymbol{e}_1, \ldots, T \boldsymbol{e}_n$也是一组基。

$\boldsymbol{e}_1, \ldots, \boldsymbol{e}_n \in V$。算子$T \in \mathcal{L}(V)$可逆，当且仅当，$\boldsymbol{e}_1, \ldots, \boldsymbol{e}_n$线性无关时$T\boldsymbol{e}_1, \ldots, T \boldsymbol{e}_n$也线性无关。

如果$T\boldsymbol{e}_i$以$\boldsymbol{e}_1, \ldots, \boldsymbol{e}_n$为基时和$\boldsymbol{e}_i$对应的那个系数（这总计$n$个数值称为主对角元）对任意$i\in 1 .. n$都不为零，那么$T$一定可逆。

## 矩阵
考虑线性映射$T \in \mathcal{L}(V, W)$，设$\boldsymbol{v}_1, \ldots,  \boldsymbol{v}_n$是$V$的一组基，$\boldsymbol{w}_1, \ldots, \boldsymbol{w}_m$是$W$的一组基。

设
$$
T \boldsymbol{v}_k = a_{1k} \boldsymbol{w}_1 + \ldots + a_{mk} \boldsymbol{w}_m,
$$
则我们定义
$$
\mathcal{M}(
    T, (\boldsymbol{v}_1, \ldots,  \boldsymbol{v}_n), (\boldsymbol{w}_1, \ldots, \boldsymbol{w}_m)
) = \left[
    \begin{matrix}
        a_{11} & \cdots & a_{1n} \\
        \vdots & \ddots & \vdots \\
        a_{m1} & \cdots & a_{mn}
    \end{matrix}
\right]
$$
也就是说，把诸$T\boldsymbol{v}_k$在诸$\boldsymbol{w}$下的表示写成列向量拼起来就是$\mathcal{M}(T, (\boldsymbol{v}_1, \ldots,  \boldsymbol{v}_n), (\boldsymbol{w}_1, \ldots, \boldsymbol{w}_m))$。

因此，$\mathbb{R}^{m\times n}$，也即所有$m$行$n$列的矩阵，同构于$\mathcal{L}(\mathbb{R}^n, \mathbb{R}^m)$。

事实上，可以证明，在给定了两组基之后，矩阵化操作是**可逆的**。

$m$行$n$列的矩阵空间也是一个$mn$维的向量空间。这就意味着，我们实际上可以使用相同的方式处理向量和它们之上的映射。

我们也可以把向量使用矩阵表示出来。若
$$
\boldsymbol{a} = a_1 \boldsymbol{v}_1 + \ldots + a_n \boldsymbol{v}_n,
$$
则
$$
\mathcal{M}(\boldsymbol{a}, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)) = 
\left[
    \begin{matrix}
        a_1 \\
        \vdots \\
        a_n
    \end{matrix}
\right]
$$

*需要注意的是这个操作在无穷维的时候不总是成立的。这也就是量子力学区分矢量和算符的原因，因为此时的算符和矢量不再具有某种同构关系。*

## 矩阵在不同的基下的表示

*定理* 设$(\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p)$是$U$的基，$(\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)$是$V$的基，$(\boldsymbol{w}_1, \ldots, \boldsymbol{w}_m)$是$W$的基，$T \in \mathcal{L}(U, V), S \in \mathcal{L}(V, W)$，$\boldsymbol{x} \in U$，
则$ST \in \mathcal{L}(U, W)$，$T \boldsymbol{x} \in V$，并且
$$
\mathcal{M}(ST, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p), (\boldsymbol{w}_1, \ldots, \boldsymbol{w}_m)) \\
= \mathcal{M}(S, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n), (\boldsymbol{w}_1, \ldots, \boldsymbol{w}_m)) \mathcal{M}(T, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n))
$$
且
$$
\mathcal{M}(T \boldsymbol{x}, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)) = \mathcal{M}(T, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)) \mathcal{M} (\boldsymbol{x}, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p)).
$$


*定理* 设$(\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_p)$都是$V$的基，则$\mathcal{M}(I, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_p))$可逆，并且
$$
\mathcal{M}(I, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_p)) = \mathcal{M}(I, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_p), (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_p))^{-1}
$$
此外，对任意$V$上的线性算子$T$，设$\boldsymbol{A} = \mathcal{M}(I, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n))$，有
$$
\mathcal{M}(T, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)) = \boldsymbol{A}^{-1} \mathcal{M}(T, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)) \boldsymbol{A}.
$$


*定理* 向量$\boldsymbol{a}$的矩阵表示则满足
$$
\mathcal{M}(\boldsymbol{a}, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)) = \boldsymbol{A}^{-1} \mathcal{M}(\boldsymbol{a}, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n))
$$

### 变换矩阵的计算
$\boldsymbol{A}$的各个矩阵元可以按照下面的方式确定。我们容易看出
$$
\boldsymbol{u}_k = A_{1k}\boldsymbol{v}_1 + \ldots + A_{nk} \boldsymbol{v}_n,
$$
考虑到矩阵化运算是可逆的线性映射，我们使用$\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n$来表示$\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n$，可以得到
$$
\boldsymbol{I} = (\mathcal{M}(\boldsymbol{v}_1, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)), \ldots, \mathcal{M}(\boldsymbol{v}_n, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n))) \boldsymbol{A}
$$
从而
$$
\boldsymbol{A} = (\mathcal{M}(\boldsymbol{v}_1, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)), \ldots, \mathcal{M}(\boldsymbol{v}_n, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)))^{-1}
$$
考虑到逆矩阵，又有
$$
\begin{aligned}
    \boldsymbol{A} &= (\mathcal{M}(\boldsymbol{v}_1, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)), \ldots, \mathcal{M}(\boldsymbol{v}_n, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)))^{-1} \\
    &= (\mathcal{M}(\boldsymbol{u}_1, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)), \ldots, \mathcal{M}(\boldsymbol{u}_n, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)))
\end{aligned}
$$

而如果我们有第三组基$\boldsymbol{w}_1, \ldots, \boldsymbol{w}_n$，那么
$$
\mathcal{M}(I, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n), (\boldsymbol{w}_1, \ldots, \boldsymbol{w}_n)) \boldsymbol{A} = \mathcal{M} (I, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n), (\boldsymbol{w}_1, \ldots, \boldsymbol{w}_n))
$$

记
$$
\mathcal{T}((\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n), (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)) = \mathcal{M} (I, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n))
$$
则有
$$
\begin{aligned}
    \mathcal{T}((\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n), (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)) &= \mathcal{M} (I, (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)) \\
    &= (\mathcal{M}(\boldsymbol{u}_1, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)), \ldots, \mathcal{M}(\boldsymbol{u}_n, (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)))
\end{aligned}
$$
也就是说$\mathcal{T}((\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n), (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n))$就是将诸$\boldsymbol{u}$在诸$\boldsymbol{v}$下的线性表示写成列向量拼起来以后得到的矩阵。
$$
\mathcal{T}((\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)) = \mathcal{T}((\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n), (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n))^{-1}
$$

$$
\mathcal{T}((\boldsymbol{w}_1, \ldots, \boldsymbol{w}_n), (\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n)) \mathcal{T}((\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n), (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n)) = \mathcal{T} ((\boldsymbol{w}_1, \ldots, \boldsymbol{w}_n), (\boldsymbol{u}_1, \ldots, \boldsymbol{u}_n))
$$

## 直和的表示
设$\boldsymbol{u} \in U$在$\boldsymbol{u}_1, \ldots, \boldsymbol{u}_m$下的矩阵表示为$\boldsymbol{a}$，$\boldsymbol{v} \in V$在$\boldsymbol{v}_1, \ldots, \boldsymbol{v}_n$下的矩阵表示为$\boldsymbol{b}$，且$W = U \oplus V$，那么$\boldsymbol{u} + \boldsymbol{v}$在$\boldsymbol{u}_1, \ldots, \boldsymbol{u}_m, \boldsymbol{v}_1, \ldots, \bold{v_n}$下的矩阵表示为
$$
\left[
    \begin{matrix}
        \boldsymbol{a} \\
        \boldsymbol{b}
    \end{matrix}
\right]
$$
