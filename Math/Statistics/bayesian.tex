\documentclass[hyperref, a4paper]{article}

\usepackage{geometry}
\usepackage{titling}
\usepackage{titlesec}
% No longer needed, since we will use enumitem package
% \usepackage{paralist}
\usepackage{enumitem}
\usepackage{footnote}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{soulutf8}
\usepackage{physics}
\usepackage{tensor}
\usepackage{siunitx}
\usepackage[version=4]{mhchem}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{autobreak}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\usepackage{nameref,zref-xr}
\zxrsetup{toltxlabel}
\usepackage[backend=bibtex]{biblatex}
\addbibresource{nonequilibrium.bib}
\usepackage[colorlinks,unicode]{hyperref} % , linkcolor=black, anchorcolor=black, citecolor=black, urlcolor=black, filecolor=black
\usepackage[most]{tcolorbox}
\usepackage{prettyref}

% Page style
\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}

% More compact lists 
\setlist[itemize]{
    itemindent=17pt, 
    leftmargin=1pt,
    listparindent=\parindent,
    parsep=0pt,
}

% Math operators
\DeclareMathOperator{\timeorder}{\mathcal{T}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\legpoly}{P}
\DeclareMathOperator{\primevalue}{P}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\res}{Res}
\DeclareMathOperator{\expect}{\mathbb{E}}
\newcommand*{\ii}{\mathrm{i}}
\newcommand*{\ee}{\mathrm{e}}
\newcommand*{\const}{\mathrm{const}}
\newcommand*{\suchthat}{\quad \text{s.t.} \quad}
\newcommand*{\argmin}{\arg\min}
\newcommand*{\argmax}{\arg\max}
\newcommand*{\normalorder}[1]{: #1 :}
\newcommand*{\pair}[1]{\langle #1 \rangle}
\newcommand*{\fd}[1]{\mathcal{D} #1}
\DeclareMathOperator{\bigO}{\mathcal{O}}

% TikZ setting
\usetikzlibrary{arrows,shapes,positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\tikzstyle arrowstyle=[scale=1]
\tikzstyle directed=[postaction={decorate,decoration={markings,
    mark=at position .5 with {\arrow[arrowstyle]{stealth}}}}]
\tikzstyle ray=[directed, thick]
\tikzstyle dot=[anchor=base,fill,circle,inner sep=1pt]

% Algorithm setting
% Julia-style code
\SetKwIF{If}{ElseIf}{Else}{if}{}{elseif}{else}{end}
\SetKwFor{For}{for}{}{end}
\SetKwFor{While}{while}{}{end}
\SetKwProg{Function}{function}{}{end}
\SetArgSty{textnormal}

\newcommand*{\concept}[1]{{\textbf{#1}}}

% Embedded codes
\lstset{basicstyle=\ttfamily,
  showstringspaces=false,
  commentstyle=\color{gray},
  keywordstyle=\color{blue}
}

% Reference formatting
\newcommand*{\citesec}[1]{\S~{#1}}
\newcommand*{\citechap}[1]{chap.~{#1}}
\newcommand*{\citefig}[1]{Fig.~{#1}}
\newcommand*{\citetable}[1]{Table~{#1}}
\newcommand*{\citepage}[1]{pp.~{#1}}
\newrefformat{fig}{Fig.~\ref{#1}}
\newcommand*{\term}[1]{\textit{#1}}

% Color boxes
\tcbuselibrary{skins, breakable, theorems}

\newtcbtheorem{infobox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=blue!5,
    colframe=blue!5,
    coltitle=blue!50,
    borderline west={4pt}{0pt}{blue!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}
\newtcbtheorem[use counter from=infobox]{theorybox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=orange!5, 
    colframe=orange!5, 
    coltitle=orange!50,
    borderline west={4pt}{0pt}{orange!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}
\newtcbtheorem[use counter from=infobox]{learnbox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=green!5,
    colframe=green!5,
    coltitle=green!50,
    borderline west={4pt}{0pt}{green!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}


\newenvironment{shelldisplay}{\begin{lstlisting}}{\end{lstlisting}}

\newcommand*{\kB}{k_{\text{B}}}
\newcommand*{\muB}{\mu_{\text{B}}}
\newcommand*{\efermi}{E_{\text{F}}}
\newcommand*{\pfermi}{p_{\text{F}}}
\newcommand*{\vfermi}{v_{\text{F}}}
\newcommand*{\sA}{\text{A}}
\newcommand*{\sB}{\text{B}}
\newcommand*{\Tc}{T_{\text{c}}}
\newcommand*{\hethree}{$^3$He}
\newcommand*{\hefour}{$^4$He}
\newcommand{\epsr}{\epsilon_{\text{r}}}
\newcommand{\chie}{\chi_{\text{e}}}
\newcommand{\cf}{c_{\text{F}}}
\newcommand{\fn}{F_{\text{N}}}
\newcommand{\ff}{F_{\text{f}}}

\title{Bayesian inference}
\author{Jinyuan Wu}

\begin{document}

\maketitle

In Bayesian inference, unlike in the frequentist framework,
parameters in a model are considered to be random variables themselves.
We assume that $p(x | \theta)$ has a known form,
and we calculate the a posteriori distribution of $\theta$ by 
\begin{equation}
    p(\theta | \mathcal{D}) = \frac{p(\mathcal{D} | \theta) p(\theta)}{
        \sum_{\theta'} p(\mathcal{D} | \theta') p(\theta')
    }.
\end{equation}
Here $p(\theta)$ is the prior.
The workflow is to TODO

Predicting a new value:
\begin{equation}
    p(y | \mathcal{D}, x)
\end{equation}
Need some consistency theorems 

\section{Bayesian regression}

Let's go back to a generic regression problem:
\begin{equation}
    Y = m(X) + \epsilon,
\end{equation}
where $\epsilon$ is assumed to be gaussian.
In Bayesian regression what we want is to estimate the distribution of $m$, seen as a random variable.
More accurately we may call $m$ a \concept{stochastic process},
as it has an index (i.e. $X$) and resembles the trajectory of a stochastic trajectory of a randomly walking agent.
Note, however, in statistics,
we don't assume $X$ to be a time variable.

It's common to assume a gaussian process prior for $m$.
That's to say,
Assuming that the 

The gaussian process prior penalizes functions that are wiggly,
because commonly used kernels have small eigenvalues when the eigenfunctions are wiggly.
This means wiggly $m$'s have smaller gaussian weights and hence smaller probabilities.

So the conclusion is that gaussian process-based Bayesian regression is equivalent to Mercer kernel regression.
But the former also provides us with an estimation of uncertainties.

\section{Sampling}

A \concept{Gibbs sampler} is what most physicists use when doing Monte Carlo simulation.
Basically it flips the variables one by one following a \emph{random} order
(that's to say, the sampler randomly chooses a variable to update and then flips it).

If we know the noise distribution in an image,
sampling of that distribution can \emph{denoise} it:
just set the initial state of the simulation to be the noisy image

\end{document}