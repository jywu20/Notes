\documentclass[hyperref, a4paper]{article}

\usepackage{geometry}
\usepackage{titling}
\usepackage{titlesec}
% No longer needed, since we will use enumitem package
% \usepackage{paralist}
\usepackage{enumitem}
\usepackage{footnote}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{soulutf8}
\usepackage{physics}
\usepackage{tensor}
\usepackage{siunitx}
\usepackage[version=4]{mhchem}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{autobreak}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\usepackage{nameref,zref-xr}
\zxrsetup{toltxlabel}
\usepackage[backend=bibtex]{biblatex}
\addbibresource{nonequilibrium.bib}
\usepackage[colorlinks,unicode]{hyperref} % , linkcolor=black, anchorcolor=black, citecolor=black, urlcolor=black, filecolor=black
\usepackage[most]{tcolorbox}
\usepackage{prettyref}

% Page style
\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}

% More compact lists 
\setlist[itemize]{
    itemindent=17pt, 
    leftmargin=1pt,
    listparindent=\parindent,
    parsep=0pt,
}

% Math operators
\DeclareMathOperator{\timeorder}{\mathcal{T}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\legpoly}{P}
\DeclareMathOperator{\primevalue}{P}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\res}{Res}
\DeclareMathOperator{\expect}{\mathbb{E}}
\newcommand*{\ii}{\mathrm{i}}
\newcommand*{\ee}{\mathrm{e}}
\newcommand*{\const}{\mathrm{const}}
\newcommand*{\suchthat}{\quad \text{s.t.} \quad}
\newcommand*{\argmin}{\arg\min}
\newcommand*{\argmax}{\arg\max}
\newcommand*{\normalorder}[1]{: #1 :}
\newcommand*{\pair}[1]{\langle #1 \rangle}
\newcommand*{\fd}[1]{\mathcal{D} #1}
\DeclareMathOperator{\bigO}{\mathcal{O}}

% TikZ setting
\usetikzlibrary{arrows,shapes,positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\tikzstyle arrowstyle=[scale=1]
\tikzstyle directed=[postaction={decorate,decoration={markings,
    mark=at position .5 with {\arrow[arrowstyle]{stealth}}}}]
\tikzstyle ray=[directed, thick]
\tikzstyle dot=[anchor=base,fill,circle,inner sep=1pt]

% Algorithm setting
% Julia-style code
\SetKwIF{If}{ElseIf}{Else}{if}{}{elseif}{else}{end}
\SetKwFor{For}{for}{}{end}
\SetKwFor{While}{while}{}{end}
\SetKwProg{Function}{function}{}{end}
\SetArgSty{textnormal}

\newcommand*{\concept}[1]{{\textbf{#1}}}

% Embedded codes
\lstset{basicstyle=\ttfamily,
  showstringspaces=false,
  commentstyle=\color{gray},
  keywordstyle=\color{blue}
}

% Reference formatting
\newcommand*{\citesec}[1]{\S~{#1}}
\newcommand*{\citechap}[1]{chap.~{#1}}
\newcommand*{\citefig}[1]{Fig.~{#1}}
\newcommand*{\citetable}[1]{Table~{#1}}
\newcommand*{\citepage}[1]{pp.~{#1}}
\newrefformat{fig}{Fig.~\ref{#1}}
\newcommand*{\term}[1]{\textit{#1}}

% Color boxes
\tcbuselibrary{skins, breakable, theorems}

\newtcbtheorem{infobox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=blue!5,
    colframe=blue!5,
    coltitle=blue!50,
    borderline west={4pt}{0pt}{blue!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}
\newtcbtheorem[use counter from=infobox]{theorybox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=orange!5, 
    colframe=orange!5, 
    coltitle=orange!50,
    borderline west={4pt}{0pt}{orange!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}
\newtcbtheorem[use counter from=infobox]{learnbox}{Box}{
    enhanced,
    boxrule=0pt,
    colback=green!5,
    colframe=green!5,
    coltitle=green!50,
    borderline west={4pt}{0pt}{green!65},
    sharp corners,
    fonttitle=\bfseries, 
    breakable,
    before upper={\parindent15pt\noindent}}{box}


\newenvironment{shelldisplay}{\begin{lstlisting}}{\end{lstlisting}}

\newcommand*{\kB}{k_{\text{B}}}
\newcommand*{\muB}{\mu_{\text{B}}}
\newcommand*{\efermi}{E_{\text{F}}}
\newcommand*{\pfermi}{p_{\text{F}}}
\newcommand*{\vfermi}{v_{\text{F}}}
\newcommand*{\sA}{\text{A}}
\newcommand*{\sB}{\text{B}}
\newcommand*{\Tc}{T_{\text{c}}}
\newcommand*{\hethree}{$^3$He}
\newcommand*{\hefour}{$^4$He}
\newcommand{\epsr}{\epsilon_{\text{r}}}
\newcommand{\chie}{\chi_{\text{e}}}
\newcommand{\cf}{c_{\text{F}}}
\newcommand{\fn}{F_{\text{N}}}
\newcommand{\ff}{F_{\text{f}}}

\title{Random variables}
\author{Jinyuan Wu}

\begin{document}

\maketitle

\section{Poisson distribution and Poisson process}

A Poisson process is a Markovian process, in which we have a random variable $N(t)$
--- the cumulated number of events that have already happened ---
and the probabilistic distribution is 
\begin{equation}
    P(\text{$N+1$ at $t + \dd{t}$} | \text{$N$ at $t$}) = \lambda \dd{t}, \quad 
    P(\text{$N$ at $t + \dd{t}$} | \text{$N$ at $t$}) = 1 - \lambda \dd{t},
    \label{eq:jump}
\end{equation}
and for $n \geq 2$,
\begin{equation}
    P(\text{$N+n$ at $t + \dd{t}$} | \text{$N$ at $t$}) = 0.
    \label{eq:no-double-jump}
\end{equation}
We also assume that there is a starting point --- typically set to be $t = 0$ ---
where we're sure that $N$ can only be zero.

The Poisson process being Markovian means 
\begin{equation}
    \begin{aligned}
        P(\text{$N+1$ at $t + \dd{t}$}) &= P(\text{$N+1$ at $t + \dd{t}$} | \text{$N+1$ at $t$}) P(\text{$N+1$ at $t$}) \\
        &+ P(\text{$N+1$ at $t + \dd{t}$} | \text{$N$ at $t$}) P(\text{$N$ at $t$}),
    \end{aligned}
\end{equation}
which immediately leads to the differential equation system 
\begin{equation}
    \dv{t} P(\text{$N+1$ at $t$}) = \lambda (P(\text{$N$ at $t$}) - P(\text{$N+1$ at $t$})),
\end{equation}
or we can also write 
\begin{equation}
    \dv{t} P(N(t) = k + 1) = \lambda (P(N(t) = k) - P(N(t) = k + 1)).
\end{equation}
The equation for $k = 0$ is 
\begin{equation}
    \dv{t} P(N(t) = 0) = - \lambda P(N(t) = 0),
\end{equation}
because there is no ``income'' term.

The equation system can be solved directly.
Alternatively it can be solved using combinatorics.
Dividing the time span from $0$ to $t$ into $t / \Delta t$ slices,
we note that in each slice, because of \eqref{eq:no-double-jump},
the cumulated number can only jump by one with the probability of $\lambda \Delta t$,
or stay the same, with the probability of $1 - \lambda \Delta t$.
This is a binomial distribution, and we have
\begin{equation}
    \begin{aligned}
        P(N(t) = k) &\approx \binom{t / \Delta t}{k} (\lambda \Delta t)^k (1 - \lambda \Delta t)^{t / \Delta t - k} \\
        &= \underbrace{\frac{(t / \Delta t)!}{k! (t / \Delta t - k)!} \cdot \frac{1}{(t / \Delta t)^k}}_{\to 1 / k!} (\lambda t)^k \underbrace{(1 - \lambda \Delta t)^{t / \Delta t - k}}_{\to \ee^{-\lambda t}} \quad \text{as $\Delta t \to 0$}  \\
        &= \frac{(\lambda t)^k}{k!} \ee^{- \lambda t}.
    \end{aligned}
\end{equation}

The distribution 
\begin{equation}
    N(t) \sim \mathrm{Poisson}(\lambda t), \quad 
    P(N(t) = k) = \frac{(\lambda t)^k}{k!} \ee^{- \lambda t}
    \label{eq:poisson}
\end{equation}
is therefore known as the \concept{Poisson distribution}.
In physics, it can be seen as a incoherent effective theory of 
processes described by Fermi golden rule.

Another question is the probabilistic distribution of the time in which nothing happens,
that is, $P(N(t + t_0) = k | N(t_0) = k)$.
From time translational symmetry and independence between events
(that's to say, we can freely add and subtract a constant from $N$),
we know this equals to $P(N(t) = 0 | N(0) = 0)$,
which is the same as fixing $N(0) = 0$ and evaluating $P(N(t) = 0)$,
which we already know: it is 
\begin{equation}
    P(N(t) = 0) = \ee^{-\lambda t}.
\end{equation}
If we use $T$ to refer to the time between two events, this means
\begin{equation}
    P(T > t) = \ee^{- \lambda t}.
\end{equation}
The temporal probabilistic distribution function therefore is 
\begin{equation}
    P(t < T < t + \dd{t}) = - \dv{P(T > t)}{t} \dd{t} = \lambda \ee^{- \lambda t} \dd{t} .
    \label{eq:temporal}
\end{equation}
From this we find
\begin{equation}
    \expect[T] = \int_{t > 0} t P(t < T < t + \dd{t}) = \frac{1}{\lambda}
\end{equation}
and similarly
\begin{equation}
    \mathrm{Var}[T] = \expect[T^2] - \expect[T]^2 = \frac{1}{\lambda^2}.
\end{equation}
This means the average waiting time to see one more event is $1 / \lambda$
(as the waiting time can be defined for $P(N(t + t_0) = k | N(t_0) = k)$
and the calculation is identical).

It's straightforward to verify the correctness of 
\eqref{eq:jump} and \eqref{eq:no-double-jump} from \eqref{eq:poisson}.
Further, given the Markovian property and independence between events,
from \eqref{eq:temporal} we can derive \eqref{eq:jump} and hence \eqref{eq:no-double-jump}.


\end{document}