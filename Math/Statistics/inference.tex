\documentclass[hyperref, UTF8, a4paper]{ctexart}

\usepackage{geometry}
\usepackage{titling}
\usepackage{titlesec}
\usepackage{paralist}
\usepackage{footnote}
\usepackage{enumerate}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{bbm}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{physics}
\usepackage{tikz}
\usepackage{autobreak}
\usepackage[ruled, vlined, linesnumbered, noend]{algorithm2e}
\usepackage[colorlinks, linkcolor=black, anchorcolor=black, citecolor=black]{hyperref}
\usepackage{prettyref}

% Page style
\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}
\preauthor{\vspace{-10pt}\begin{center}}
\postauthor{\par\end{center}}

% Math operators
\DeclareMathOperator{\timeorder}{T}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\legpoly}{P}
\DeclareMathOperator{\primevalue}{P}
\DeclareMathOperator{\sgn}{sgn}
\newcommand*{\ii}{\mathrm{i}}
\newcommand*{\ee}{\mathrm{e}}
\newcommand*{\const}{\mathrm{const}}
\newcommand*{\comment}{\paragraph{注记}}
\newcommand*{\suchthat}{\quad \text{s.t.} \quad}
\newcommand*{\argmin}{\arg\min}
\newcommand*{\argmax}{\arg\max}
\newcommand*{\normalorder}[1]{: #1 :}
\newcommand*{\pair}[1]{\langle #1 \rangle}
\newcommand*{\fd}[1]{\mathcal{D} #1}
\DeclareMathOperator{\bigO}{\mathcal{O}}

% prettyref setting
\newrefformat{sec}{第\ref{#1}节}
\newrefformat{note}{注\ref{#1}}
\newrefformat{fig}{图\ref{#1}}
\newrefformat{alg}{算法\ref{#1}}
\renewcommand{\autoref}{\prettyref}

% TikZ setting
\usetikzlibrary{arrows,shapes,positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\tikzstyle arrowstyle=[scale=1]
\tikzstyle directed=[postaction={decorate,decoration={markings,
    mark=at position .5 with {\arrow[arrowstyle]{stealth}}}}]
\tikzstyle ray=[directed, thick]
\tikzstyle dot=[anchor=base,fill,circle,inner sep=1pt]

% Algorithm setting
\renewcommand{\algorithmcfname}{算法}
% Python-style code
\SetKwIF{If}{ElseIf}{Else}{if}{:}{elif:}{else:}{}
\SetKwFor{For}{for}{:}{}
\SetKwFor{While}{while}{:}{}
\SetKwInput{KwData}{输入}
\SetKwInput{KwResult}{输出}
\SetArgSty{textnormal}

\renewcommand{\emph}[1]{\textbf{#1}}
\newcommand*{\concept}[1]{\underline{\textbf{#1}}}

\title{统计推断}
\author{吴晋渊}

\begin{document}

\maketitle

\section{统计推断的基本概念}

我们常常需要面对这样的问题：设有一个在我们关心的范围内不随时间变化的随机变量（称为\concept{总体}）$\mathcal{X}$，我们并不完全知道这个随机变量的形式。
现在我们获知了和$\mathcal{X}$有关的一系列事件$X$（称为\concept{证据}），要通过它们来推知关于$\mathcal{X}$的一些信息，这个过程就是\concept{统计推断}。
例如，证据可以是反复运行$\mathcal{X}$而获得的一组取值
\begin{equation}
    \mathcal{D} = \{X_i\},
\end{equation}
这称为\concept{样本}，获得取值的方式称为\concept{采样}）。

\subsection{常见的统计推断任务}

常见的统计推断任务包括
\begin{itemize}
    \item \concept{假设检验}，即从一系列证据出发，判断是否应该认为关于$\mathcal{X}$的某个命题成立；
    \item \concept{概率估计}，即判断某个命题为真的概率有多大，这和假设检验有非常显然的联系；
    \item \concept{参数估计}，即判断与总体相关的一些参数的取值（或者取值的概率分布）；
    \item \concept{相关性分析}，这是在$\mathcal{X}$有多个分量时使用的，即分析这些变量之间的关系；
    \item \concept{机器学习}，即从较大的样本中将数据分类贴上标签；
\end{itemize}
还有许许多多其它的任务。

机器学习的一个特殊的例子是
\begin{equation}
    \mathcal{X} = (\vb{x}, y),
\end{equation}
$\vb{x}$是一组数据（通常称为\concept{特征}），$y$是和这组数据有关的另一个数据（通常称为\concept{标签}），此时的统计推断就是\concept{监督学习}。
如果直接从样本分析$P(\vb{x}, y)$的特征，就是\concept{生成模型}，而如果从样本分析$P(y|\vb{x})$的特征，那就是\concept{判别模型}。两者之间有着这样的关系：
\begin{equation}
    P(y | \vb{x}) = \frac{P(\vb{x}, y)}{P(\vb{x})} = \frac{P(\vb{x}, y)}{\sum_{y'} P(\vb{x}, y')}, 
\end{equation}
这里使用的记号需要特殊说明一下：$P(y | \vb{x})$实际上是“在某次运行$\mathcal{X}$，得到的特征是$\vb{x}$的条件下，发现其标签为$y$”的概率的简写，$P(\vb{x}, y)$同理。
为了简洁我们接下来在不至于混淆时不强调“随机变量”和“随机变量的可能取值”的区别。                                                
\subsection{模型}

当然，既然$\mathcal{X}$是自然界中一系列随机性过程给出的输出，我们总是可以找到一系列数目往往非常大的随机变量$\alpha_1, \alpha_2, \ldots, \alpha_N$，它们决定了$\mathcal{X}$，即
\[
    \mathcal{X} = F(\alpha_1, \alpha_2, \ldots, \alpha_N).
\]
我们可以把物理定律当成某种“计算过程”，向它输入一些事件，就可以输出一个$\mathcal{X}$的值。
我们当然不可能使用如此大量的随机变量来描述$\mathcal{X}$，即使技术上可行，这也没有提供给我们任何有价值的信息，因为这相当于做了一次虚拟仿真实验。
但，如果我们能够找到某个事件$H$和一个随机变量$\theta$（它可能也含有大量的分量，但无论如何比$\{\alpha\}$简洁），使得
\[
    P(\mathcal{X} = C | H, \theta) = f(C ; \theta), 
\]
且$P(H)$非常大，那就可以大大简化我们要处理的问题，并且提供给我们一个“因为所以”式的\emph{解释}——因为$\theta$取了某些值，所以$\mathcal{X}$取了这个特定的值。
我们称$H$为\concept{模型假设}，$f(\mathcal{X};\theta)$为\concept{模型}，$\theta$为\concept{参数}。
在$P(H)$非常大（以至于可以认为$H$是确凿无疑的一个命题）时，我们就有
\begin{equation}
    P(\mathcal{X} = C | \theta) = f(C ; \theta).
\end{equation}
模型假设是否正确可以通过假设检验来判断，也可以通过专家知识给出。

\subsection{主观概率}

当然，由于$\mathcal{X}$是通过一个实际的随机过程产生的，我们肯定会有一个“真实的”概率$P(\mathcal{X}=C)$，并进而可以计算出各种不同的事件发生的真实概率。
但大部分时候，我们都不能够把产生$\mathcal{X}$的物理过程写下来，而只是有一些零散的证据而已，此时讨论真实概率是怎样的根本就毫无意义。

我们采取贝叶斯学派的观点，即将对命题的置信程度当成一种概率测度（它多半和真实概率不一样），称为\concept{主观概率}，并使用$p(\cdot)$表示。
证据的出现当然会导致对各种命题的置信程度的变化。贝叶斯学派做了以下假定：如果事件$A$实际上发生了（或者说事件$A$是证据的一部分），那么要做以下\concept{概率更新}：
\begin{equation}
    p(B) \longleftarrow p(B|A),
\end{equation}
即事件$A$出现之后，应该将$B$发生的概率（即对$B$的置信程度）替换为$A$发生之前的条件概率。
通过这样的方式定义的主观概率就是\concept{贝叶斯概率}。
出于显而易见的原因，我们称$p(B)$为\concept{先验概率}，称$p(B|A)$为\concept{后验概率}；概率更新让上一轮概率更新的后验概率变成本轮概率更新的先验概率。

有定理（convergence-to-truth theorems）保证只要有足够多的证据，总是可以让贝叶斯概率收敛到真实概率上。
因此贝叶斯方法总是可以用的。
另一个选择贝叶斯方法的原因是，它可以很好地表述“过往的证据给我们留下的知识”。
概率更新肯定要有一个起点，在起点处不同事件的概率被赋予一个初始值，只需要把这个初始值（也就是整个更新过程的先验概率）选取为以前的概率更新的结果就可以了。

总之，贝叶斯概率更新的步骤如下：

\begin{algorithm}[H]

    \DontPrintSemicolon
    \SetAlgoLined

    \KwData{本次概率更新的先验概率$p_0(B)$，证据集$\{X_i\}$，证据$X$的先验概率$p_0(X)$，$B$成立时每个证据的条件概率}
    \KwResult{更新结束后的贝叶斯概率$p_\text{final}(B)$}
    
    $p(B) \leftarrow p_0(B)$ \;
    \For{每一个$X_i$}{
        计算证据$X_i$出现的先验概率$p(X_i) = p_0(X_i)$ \;
        计算后验概率$p(B|X_i) = \frac{p(B)}{p(X)} p(X_i | B)$ \;
        概率更新：$p(B) \leftarrow p(B|X_i)$ \;
    }
    \Return{$p(B)$}\;

    \caption{贝叶斯更新}
    \label{alg:bayesian-updating}
\end{algorithm}

\section{贝叶斯推断任务}

\subsection{模型选择}

\subsection{参数估计}

本节讨论\concept{参数估计}，即已经确定使用某个模型之后，怎么把这个模型中的参数$\theta$算出来。
虽然原则上，按照贝叶斯更新算法，我们应该把$\theta$的完整后验概率分布$p(\theta | X)$算出来，并用它代替$p(\theta)$，但这样计算量实在是太大了。通常，我们只是做\concept{极大后验估计}，即假定$p(\theta | X)$非常尖锐，那么可以取
\[
    \hat{\theta} = \argmax_\theta p(\theta | X).
\]
考虑到贝叶斯公式，且$p(X)$是先验概率，和$\theta$无关，我们有
\begin{equation}
    \hat{\theta} = \argmax_\theta (p(X | \theta) + p(\theta)).
    \label{eq:max-post-estimation}
\end{equation}
这个公式和优化中的损失函数-正则化是一样的：$p(X | \theta)$是损失函数，而$p(\theta)$则是正则化项。
这是正确的，因为正则化项手动地设定了“模型参数应该大致是什么样子的”，而这恰恰是先验概率提供的信息。
在$p(\theta)$是常数时它可以略去，此时我们就得到了频率学派的\concept{极大似然估计}。

所谓机器学习实际上就是一种使用大样本、大模型的参数估计。首先我们采取合适的假设，写出$p(X | \theta)$，在实际工作中这就是编写模型。
通常写出模型的方法是，首先假装$p(\mathcal{X}|\theta)$可以充分模拟$\mathcal{X}$的分布，然后假定$X$是通过某种（可能出错）的信道抽样出来的，那么就可以写出$p(X | \theta)$。
至于这个假设（或者说模型的架构）是不是正确，当然有各种假设检验和基准测试的方法；然后使用梯度下降法或者其变体，按照\eqref{eq:max-post-estimation}做优化%
\footnote{至于是不是$\theta$停留在了某个鞍点，通常并不清楚；但是只要优化得足够好就行。
实际上，$\theta$停留在某个鞍点还可以避免过拟合，相当于自动地调整了$p(\theta)$的形式，考虑到实际上很难很准确地分析出足够好的先验，这未必是坏事。}%
，然后再在测试数据集上\concept{验证}。
在这个过程中，先验知识体现为假设$H$，以及先验$p(\theta)$，或者说体现为模型和优化方式。

\section{频率学派}

从贝叶斯统计的角度看，实际上并没有真正的“频率学派”——实际上大部分频率学派的内容都和没有先验的贝叶斯统计是等价的。
因此我们会注意到，大部分情况下贝叶斯推断都比频率学派的推断更为费力，这是因为频率学派实际上做了相当多非常强的假设。

\end{document}