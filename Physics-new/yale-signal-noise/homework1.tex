\documentclass[hyperref, a4paper]{article}

\usepackage{geometry}
\usepackage{titling}
\usepackage{titlesec}
% No longer needed, since we will use enumitem package
% \usepackage{paralist}
\usepackage{enumitem}
\usepackage{footnote}
\usepackage{enumerate}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{physics}
\usepackage{tensor}
\usepackage{siunitx}
\usepackage[version=4]{mhchem}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{autobreak}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\usepackage{nameref,zref-xr}
\zxrsetup{toltxlabel}
\usepackage[colorlinks,unicode]{hyperref} % , linkcolor=black, anchorcolor=black, citecolor=black, urlcolor=black, filecolor=black
\usepackage[most]{tcolorbox}
\usepackage{prettyref}

% Page style
\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\titlespacing{\paragraph}{0pt}{1pt}{10pt}[20pt]
\setlength{\droptitle}{-5em}
\preauthor{\vspace{-10pt}\begin{center}}
\postauthor{\par\end{center}}

% More compact lists 
\setlist[itemize]{
    itemindent=17pt, 
    leftmargin=1pt,
    listparindent=\parindent,
    parsep=0pt,
}

% Math operators
\DeclareMathOperator{\timeorder}{\mathcal{T}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\legpoly}{P}
\DeclareMathOperator{\primevalue}{P}
\DeclareMathOperator{\sgn}{sgn}
\newcommand*{\ii}{\mathrm{i}}
\newcommand*{\ee}{\mathrm{e}}
\newcommand*{\const}{\mathrm{const}}
\newcommand*{\suchthat}{\quad \text{s.t.} \quad}
\newcommand*{\argmin}{\arg\min}
\newcommand*{\argmax}{\arg\max}
\newcommand*{\normalorder}[1]{: #1 :}
\newcommand*{\pair}[1]{\langle #1 \rangle}
\newcommand*{\fd}[1]{\mathcal{D} #1}
\DeclareMathOperator{\bigO}{\mathcal{O}}

% TikZ setting
\usetikzlibrary{arrows,shapes,positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\tikzstyle arrowstyle=[scale=1]
\tikzstyle directed=[postaction={decorate,decoration={markings,
    mark=at position .5 with {\arrow[arrowstyle]{stealth}}}}]
\tikzstyle ray=[directed, thick]
\tikzstyle dot=[anchor=base,fill,circle,inner sep=1pt]

% Algorithm setting
% Julia-style code
\SetKwIF{If}{ElseIf}{Else}{if}{}{elseif}{else}{end}
\SetKwFor{For}{for}{}{end}
\SetKwFor{While}{while}{}{end}
\SetKwProg{Function}{function}{}{end}
\SetArgSty{textnormal}

\newcommand*{\concept}[1]{{\textbf{#1}}}

% Embedded codes
\lstset{basicstyle=\ttfamily,
  showstringspaces=false,
  commentstyle=\color{gray},
  keywordstyle=\color{blue}
}

% Reference formatting
\newrefformat{fig}{Figure~\ref{#1}}

% Color boxes
\tcbuselibrary{skins, breakable, theorems}
\newtcbtheorem[number within=section]{warning}{Warning}%
  {colback=orange!5,colframe=orange!65,fonttitle=\bfseries, breakable}{warn}
\newtcbtheorem[number within=section]{note}{Note}%
  {colback=green!5,colframe=green!65,fonttitle=\bfseries, breakable}{note}
\newtcbtheorem[number within=section]{info}{Info}%
  {colback=blue!5,colframe=blue!65,fonttitle=\bfseries, breakable}{info}

\newenvironment{shelldisplay}{\begin{lstlisting}}{\end{lstlisting}}

\title{Homework 1}
\author{Jinyuan Wu}

\begin{document}

\maketitle

\paragraph{Exercise 9 in chapter 1} (**) Let us show now one simple way to produce the realizations of $B_m$ knowing the realizations of one example of $B_{1 / 2}$. From the set of the realizations of $B_{1 / 2}$, which we can view as a real number $r \in[0,1[$ by forming the binary digit number $0.\beta^{(1)} \beta^{(2)} \beta^{(3)} \beta^{(4)} \beta^{(5)} \ldots$ (example: $0.011010110001111 \ldots$ ), we can obtain the real numbers $r^{(1)}, r^{(2)}, r^{(3)}$ etc... from the formula:
$$
r^{(n)}=\left(2^n r\right) \bmod 1
$$
The realisations $\beta_m^{(n)}$ will be obtained from $r^{(n)}$ by the expression
$$
\begin{aligned}
&\beta_m^{(n)}=0 \text { if } r^{(n)} \geqslant m \\
&\beta_m^{(n)}=1 \text { if } r^{(n)}<m
\end{aligned}
$$
Prove that this last expression yields the expected properties for $B_m$.

\paragraph{Solution} Since 
\[
    r^{(n)} = \beta^{(1)} \beta^{(2)} \cdots \beta^{(n)} . \beta^{(n+1)} \beta^{(n+2)} \cdots,
\]
we know 
\begin{equation}
    r^{(n)} = 0. \beta^{(n + 1)} \beta^{(n+2)} \cdots.
\end{equation}
Each digit of $r^{(n)}$ is 0 or 1, 
and thus the possible range of $r^{(n)}$ is [0, 1].%
\footnote{
    It's actually possible to have $r^{(n)} = 1$,
    because the binary $0.11111\cdots$ is actually $1$,
    in the same way $0.9999\cdots = 1$ in the decimal case.
    But the probability to have such a $r^{(n)}$ is $1/2 \times 1/2 \times \cdots = 0$.
    That is, the event that $r^{(n)} = 1$ is possible but is a null set.
} 
Suppose 
\[
    x = 0.x^{(1)} x^{(2)} \cdots \in [0, 1],
\]
we have 
\[
    \begin{aligned}
        P(r^{(n)} < x) &= P(\beta^{(n+1)} < x^{(1)}) + P(\beta^{(n+1)} = x^{(1)}) P(\beta^{(n+2)} < x^{(2)}) + \cdots \\
        &= \frac{1}{2} \delta_{x^{(1)}, 1} + \frac{1}{2} \times \frac{1}{2} \delta_{x^{(2)}, 1} + \cdots \\
        &= 0.x^{(1)} x^{(2)} \cdots = x,
    \end{aligned}
\]
so $r^{(n)}$ has a uniform probabilistic distribution on $[0, 1]$.
So the probability of $r^{(n)} < m$ i.e. $\beta^{(n)}_m = 1$ is exactly $m$,
and therefore $\beta^{(n)}_m$ is a realization of $B_m$, regardless of what $n$ is.

\paragraph{Exercise 14 in chapter 1} (**) Explain the link between the binomial distribution and the expansion of $(a+b)^N$.

\paragraph{Solution} The binomial distribution can be derived by an intermediate step used
to derive the expansion of $(a + b)^N$.

The binomial coefficient $\binom{N}{n}$ 
gives the number of ways to pick $n$ points in $N$ different points.
Without invoking the commutative property of multiplication,
there are $2^N$ terms in the expansion of $(a + b)^N$,
each of which is like 
\[
    aabbabba \cdots.
\]
Now by the definition of the binomial coefficient,
there are $\binom{N}{n}$ terms that have $n$ $a$'s and $(N-n)$ $b$'s.

From this conclusion we can derive the expansion of $(a + b)^N$:
there are $\binom{N}{n}$ terms in the total $2^N$ terms which has $n$ $a$'s and $(N-n)$ $b$'s,
and we have 
\begin{equation}
    (a + b)^N = \sum_{n=0}^N \binom{N}{n} a^n b^{N-n}.
\end{equation}
Similarly, if we consider the probabilistic distribution of 
\begin{equation}
    X_{m, N} = \sum_{k=1}^N B_{m, k},
\end{equation}
we will find the probability of the event that $X_{m, N} = x$ is the sum of the probability of 
all outputs of $\{B_{m, k}\}$ in which there are $x$ 1 outputs and $N - x$ 0 outputs,
and for each possible output, 
the probability is 
\[
    p(1)^x p(0)^{N-x} = m^x (1 - m)^{N-x},
\]
and we have 
\begin{equation}
    p_{m, N} (x) = \binom{N}{x} m^x (1 - m)^{N-x}.
    \label{eq:binominal}
\end{equation}

So the relation between the binomial distribution and the $(a + b)^N$ expansion is 
they both involve the notion of ``picking $x$ points from $N$ points''.
Indeed, by considering the normalization condition of \eqref{eq:binominal},
which is 
\begin{equation}
    1 = \sum_{x} p_{m, N}(x) = \sum_{x = 0}^N \binom{N}{x} m^x (1 - m)^{N-x},
\end{equation}
we rediscover the expansion of $(a + b)^N$,
where we set $a = m$ and $b = 1 - m$.

\paragraph{Exercise 3 in chapter 2} (**)  (a) Show that the above expression (2.15) for $w(x, t)$ with $t>0$ satisfies this equation. (b) By using a double Fourier transform in $x$ and t show that the Green's function of the Smoluchowsky equation (2.26) is indeed the above expression (2.15) for $w(x, t)$ with $t \geq 0$.

\paragraph{Solution} \begin{itemize}
\item[(a)] From (2.15) we have 
\[
    \begin{aligned}
        \pdv{t} w(x, t) &= 
        - \frac{1}{2} \sqrt{\frac{1}{4 \pi D t^3}} \ee^{- \frac{(x - v_d t)^2}{4 D t}} 
        - \sqrt{\frac{1}{4 \pi D t}} \ee^{- \frac{(x - v_d t)^2}{4 D t}} \frac{1}{4 D t^2} 
        (2 v_d (v_d t - x) t - (x- v_d t)^2 ) \\
        &= - \sqrt{\frac{1}{4 \pi D t}} \ee^{- \frac{(x - v_d t)^2}{4 D t}} 
        \left( \frac{1}{2 t} + \frac{(v_d t - x) (v_d t + x)}{4 D t^2} \right),
    \end{aligned}
\]
\[
    \begin{aligned}
        \pdv{x}w(x, t) &= - \sqrt{\frac{1}{4 \pi D t}} \ee^{- \frac{(x - v_d t)^2}{4 D t}} 
        \frac{x - v_d t}{2 D t},
    \end{aligned}
\]
and 
\[
    \begin{aligned}
        \pdv[2]{x}w(x, t) &= - \sqrt{\frac{1}{4 \pi D t}} \ee^{- \frac{(x - v_d t)^2}{4 D t}} 
        \left(
            \frac{1}{2 D t} - \left( \frac{x - v_d t}{2 D t} \right)^2
        \right),
    \end{aligned}
\]
The RHS of the Smoluchowski equation is 
\[
    \begin{aligned}
        D \pdv[2]{w}{x} - v_d \pdv{w}{x} &= - \sqrt{\frac{1}{4 \pi D t}} \ee^{- \frac{(x - v_d t)^2}{4 D t}} 
        \left(
            \frac{1}{2 t} - \frac{(x - v_d t)^2}{4 D t^2} - v_d \frac{x - v_d t}{2 D t}
        \right) \\
        &= - \sqrt{\frac{1}{4 \pi D t}} \ee^{- \frac{(x - v_d t)^2}{4 D t}} 
        \left(
            \frac{1}{2 t} - \frac{x^2 - v_d^2 t^2}{4 D t^2}
        \right),
    \end{aligned}
\]
so we have 
\[
    \pdv{x}w(x, t) = D \pdv[2]{w}{x} - v_d \pdv{w}{x} .
\]

\item[(b)] The initial condition is 
\[
    \lim_{t \to 0} w = \delta(x),
\]
which can be imposed to (2.26) by adding an ``impact'':
\begin{equation}
    \pdv{w}{t} = D \pdv[2]{w}{x} - v_d \pdv{w}{x} + \delta(x) \delta(t).
\end{equation}
Now by Fourier transformation we have 
\[
    \begin{aligned}
        w(x, t) &= \int \frac{\dd{k} \dd{\omega}}{(2\pi)^2} \ee^{- \ii (\omega t - k x)} \tilde{w}(k, \omega),  \\
        - \ii \omega \tilde{w} &= D (\ii k)^2 \tilde{w} - \ii k v_d \tilde{w}  + 1.
    \end{aligned}
\]
We find 
\[
    \tilde{w} = \frac{1}{- \ii \omega + k^2 D + \ii k v_d},
\]
and thus 
\[
    w(x, t) = \int \frac{\dd{k} \dd{\omega}}{(2\pi)^2} \ee^{- \ii (\omega t - k x)}  \frac{1}{- \ii \omega + k^2 D + \ii k v_d}.
\]
We first complete the integral over $\omega$, with the following contour:
\[
    \begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
        %uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300
        
        %Straight Lines [id:da9297518667832358] 
        \draw    (139.5,107) -- (397.5,107) ;
        \draw [shift={(399.5,107)}, rotate = 180] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (12,-3) -- (0,0) -- (12,3) -- cycle    ;
        %Straight Lines [id:da9150191168439286] 
        \draw    (206.75,217.85) -- (206.75,80.43) ;
        \draw [shift={(206.75,78.43)}, rotate = 90] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (12,-3) -- (0,0) -- (12,3) -- cycle    ;
        %Straight Lines [id:da9914740440795959] 
        \draw    (241,147) ;
        \draw [shift={(241,147)}, rotate = 0] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]      (0, 0) circle [x radius= 3.35, y radius= 3.35]   ;
        %Straight Lines [id:da5103977712607115] 
        \draw  [dash pattern={on 4.5pt off 4.5pt}]  (142,117) -- (393.5,117) ;
        %Shape: Arc [id:dp04340597399658641] 
        \draw  [draw opacity=0][dash pattern={on 4.5pt off 4.5pt}] (393.46,114.38) .. controls (393.49,115.38) and (393.51,116.39) .. (393.5,117.4) .. controls (393.01,171.72) and (336.32,215.25) .. (266.87,214.63) .. controls (198.23,214.02) and (142.81,170.51) .. (142,117.05) -- (267.75,116.28) -- cycle ; \draw  [dash pattern={on 4.5pt off 4.5pt}] (393.46,114.38) .. controls (393.49,115.38) and (393.51,116.39) .. (393.5,117.4) .. controls (393.01,171.72) and (336.32,215.25) .. (266.87,214.63) .. controls (198.23,214.02) and (142.81,170.51) .. (142,117.05) ;  
        
        % Text Node
        \draw (250,144.4) node [anchor=north west][inner sep=0.75pt]    {$-\ii k^{2} D+kv_{d}$};
        
        
        \end{tikzpicture}    
\]
\[
    \begin{aligned}
        \int \dd{\omega} \ee^{- \ii (\omega t - k x)} \frac{1}{\omega + \ii D k^2 - k v_d} = - 2\pi \ii \ee^{- \ii ( - \ii k^2 D t + k v_d t - kx )}.
    \end{aligned}
\]
Thus 
\[
    \begin{aligned}
        w(x, t) &= \frac{\ii}{(2\pi)^2} \int \dd{k} (- 2\pi \ii) \ee^{- \ii ( - \ii k^2 D t + k v_d t - kx )} \\
        &= \frac{1}{2\pi} \int \dd{k} \ee^{- k^2 D t - \ii k (v_d t - x)} \\
        &= \frac{1}{2\pi} \cdot \sqrt{\frac{2\pi}{2 D t}} \ee^{\frac{1}{2} \frac{1}{2 D t} (- \ii (v_d t - x))^2} \\
        &= \sqrt{\frac{1}{4 \pi D t}} \ee^{- \frac{(x - v_d t)^2}{4 D t}} .
    \end{aligned}
\]
This is exactly (2.15).

\end{itemize}

\paragraph{Exercise 5 in chapter 2} (**) Explain in detail how, by measuring for the first time the position diffusion constant of a small Brownian sphere immerged in water, the physicist Jean Perrin, using the Einstein relation, was able to measure Avogadro's Number $N_A$, thereby confirming the existence of atoms (Jean Perrin received the Nobel prize for this work in 1926, see his Nobel lecture on the Nobel website). Use Stokes' law stating that a sphere of radius $R$ moving at a velocity $V$ feels in a fluid with viscosity $\eta$ a frictional force
$$
F=6 \pi R \eta V
$$
Remember that Avogadro's Number $N_A$ is involved in the ideal gas constant, defined by the relation
$$
\frac{\text { pressure } \text { volume }}{\text { temperature }}=n R_{\mathrm{ig}}
$$
where $n$ is the number of moles of the volume of gas considered. In the kinetic theory of gases, $R_{\mathrm{ig}}$ is given by
$$
R_{\mathrm{ig}}=N_A k_B
$$

\paragraph{Solution} The Stokes' law 
\begin{equation}
    F = 6 \pi R \eta v 
\end{equation}
connects two physical quantities arising from the same dissipation process in the fluid:
the viscosity $\mu$ and the response coefficient
\begin{equation}
    \mu = \frac{v}{F}.
\end{equation}
The relation between the two is imposed by the Navier-Stokes equation.
Since we also have 
\begin{equation}
    \mu = \frac{D}{k_{\text{B}} T},
\end{equation}
we have 
\begin{equation}
    \frac{1}{6 \pi R \eta} = \frac{D}{k_{\text{B}} T}.
\end{equation}
This equation can be used to measure $k_{\text{B}}$:
each quantities involved in the equation can be measured separately.
The viscosity $\eta$ can be measured by standard fluid dynamic methods.
The radius $R$ can be measured by letting the particles fall in the fluid 
and recording its terminal velocity,
and then we have 
\begin{equation}
    R = \frac{mg}{6 \pi \eta v_{\text{terminal}}}.
\end{equation}
The diffusion coefficient $D$ can be measured by looking at the trajectory of a Brownian particle.
The temperature is measured by a thermometer.
Now we find $k_{\text{B}}$,
and by the ideal gas equation 
\begin{equation}
    p V = n R_{\text{ig}} T
\end{equation}
we can measure $R_{\text{ig}}$,
so finally, by 
\begin{equation}
    R_{\text{ig}} = N_A k_{\text{B}},
\end{equation}
the Avogadro constant is found.

\paragraph{Problem 2} 

\paragraph{Solution} \begin{itemize}
\item[(a)] For a single bit we have 
\begin{equation}
    H(\mathrm{B}_{1/2}) = - \frac{1}{2} \log_2 \frac{1}{2} - \frac{1}{2} \log_2 \frac{1}{2} = 1.
\end{equation}
For $N$ independent bits,
we have 
\begin{equation}
    H(\otimes_{j=1}^N \mathrm{B}_{1/2, j}) = - \sum_{i} \left(\frac{1}{2}\right)^N \log_2 \left(\frac{1}{2}\right)^N = - 2^N \times \frac{1}{2^N} \times (- N) = N.
\end{equation}

\item[(b)] We have 
\[
    S = - \pdv{F}{T}, \quad F = - k _{\text{B}} T \ln Z.
\]
Now with the definition of the partition function 
\begin{equation}
    Z = \sum_i \ee^{- E_i / k_{\text{B}} T},
\end{equation}
we have 
\[
    \begin{aligned}
        \pdv{T} T \ln Z &= \ln Z + \frac{T}{Z} \pdv{Z}{T} \\
        &= \ln Z + \frac{T}{Z} \sum_i \frac{E_i}{k_{\text{B}} T^2} \ee^{- E_i / k_{\text{B}} T} \\
        &= \ln Z + \frac{1}{k_{\text{B}} T} \sum_i p_i E_i.
    \end{aligned}
\]
Thus 
\begin{equation}
    S = - k_{\text{B}} \ln Z - \frac{1}{T} \sum_i p_i E_i = - k_{\text{B}} \ln Z - \frac{\expval*{E}}{T}.
\end{equation}

\item[(c)] In the high temperature limit $E_i / k_{\text{B}} T \to 0$ for every $E_{i}$,
so energy is no longer important in determining the probabilistic distribution 
and each configuration has the same probability.
The energy of $N$ indistinguishable random bits, in this case, is therefore 
\begin{equation}
    E = \sum_{j=1}^N \mathrm{B}_{1/2, j}.
\end{equation}
The probability of $E = \epsilon$ is 
\begin{equation}
    p(E = \epsilon) = \binom{N}{\epsilon} \times \frac{1}{2^N},
\end{equation}
which reaches its peak when $\epsilon = N / 2$,
so 
\begin{equation}
    \mathcal{E} = N / 2.
\end{equation}

There are $\binom{N}{\epsilon}$ microstates in the macrostate $(N ,\mathcal{C})$,
so 
\[
    \begin{aligned}
        \lim_{N \to \infty} \frac{1}{N} S(N, \mathcal{E}) &= k_{\text{B}} \frac{1}{N} \ln \binom{N}{N / 2} \\
        &= \frac{k_{\text{B}}}{N} (\ln N! - 2 \ln (N/2)!) \\
        &\approx \frac{k_{\text{B}}}{N} (N \ln N - 2 (N / 2) \ln N/2 ) \\
        &= k_{\text{B}} \ln 2.
    \end{aligned}
\]
Thus 
\begin{equation}
    \lim_{N \to \infty} \frac{1}{N} S(N, \mathcal{E}) = k_{\text{B}} \ln 2 = k_{\text{B}} \ln 2 \times S_{\text{Shannon}} (\mathrm{B}_{1/2}).
\end{equation}

\item[(d)] 

\item[(g)] We need to take the $\alpha \to 1$ limit of 
\begin{equation}
    H_\alpha(X) = \frac{1}{1 - \alpha} \log_2 \left( \sum_i p_i^\alpha \right) .
\end{equation}
When $\alpha = 1$, both the numerator ($\log_2 1 = 0$) and the denominator are zero,
so we can use the L'Hospital's rule:
\[
    \lim_{\alpha \to 1} H_{\alpha} = \lim_{\alpha \to 1} \frac{\frac{\sum_{i} \ln p_i p_i^\alpha}{\ln 2 \sum_{i} p_i^\alpha}}{-1}
    = - \sum_i p_i \log p_i = H(X).
\]

\end{itemize}

\end{document}